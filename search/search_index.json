{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"about/","text":"Engineers and scientists working in a heterogeneous computing environment often want to distribute the various tasks of an application\u2014such as computation, storage, analysis, or visualization\u2014to different types of resources and libraries. Often, a technique known as Remote Procedure Call (RPC) is used that allows local calls to be transparently executed onto remote resources. Using common RPC frameworks on a High-Performance Computing (HPC) system presents two limitations, however: the inability to take advantage of the native network transport and the inability to transfer large amounts of data. To avoid these limitations, we developed Mercury\u2014an RPC interface specifically designed for HPC. Mercury builds on a small, easily ported network abstraction layer, providing operations closely matched to the capabilities of high-performance network environments. Unlike most other RPC frameworks, Mercury directly supports handling remote calls containing large data arguments. Moreover, Mercury\u2019s network protocol is designed to scale to thousands of clients. Collaborators","title":"About"},{"location":"about/#collaborators","text":"","title":"Collaborators"},{"location":"help/","text":"Mailing Lists There are two mailing lists described below that users may wish to subscribe to: mercury@lists.mcs.anl.gov | subscribe | This mailing list is available for users to discuss Mercury issues among each other. Users must subscribe before they can send e-mails to the list. mercury-devel@lists.mcs.anl.gov | subscribe | This mailing list is available for Mercury developers to discuss implementation of new and existing features, NA plugins, etc. Developers must subscribe before they can send e-mails to the list. Issue Tracking Current and past issues can be found on GitHub: You may check that the latest build passes by looking at the CI: Or for more details you may also look at what the build tests have reported onto the CDash Dashboard: Contribute We welcome all contributions to Mercury! Code Patches Requests for new features Feedback on using Mercury and suggestions for improvements Please feel free to send any of the above to the mercury development mailing list or create an issue/pull request directly on GitHub. We have many things planned for Mercury and limited developer time available; contact us if you want to learn more about RPC on HPC systems or if you are looking for an interesting project to contribute to. Info We require a Contributor License Agreement (CLA) to be filled out and sent to: var username = \"mercury-legal\"; var hostname = \"anl.gov\"; var linktext = username + \"@\" + hostname; document.write(\"<a href='\" + \"mail\" + \"to:\" + username + \"@\" + hostname + \"'>\" + linktext + \"</a>\"); You may use either an individual CLA for your own personal contributions or a corporate CLA for contributions from your organization.","title":"Help"},{"location":"help/#mailing-lists","text":"There are two mailing lists described below that users may wish to subscribe to: mercury@lists.mcs.anl.gov | subscribe | This mailing list is available for users to discuss Mercury issues among each other. Users must subscribe before they can send e-mails to the list. mercury-devel@lists.mcs.anl.gov | subscribe | This mailing list is available for Mercury developers to discuss implementation of new and existing features, NA plugins, etc. Developers must subscribe before they can send e-mails to the list.","title":"Mailing Lists"},{"location":"help/#issue-tracking","text":"Current and past issues can be found on GitHub: You may check that the latest build passes by looking at the CI: Or for more details you may also look at what the build tests have reported onto the CDash Dashboard:","title":"Issue Tracking"},{"location":"help/#contribute","text":"We welcome all contributions to Mercury! Code Patches Requests for new features Feedback on using Mercury and suggestions for improvements Please feel free to send any of the above to the mercury development mailing list or create an issue/pull request directly on GitHub. We have many things planned for Mercury and limited developer time available; contact us if you want to learn more about RPC on HPC systems or if you are looking for an interesting project to contribute to. Info We require a Contributor License Agreement (CLA) to be filled out and sent to: var username = \"mercury-legal\"; var hostname = \"anl.gov\"; var linktext = username + \"@\" + hostname; document.write(\"<a href='\" + \"mail\" + \"to:\" + username + \"@\" + hostname + \"'>\" + linktext + \"</a>\"); You may use either an individual CLA for your own personal contributions or a corporate CLA for contributions from your organization.","title":"Contribute"},{"location":"publications/","text":"Conference Proceedings J. Soumagne, D. Kimpe, J. Zounmevo, M. Chaarawi, Q. Koziol, A. Afsahi, and R. Ross, Mercury: Enabling Remote Procedure Call for High-Performance Computing , IEEE International Conference on Cluster Computing, Sep 2013. | paper | slides | Journals J. Soumagne, P. Carns, R. Ross, Advancing RPC for Data Services at Exascale , IEEE Data Engineering Bulletin, Vol. 43 No. 1, 23\u201334, March 2020. | paper | Posters J. Soumagne, P. Carns, D. Kimpe, Q. Koziol, and R. Ross, A Remote Procedure Call Approach for Extreme Scale Services , Computational Science and Engineering Software Sustainability and Productivity Challenges (CSESSP) Workshop, Oct 2015. | paper | poster | Past Presentations SC18 BoF, Sep 2018. | slides | Nersc CS Seminar, Jun 2017. | slides | Intel F2F, Jul 2016. | slides | INRIA Joint-lab Workshop, Nov 2013. | slides | Additional Publications Please refer to these two additional links for work that was realized within the context of Mochi and for work from projects that are using Mercury and Mochi: Mochi Publications. | link | Mochi Projects. | link |","title":"Publications"},{"location":"publications/#conference-proceedings","text":"J. Soumagne, D. Kimpe, J. Zounmevo, M. Chaarawi, Q. Koziol, A. Afsahi, and R. Ross, Mercury: Enabling Remote Procedure Call for High-Performance Computing , IEEE International Conference on Cluster Computing, Sep 2013. | paper | slides |","title":"Conference Proceedings"},{"location":"publications/#journals","text":"J. Soumagne, P. Carns, R. Ross, Advancing RPC for Data Services at Exascale , IEEE Data Engineering Bulletin, Vol. 43 No. 1, 23\u201334, March 2020. | paper |","title":"Journals"},{"location":"publications/#posters","text":"J. Soumagne, P. Carns, D. Kimpe, Q. Koziol, and R. Ross, A Remote Procedure Call Approach for Extreme Scale Services , Computational Science and Engineering Software Sustainability and Productivity Challenges (CSESSP) Workshop, Oct 2015. | paper | poster |","title":"Posters"},{"location":"publications/#past-presentations","text":"SC18 BoF, Sep 2018. | slides | Nersc CS Seminar, Jun 2017. | slides | Intel F2F, Jul 2016. | slides | INRIA Joint-lab Workshop, Nov 2013. | slides |","title":"Past Presentations"},{"location":"publications/#additional-publications","text":"Please refer to these two additional links for work that was realized within the context of Mochi and for work from projects that are using Mercury and Mochi: Mochi Publications. | link | Mochi Projects. | link |","title":"Additional Publications"},{"location":"releases/CHANGES_v2.0.1/","text":"Summary This version brings a few bug fixes and updates to our v2.0.0 release. New features Improve logging system and add HG_LOG_SUBSYS environment variable that can be used in combination with HG_LOG_LEVEL to select log sub-systems. Add min_debug log level to keep debug traces. Traces get printed when an error occurs. [HG] Add HG_Set_log_subsys() . [NA] Add support for message size hints though max_unexpected_size and max_expected_size hints. Supported with OFI, BMI and MPI plugins. [NA BMI/SM/OFI] Support sends to self address. [HG/NA] Add HG_HOSTUNREACH / NA_HOSTUNREACH error codes. Bug fixes [HG] Add missing check for NULL addr passed to HG_Forward() . Remove unnecessary spinwait() and track handle in completion queue. Fix handle refcount if HG_Respond() fails. Remove race in HG_Trigger() optimization that was skipping signaling. [HG bulk] Prevent virtual handle data to be sent eagerly. Ensure underlying error codes from NA are returned back to user. [HG util] Fix timeout passed to pthread_cond_timedwait() when CLOCK_MONOTONIC_COARSE is used. Remove check for STDERR_FILENO . Add best-effort C++ compatibility for atomics. [NA] Ensure completion callback is called after OP ID is fully released. [NA BMI] Rework and simplify NA BMI code and remove extra allocations. [NA SM] Prevent potential race on bulk handle that was freed. Fix release of invalid addresses. Prevent race in address resolution. [NA OFI] Allow libfabric to return canceled operations. Yield to other threads when using PSM2. Return and convert OFI error codes back to upper layers. Ensure selected domain matches address format. Prevent tcp protocol to be used on macOS. Fix potential memory leak in na_ofi_provider_check() . Add addr pool to prevent addr allocation on unexpected recv. Known Issues [NA OFI] [tcp/verbs;ofi_rxm] Using more than 256 peers requires FI_UNIVERSE_SIZE to be set. [tcp;ofi_rxm] Remains unstable, use sockets as a fallback in case of issues.","title":"Release Notes v2.0.1"},{"location":"releases/CHANGES_v2.0.1/#summary","text":"This version brings a few bug fixes and updates to our v2.0.0 release.","title":"Summary"},{"location":"releases/CHANGES_v2.0.1/#new-features","text":"Improve logging system and add HG_LOG_SUBSYS environment variable that can be used in combination with HG_LOG_LEVEL to select log sub-systems. Add min_debug log level to keep debug traces. Traces get printed when an error occurs. [HG] Add HG_Set_log_subsys() . [NA] Add support for message size hints though max_unexpected_size and max_expected_size hints. Supported with OFI, BMI and MPI plugins. [NA BMI/SM/OFI] Support sends to self address. [HG/NA] Add HG_HOSTUNREACH / NA_HOSTUNREACH error codes.","title":"New features"},{"location":"releases/CHANGES_v2.0.1/#bug-fixes","text":"[HG] Add missing check for NULL addr passed to HG_Forward() . Remove unnecessary spinwait() and track handle in completion queue. Fix handle refcount if HG_Respond() fails. Remove race in HG_Trigger() optimization that was skipping signaling. [HG bulk] Prevent virtual handle data to be sent eagerly. Ensure underlying error codes from NA are returned back to user. [HG util] Fix timeout passed to pthread_cond_timedwait() when CLOCK_MONOTONIC_COARSE is used. Remove check for STDERR_FILENO . Add best-effort C++ compatibility for atomics. [NA] Ensure completion callback is called after OP ID is fully released. [NA BMI] Rework and simplify NA BMI code and remove extra allocations. [NA SM] Prevent potential race on bulk handle that was freed. Fix release of invalid addresses. Prevent race in address resolution. [NA OFI] Allow libfabric to return canceled operations. Yield to other threads when using PSM2. Return and convert OFI error codes back to upper layers. Ensure selected domain matches address format. Prevent tcp protocol to be used on macOS. Fix potential memory leak in na_ofi_provider_check() . Add addr pool to prevent addr allocation on unexpected recv.","title":"Bug fixes"},{"location":"releases/CHANGES_v2.0.1/#known-issues","text":"[NA OFI] [tcp/verbs;ofi_rxm] Using more than 256 peers requires FI_UNIVERSE_SIZE to be set. [tcp;ofi_rxm] Remains unstable, use sockets as a fallback in case of issues.","title":"Known Issues"},{"location":"releases/CHANGES_v2.1.0/","text":"Summary This version brings bug fixes and updates to our v2.0.0 release. New features [NA UCX] Add initial support for UCX. As opposed to other plugins, the UCX plugin is able through the ucx+all init string to decide on which protocol to use. [NA SM] Update default addressing format to follow PID-ID instead of PID/ID Allow for passing of arbitrary SM init URIs Enable support for bulk handle address binding Add sm_info_string field to HG init info, which allows for specific init URIs to be used for SM when auto_sm is enabled. [NA] Add thread_mode to NA init options and add NA_THREAD_MODE_SINGLE to relax thread-safety requirements. Add na_cb_info_recv_expected to return actual_buf_size . Add na_cb_type_to_string() to convert callback enum type to printable string. [NA IP] Add na_ip_check_interface() routine that can be used by plugins to select IP interface to use. [HG util] Add hg_mem_header_alloc() / free() calls to allocate buffers with a preceding header. Add thread annotation module for thread safety analysis. Add mercury_mem_pool memory pool to facilitate allocation and memory registration of a pool of buffers. Enable format argument checking on logging functions. Add hg_time_from_ms() and hg_time_to_ms() for time conversion to ms. [HG bulk] Return transfer size size through hg_cb_info and hg_cb_info_bulk . Bug fixes [NA OFI] Require at least v1.7.0 of libfabric. Fix handling of completion queue events and completion of retried operations that fail. Fix progress loop to reduce time calls. Force per-region registration for all providers and remove deprecated FI_MR_SCALABLE type of registrations and global MR keys. [NA SM] Refactor and clean up sends/cancelation/retries/rma/address keys. Remove use of usernames from SM paths. [HG util] Prevent use of CLOCK_MONOTONIC_COARSE on PPC platforms and default to CLOCK_MONOTONIC . Fix debug logs that were not freed at exit. Remove return value of mutex lock/unlock routines. Fix log subsys to prevent setting duplicates. Simplify handling of compiler attributes and add mercury_compiler_attributes.h module. Remove hg_util_ integer types and use stdint.h . Remove OpenPA dependency for atomics and use built-in atomics instead (requires gcc >= 4.7). [HG/HG util/NA] Fix thread safety warnings and potential thread locking issues. Fix log level set routines that were not enabling the underlying log sub-system. Avoid reading system timers and optimize handling of timeouts. [HG bulk] Fix erroneous call to NA_Mem_deregister() when handle is deserialized. Correctly mark op as canceled if canceled from NA. Clean up and simplify handling of NA error return codes in callback. Minimal tracking of bulk handles that are not freed. [HG Core] Fix error handling when NA send fails during an HG_Forward() operation. Correctly map NA error return code back to HG error return code in user callback. Correctly print HG handle debug information. In short responses like ACKs, leave room at the front of a buffer for the NA header, and expect the header to be present. Fix potential issue on context destroy where handles could have been reposted while finalizing if RPCs were still in the queue. [General] Warning and static analysis issues were fixed. Known Issues [NA OFI] [tcp/verbs;ofi_rxm] Using more than 256 peers requires FI_UNIVERSE_SIZE to be set. [tcp;ofi_rxm] Remains unstable, use sockets as a fallback in case of issues. Please note that libfabric v1.13.0 and v1.13.1 have address management issues with that transport. Please either downgrade to v1.12.1 (or earlier) or upgrade to v1.13.2 (or later). [NA UCX] NA_Addr_to_string() cannot be used on non-listening processes to convert a self-address to a string.","title":"Release Notes v2.1.0"},{"location":"releases/CHANGES_v2.1.0/#summary","text":"This version brings bug fixes and updates to our v2.0.0 release.","title":"Summary"},{"location":"releases/CHANGES_v2.1.0/#new-features","text":"[NA UCX] Add initial support for UCX. As opposed to other plugins, the UCX plugin is able through the ucx+all init string to decide on which protocol to use. [NA SM] Update default addressing format to follow PID-ID instead of PID/ID Allow for passing of arbitrary SM init URIs Enable support for bulk handle address binding Add sm_info_string field to HG init info, which allows for specific init URIs to be used for SM when auto_sm is enabled. [NA] Add thread_mode to NA init options and add NA_THREAD_MODE_SINGLE to relax thread-safety requirements. Add na_cb_info_recv_expected to return actual_buf_size . Add na_cb_type_to_string() to convert callback enum type to printable string. [NA IP] Add na_ip_check_interface() routine that can be used by plugins to select IP interface to use. [HG util] Add hg_mem_header_alloc() / free() calls to allocate buffers with a preceding header. Add thread annotation module for thread safety analysis. Add mercury_mem_pool memory pool to facilitate allocation and memory registration of a pool of buffers. Enable format argument checking on logging functions. Add hg_time_from_ms() and hg_time_to_ms() for time conversion to ms. [HG bulk] Return transfer size size through hg_cb_info and hg_cb_info_bulk .","title":"New features"},{"location":"releases/CHANGES_v2.1.0/#bug-fixes","text":"[NA OFI] Require at least v1.7.0 of libfabric. Fix handling of completion queue events and completion of retried operations that fail. Fix progress loop to reduce time calls. Force per-region registration for all providers and remove deprecated FI_MR_SCALABLE type of registrations and global MR keys. [NA SM] Refactor and clean up sends/cancelation/retries/rma/address keys. Remove use of usernames from SM paths. [HG util] Prevent use of CLOCK_MONOTONIC_COARSE on PPC platforms and default to CLOCK_MONOTONIC . Fix debug logs that were not freed at exit. Remove return value of mutex lock/unlock routines. Fix log subsys to prevent setting duplicates. Simplify handling of compiler attributes and add mercury_compiler_attributes.h module. Remove hg_util_ integer types and use stdint.h . Remove OpenPA dependency for atomics and use built-in atomics instead (requires gcc >= 4.7). [HG/HG util/NA] Fix thread safety warnings and potential thread locking issues. Fix log level set routines that were not enabling the underlying log sub-system. Avoid reading system timers and optimize handling of timeouts. [HG bulk] Fix erroneous call to NA_Mem_deregister() when handle is deserialized. Correctly mark op as canceled if canceled from NA. Clean up and simplify handling of NA error return codes in callback. Minimal tracking of bulk handles that are not freed. [HG Core] Fix error handling when NA send fails during an HG_Forward() operation. Correctly map NA error return code back to HG error return code in user callback. Correctly print HG handle debug information. In short responses like ACKs, leave room at the front of a buffer for the NA header, and expect the header to be present. Fix potential issue on context destroy where handles could have been reposted while finalizing if RPCs were still in the queue. [General] Warning and static analysis issues were fixed.","title":"Bug fixes"},{"location":"releases/CHANGES_v2.1.0/#known-issues","text":"[NA OFI] [tcp/verbs;ofi_rxm] Using more than 256 peers requires FI_UNIVERSE_SIZE to be set. [tcp;ofi_rxm] Remains unstable, use sockets as a fallback in case of issues. Please note that libfabric v1.13.0 and v1.13.1 have address management issues with that transport. Please either downgrade to v1.12.1 (or earlier) or upgrade to v1.13.2 (or later). [NA UCX] NA_Addr_to_string() cannot be used on non-listening processes to convert a self-address to a string.","title":"Known Issues"},{"location":"releases/CHANGES_v2.2.0/","text":"Summary This version brings bug fixes and updates to our v2.0.0 release. New features [NA OFI] Choose addr format dynamically based on user preferences Add support for IPv6 Add support for FI_SOCKADDR_IB Add support for FI_ADDR_STR and shm provider Add support for FI_ADDR_OPX and opx provider Add support for HPE cxi provider, init info format for cxi is: NIC:PID (both or only one may be passed), NIC is cxi[0-9] , PID is [0-510] Use hwloc to select interface to use if NIC information is available (only supported by cxi at the moment) Support device memory types and FI_HMEM for verbs and cxi providers Add support for FI_THREAD_DOMAIN Passing NA_THREAD_MODE_SINGLE will relax default FI_THREAD_SAFE thread mode and use FI_THREAD_DOMAIN instead. Update min required version to libfabric 1.9 Improve debug output to print verbose FI info of selected provider [NA UCX] Use active messaging UCP_FEATURE_AM for unexpected messages (only), this allows for removal of address resolution and retry on first message to exchange connection IDs Turn on mempool by default Support device memory types Bump min required version to 1.10 [NA PSM] Add mercury NA plugin for the qlogic/intel PSM interface Also support PSM2 (Intel OmniPath) through the PSM NA plugin [NA SM] Add support for 0-size messages [NA] Add na_addr_format init info Add request_mem_device init info when GPU support is requested Update NA_Mem_register() API call to support memory types (e.g., CUDA, ROCm, ZE) and devices IDs Add na_loc module for hwloc detection Remove na_uint , na_int , na_bool_t and na_size_t types Use separate versioning for library and update to v3.0.0 [NA IP] Refactor na_ip_check_interface() to only use getaddrinfo() and getifaddrs() Add family argument to force detection of IPv4/IPv6 addresses Add ip debug log [NA Test] Introduce new perf tests to measure msg latency, put / get bandwidth. These benchmarks produce results that are comparable with OSU benchmarks. [HG util] Add mercury_byteswap.h for bswap macros Add mercury_inet.h for htonll and ntohll routine Add mercury_param.h to use sys/param.h or MIN/MAX macros etc Add alternative log names: err , warn , trace , dbg Use separate versioning for library and update to v3.0.0 [HG bulk] Add support for memory attributes through a new HG_Bulk_create_attr() routine (support CUDA, ROCm, ZE) [HG] Remove MERCURY_ENABLE_STATS CMake option and use 'diag' log subsys instead Modify behavior of stats field to turn on diagnostics Refactor existing counters (used only if debug is on) Add checksum levels that can be manually controlled at runtime (disabled by default, HG_CHECKSUM_NONE level) Update to mchecksum v2.0 Add HG_Set_log_func() and HG_Set_log_stream() to control log output [HG hl] The deprecated mercury high-level library and high-level macros have now been removed. Bug fixes [NA OFI] Switch tcp provider to FI_PROGRESS_MANUAL Prevent empty authorization keys from being passed Check max MR key used when FI_MR_PROV_KEY is not set New implementation of address management Fix duplicate addresses on multithreaded lookups Redefine address keys and raw addresses to prevent allocations Use FI addr map to lookup by FI addr Improve serialization and deserialization of addresses Fix provider table and use EP proto Refactor and clean up plugin initialization Clean up ip and domain checking Ensure interface name is not used as domain name for verbs etc Use NA IP module and add missing NA_OFI_VERIFY_PROV_DOM for tcp provider Rework handling of fi_info to open fabric/domain/endpoint Separate fabric from domain and keep single domain per NA class Refactor handling of scalable vs standard endpoints Improve handling of retries after FI_EAGAIN return code Abort retried ops after default 90s timeout Abort ops to a target being retried after first NA_HOSTUNREACH error in CQ [NA UCX] Fix potential error not returned correctly on conn_insert() Fix potential double free of worker_addr Remove use of unified mode Ensure address key is correctly reset Fix hostname / net device parsing to allow for multiple net devices [HG util] Make sure we round up ms time conversion, this ensures that small timeouts do not result in busy spin. Use sched_yield() instead of deprecated pthread_yield() Fix 'none' log level not recognized Fix external logging facility Let mercury log print counters on exit when debug outlet is on [HG proc] Prevent call to save_ptr()/restore_ptr() during HG_FREE [HG Bulk] Remove some NA_CANCELED event warnings. [HG] Properly handle error when overflow bulk transfer is interrupted. Previously the RPC callback was triggered regarldless, potentially causing issues. [CMake] Correctly set INSTALL_RPATH for target libraries Split mercury.pc pkg config file into multiple .pc files for mercury_util and na to prevent from overlinking against those libraries when using pkg config. Known Issues [NA OFI] [tcp/verbs;ofi_rxm] Using more than 256 peers requires FI_UNIVERSE_SIZE to be set. [NA UCX] NA_Addr_to_string() cannot be used on non-listening processes to convert a self-address to a string.","title":"Release Notes v2.2.0"},{"location":"releases/CHANGES_v2.2.0/#summary","text":"This version brings bug fixes and updates to our v2.0.0 release.","title":"Summary"},{"location":"releases/CHANGES_v2.2.0/#new-features","text":"[NA OFI] Choose addr format dynamically based on user preferences Add support for IPv6 Add support for FI_SOCKADDR_IB Add support for FI_ADDR_STR and shm provider Add support for FI_ADDR_OPX and opx provider Add support for HPE cxi provider, init info format for cxi is: NIC:PID (both or only one may be passed), NIC is cxi[0-9] , PID is [0-510] Use hwloc to select interface to use if NIC information is available (only supported by cxi at the moment) Support device memory types and FI_HMEM for verbs and cxi providers Add support for FI_THREAD_DOMAIN Passing NA_THREAD_MODE_SINGLE will relax default FI_THREAD_SAFE thread mode and use FI_THREAD_DOMAIN instead. Update min required version to libfabric 1.9 Improve debug output to print verbose FI info of selected provider [NA UCX] Use active messaging UCP_FEATURE_AM for unexpected messages (only), this allows for removal of address resolution and retry on first message to exchange connection IDs Turn on mempool by default Support device memory types Bump min required version to 1.10 [NA PSM] Add mercury NA plugin for the qlogic/intel PSM interface Also support PSM2 (Intel OmniPath) through the PSM NA plugin [NA SM] Add support for 0-size messages [NA] Add na_addr_format init info Add request_mem_device init info when GPU support is requested Update NA_Mem_register() API call to support memory types (e.g., CUDA, ROCm, ZE) and devices IDs Add na_loc module for hwloc detection Remove na_uint , na_int , na_bool_t and na_size_t types Use separate versioning for library and update to v3.0.0 [NA IP] Refactor na_ip_check_interface() to only use getaddrinfo() and getifaddrs() Add family argument to force detection of IPv4/IPv6 addresses Add ip debug log [NA Test] Introduce new perf tests to measure msg latency, put / get bandwidth. These benchmarks produce results that are comparable with OSU benchmarks. [HG util] Add mercury_byteswap.h for bswap macros Add mercury_inet.h for htonll and ntohll routine Add mercury_param.h to use sys/param.h or MIN/MAX macros etc Add alternative log names: err , warn , trace , dbg Use separate versioning for library and update to v3.0.0 [HG bulk] Add support for memory attributes through a new HG_Bulk_create_attr() routine (support CUDA, ROCm, ZE) [HG] Remove MERCURY_ENABLE_STATS CMake option and use 'diag' log subsys instead Modify behavior of stats field to turn on diagnostics Refactor existing counters (used only if debug is on) Add checksum levels that can be manually controlled at runtime (disabled by default, HG_CHECKSUM_NONE level) Update to mchecksum v2.0 Add HG_Set_log_func() and HG_Set_log_stream() to control log output [HG hl] The deprecated mercury high-level library and high-level macros have now been removed.","title":"New features"},{"location":"releases/CHANGES_v2.2.0/#bug-fixes","text":"[NA OFI] Switch tcp provider to FI_PROGRESS_MANUAL Prevent empty authorization keys from being passed Check max MR key used when FI_MR_PROV_KEY is not set New implementation of address management Fix duplicate addresses on multithreaded lookups Redefine address keys and raw addresses to prevent allocations Use FI addr map to lookup by FI addr Improve serialization and deserialization of addresses Fix provider table and use EP proto Refactor and clean up plugin initialization Clean up ip and domain checking Ensure interface name is not used as domain name for verbs etc Use NA IP module and add missing NA_OFI_VERIFY_PROV_DOM for tcp provider Rework handling of fi_info to open fabric/domain/endpoint Separate fabric from domain and keep single domain per NA class Refactor handling of scalable vs standard endpoints Improve handling of retries after FI_EAGAIN return code Abort retried ops after default 90s timeout Abort ops to a target being retried after first NA_HOSTUNREACH error in CQ [NA UCX] Fix potential error not returned correctly on conn_insert() Fix potential double free of worker_addr Remove use of unified mode Ensure address key is correctly reset Fix hostname / net device parsing to allow for multiple net devices [HG util] Make sure we round up ms time conversion, this ensures that small timeouts do not result in busy spin. Use sched_yield() instead of deprecated pthread_yield() Fix 'none' log level not recognized Fix external logging facility Let mercury log print counters on exit when debug outlet is on [HG proc] Prevent call to save_ptr()/restore_ptr() during HG_FREE [HG Bulk] Remove some NA_CANCELED event warnings. [HG] Properly handle error when overflow bulk transfer is interrupted. Previously the RPC callback was triggered regarldless, potentially causing issues. [CMake] Correctly set INSTALL_RPATH for target libraries Split mercury.pc pkg config file into multiple .pc files for mercury_util and na to prevent from overlinking against those libraries when using pkg config.","title":"Bug fixes"},{"location":"releases/CHANGES_v2.2.0/#known-issues","text":"[NA OFI] [tcp/verbs;ofi_rxm] Using more than 256 peers requires FI_UNIVERSE_SIZE to be set. [NA UCX] NA_Addr_to_string() cannot be used on non-listening processes to convert a self-address to a string.","title":"Known Issues"},{"location":"releases/CHANGES_v2.3.0/","text":"Summary This version brings bug fixes and updates to our v2.0.0 release. New features [HG/NA] Add HG_Init_opt2() / HG_Core_init_opt2() / NA_Initialize_opt2() to safely pass updated init info while maintaining ABI compatibility between versions Add HG_Get_na_protocol_info() / HG_Free_na_protocol_info() and add hg_info utility for basic listing of protocols [HG] Add support for multi-recv operations (OFI plugin only) Currently disable multi-recv when auto SM is on Posted recv operations are in that case decoupled from pool of RPC handles Add release_input_early init info flag to attempt to release input buffers early once input is decoded Add HG_Release_input_buf() to manually release input buffer. Add also no_multi_recv init info option to force disabling multi-recv Make use of subsys logs ( cls , ctx , addr , rpc , poll ) to control log output Add init info struct versioning Add HG_Context_unpost() / HG_Core_context_unpost() for optional 2-step context shutdown [HG bulk] Update to new logging system through bulk subsys log. [HG proc] Update to new logging system through proc subsys log. [HG Test] Refactor tests to separate perf tests from unit tests Add NA/HG test common library Add hg_rate / hg_bw_write and hg_bw_read perf tests Perf test now supports multi-client / multi-server workloads Add BUILD_TESTING_UNIT and BUILD_TESTING_PERF CMake options [NA] Add support for multi-recv operations Add NA_Msg_multi_recv_unexpected() and na_cb_info_multi_recv_unexpected cb info Add flags parameter to NA_Op_create() and NA_Msg_buf_alloc() Add NA_Has_opt_feature() to query multi recv capability Remove int return type from NA callbacks and return void Remove unused timeout parameter from NA_Trigger() NA_Addr_free() / NA_Mem_handle_free() and NA_Op_destroy() now return void na_mem_handle_t and na_addr_t types no longer include pointer type Add support for dynamically loaded plugins Add NA_PLUGIN_PATH env variable to optionally control plugin loading path (default is NA_INSTALL_PLUGIN_DIR ) Add NA_INSTALL_PLUGIN_DIR variable to control plugin install path (default is lib install path) Add NA_USE_DYNAMIC_PLUGINS CMake option (OFF by default) Add ability to query protocol info from plugins Add NA_Get_protocol_info() / NA_Free_protocol_info() API routines Add na_protocol_info struct to na_types Bump NA library version to 4.0.0 [NA OFI] Add support for multi-recv operations and use FI_MSG Allocate multi-recv buffers using hugepages when available Switch to using fi_senddata() with immediate data for unexpected msgs NA_OFI_UNEXPECTED_TAG_MSG can be set to switch back to former behavior that uses tagged messages instead Remove support for deprecated psm provider Control CQ interrupt signaling with FI_AFFINITY (only used if thread is bound to a single CPU ID) Enable cxi provider to use FI_WAIT_FD Add NA_OFI_OP_RETRY_TIMEOUT and NA_OFI_OP_RETRY_PERIOD Once NA_OFI_OP_RETRY_TIMEOUT milliseconds elapse, retry is stopped and operation is aborted (default is 120000ms) When NA_OFI_OP_RETRY_PERIOD is set, operations are retried only every NA_OFI_OP_RETRY_PERIOD milliseconds (default is 0) Add support for tcp with and without ofi_rxm tcp defaults to tcp;ofi_rxm for libfabric < 1.18 Enable plugin to be built as a dynamic plugin Add support for get_protocol_info to query list of protocols Add support for libfabric log redirection Requires libfabric >= 1.16.0, disabled if FI_LOG_LEVEL is set Add libfabric log subsys (off by default) Bump FI_VERSION to 1.13 when log redirection is supported [NA UCX] Attempt to disable UCX backtrace if UCX_HANDLE_ERRORS is not set Add support for UCP_EP_PARAM_FIELD_LOCAL_SOCK_ADDR With UCX >= 1.13 local src address information can now be specified on client to use specific interface and port Set CM_REUSEADDR by default to enable reuse of existing listener addr after a listener exits abnormally Attempt to reconnect EP if disconnected This concerns cases where a peer would have reappeared after a previous disconnection Add support for get_protocol_info to query list of protocols Enable plugin to be built as a dynamic plugin [NA Test] Update NA test perf to use multi-recv feature Update perf test to use hugepages Add support for multi-targets and add lookup test Install perf tests if BUILD_TESTING_PERF is ON [HG util] Change return type of hg_time_less() to bool Add HG_LOG_WRITE_FUNC() macro to pass func/line info Add also module / no_return parameters to hg_log_write() Add support for hugepage allocations Use isb for cpu_spinwait on aarch64 Add mercury_dl to support dynamically loaded modules Bump HG util version to 4.0.0 Bug fixes [HG] Ensure init info version is compatible with previous versions of the struct Clean up and refactoring fixes Fix race condition in hg_core_forward with debug enabled Simplify RPC map and fix hashing for RPC IDs larger than 32-bit integer Refactor context pools and cleanup Fix potential leak on ack buffer Ensure list of created RPC handles is empty before closing context Bump default number of pre-allocated requests from 256 to 512 to make use of 2M hugepages by default Add extra error checking to prevent class mismatch Fix potential race when sending one-way RPCs to ourself [HG Bulk] Add extra error checking to prevent class mismatch [HG Test] Refactor test_rpc to correctly handle timeout return values Fix overflow of number of target / classes Number of targets was limited to UINT8_MAX [NA OFI] Fix handling of extra caps to not always follow advertised caps Ensure also that extra caps passed are honored by provider Force sockets provider to use shared domains This prevents a performance regression when multiple classes are being used ( FI_THREAD_DOMAIN is therefore disabled for this provider) Refactor unexpected and expected sends, retry of OFI operations, handling of RMA operations Always include FI_DIRECTED_RECV in primary caps Disable use of FI_SOURCE for most providers to reduce lookup overhead Separate code paths for providers that do not support FI_SOURCE Remove insert of FI addr into secondary table if FI_SOURCE is not used Remove NA_OFI_SOURCE_MSG flag that was matching FI_SOURCE_ERR Fix potential refcount race when sharing domains Check domain's optimal MR count if non-zero Fix potential double free of src_addr info Refactor auth key parsing code to build without extension headers Merge latest changes required for opx provider enablement Pass FI_COMPLETION to RMA ops as flag is currently not ignored ( prov/opx tmp fix) Add runtime version check Ensure that runtime version is greater than min version [NA SM] Fix handling of 0-size messages when no receive has been posted Fix issue where an expected msg that is no longer posted arrives In that particular case just drop the incoming msg Add perf warning message for unexpected messages without recv posted [NA UCX] Fix handling of UCS return types to match NA types Enforce src_addr port used for connections to be 0 This fixes a port conflict between listener and connection ports Fix handling of unexpected messages without pre-posted recv [NA BMI] Clean up and fix some coverity warnings [NA MPI] Clean up and fix some coverity warnings [NA Test] Fix NA latency test to ensure recvs are always pre-posted Do not use MPI_Init_thread() if not needed Fix missing return check of na_test_mpi_init() [HG util] Clean up logging and set log root to hg_all hg_all subsys can now be set to turn on logging in all subsystems Set log subsys to hg_all if log level env is set Fixes to support WIN32 builds [CMake] Fix internal/external dependencies that were not correctly set Fix pkg-config entries wrongly set as public/private Ensure VERSION / SOVERSION is not set on MODULE libraries Allow for in-source builds (RPM support) Add DL lib dependency Fix object target linking on CMake < 3.12 Ensure we build with PIC and PIE when available [Examples] Allow examples to build without Boost support Known Issues [NA OFI] [tcp/verbs;ofi_rxm] Using more than 256 peers requires FI_UNIVERSE_SIZE to be set.","title":"Release Notes v2.3.0"},{"location":"releases/CHANGES_v2.3.0/#summary","text":"This version brings bug fixes and updates to our v2.0.0 release.","title":"Summary"},{"location":"releases/CHANGES_v2.3.0/#new-features","text":"[HG/NA] Add HG_Init_opt2() / HG_Core_init_opt2() / NA_Initialize_opt2() to safely pass updated init info while maintaining ABI compatibility between versions Add HG_Get_na_protocol_info() / HG_Free_na_protocol_info() and add hg_info utility for basic listing of protocols [HG] Add support for multi-recv operations (OFI plugin only) Currently disable multi-recv when auto SM is on Posted recv operations are in that case decoupled from pool of RPC handles Add release_input_early init info flag to attempt to release input buffers early once input is decoded Add HG_Release_input_buf() to manually release input buffer. Add also no_multi_recv init info option to force disabling multi-recv Make use of subsys logs ( cls , ctx , addr , rpc , poll ) to control log output Add init info struct versioning Add HG_Context_unpost() / HG_Core_context_unpost() for optional 2-step context shutdown [HG bulk] Update to new logging system through bulk subsys log. [HG proc] Update to new logging system through proc subsys log. [HG Test] Refactor tests to separate perf tests from unit tests Add NA/HG test common library Add hg_rate / hg_bw_write and hg_bw_read perf tests Perf test now supports multi-client / multi-server workloads Add BUILD_TESTING_UNIT and BUILD_TESTING_PERF CMake options [NA] Add support for multi-recv operations Add NA_Msg_multi_recv_unexpected() and na_cb_info_multi_recv_unexpected cb info Add flags parameter to NA_Op_create() and NA_Msg_buf_alloc() Add NA_Has_opt_feature() to query multi recv capability Remove int return type from NA callbacks and return void Remove unused timeout parameter from NA_Trigger() NA_Addr_free() / NA_Mem_handle_free() and NA_Op_destroy() now return void na_mem_handle_t and na_addr_t types no longer include pointer type Add support for dynamically loaded plugins Add NA_PLUGIN_PATH env variable to optionally control plugin loading path (default is NA_INSTALL_PLUGIN_DIR ) Add NA_INSTALL_PLUGIN_DIR variable to control plugin install path (default is lib install path) Add NA_USE_DYNAMIC_PLUGINS CMake option (OFF by default) Add ability to query protocol info from plugins Add NA_Get_protocol_info() / NA_Free_protocol_info() API routines Add na_protocol_info struct to na_types Bump NA library version to 4.0.0 [NA OFI] Add support for multi-recv operations and use FI_MSG Allocate multi-recv buffers using hugepages when available Switch to using fi_senddata() with immediate data for unexpected msgs NA_OFI_UNEXPECTED_TAG_MSG can be set to switch back to former behavior that uses tagged messages instead Remove support for deprecated psm provider Control CQ interrupt signaling with FI_AFFINITY (only used if thread is bound to a single CPU ID) Enable cxi provider to use FI_WAIT_FD Add NA_OFI_OP_RETRY_TIMEOUT and NA_OFI_OP_RETRY_PERIOD Once NA_OFI_OP_RETRY_TIMEOUT milliseconds elapse, retry is stopped and operation is aborted (default is 120000ms) When NA_OFI_OP_RETRY_PERIOD is set, operations are retried only every NA_OFI_OP_RETRY_PERIOD milliseconds (default is 0) Add support for tcp with and without ofi_rxm tcp defaults to tcp;ofi_rxm for libfabric < 1.18 Enable plugin to be built as a dynamic plugin Add support for get_protocol_info to query list of protocols Add support for libfabric log redirection Requires libfabric >= 1.16.0, disabled if FI_LOG_LEVEL is set Add libfabric log subsys (off by default) Bump FI_VERSION to 1.13 when log redirection is supported [NA UCX] Attempt to disable UCX backtrace if UCX_HANDLE_ERRORS is not set Add support for UCP_EP_PARAM_FIELD_LOCAL_SOCK_ADDR With UCX >= 1.13 local src address information can now be specified on client to use specific interface and port Set CM_REUSEADDR by default to enable reuse of existing listener addr after a listener exits abnormally Attempt to reconnect EP if disconnected This concerns cases where a peer would have reappeared after a previous disconnection Add support for get_protocol_info to query list of protocols Enable plugin to be built as a dynamic plugin [NA Test] Update NA test perf to use multi-recv feature Update perf test to use hugepages Add support for multi-targets and add lookup test Install perf tests if BUILD_TESTING_PERF is ON [HG util] Change return type of hg_time_less() to bool Add HG_LOG_WRITE_FUNC() macro to pass func/line info Add also module / no_return parameters to hg_log_write() Add support for hugepage allocations Use isb for cpu_spinwait on aarch64 Add mercury_dl to support dynamically loaded modules Bump HG util version to 4.0.0","title":"New features"},{"location":"releases/CHANGES_v2.3.0/#bug-fixes","text":"[HG] Ensure init info version is compatible with previous versions of the struct Clean up and refactoring fixes Fix race condition in hg_core_forward with debug enabled Simplify RPC map and fix hashing for RPC IDs larger than 32-bit integer Refactor context pools and cleanup Fix potential leak on ack buffer Ensure list of created RPC handles is empty before closing context Bump default number of pre-allocated requests from 256 to 512 to make use of 2M hugepages by default Add extra error checking to prevent class mismatch Fix potential race when sending one-way RPCs to ourself [HG Bulk] Add extra error checking to prevent class mismatch [HG Test] Refactor test_rpc to correctly handle timeout return values Fix overflow of number of target / classes Number of targets was limited to UINT8_MAX [NA OFI] Fix handling of extra caps to not always follow advertised caps Ensure also that extra caps passed are honored by provider Force sockets provider to use shared domains This prevents a performance regression when multiple classes are being used ( FI_THREAD_DOMAIN is therefore disabled for this provider) Refactor unexpected and expected sends, retry of OFI operations, handling of RMA operations Always include FI_DIRECTED_RECV in primary caps Disable use of FI_SOURCE for most providers to reduce lookup overhead Separate code paths for providers that do not support FI_SOURCE Remove insert of FI addr into secondary table if FI_SOURCE is not used Remove NA_OFI_SOURCE_MSG flag that was matching FI_SOURCE_ERR Fix potential refcount race when sharing domains Check domain's optimal MR count if non-zero Fix potential double free of src_addr info Refactor auth key parsing code to build without extension headers Merge latest changes required for opx provider enablement Pass FI_COMPLETION to RMA ops as flag is currently not ignored ( prov/opx tmp fix) Add runtime version check Ensure that runtime version is greater than min version [NA SM] Fix handling of 0-size messages when no receive has been posted Fix issue where an expected msg that is no longer posted arrives In that particular case just drop the incoming msg Add perf warning message for unexpected messages without recv posted [NA UCX] Fix handling of UCS return types to match NA types Enforce src_addr port used for connections to be 0 This fixes a port conflict between listener and connection ports Fix handling of unexpected messages without pre-posted recv [NA BMI] Clean up and fix some coverity warnings [NA MPI] Clean up and fix some coverity warnings [NA Test] Fix NA latency test to ensure recvs are always pre-posted Do not use MPI_Init_thread() if not needed Fix missing return check of na_test_mpi_init() [HG util] Clean up logging and set log root to hg_all hg_all subsys can now be set to turn on logging in all subsystems Set log subsys to hg_all if log level env is set Fixes to support WIN32 builds [CMake] Fix internal/external dependencies that were not correctly set Fix pkg-config entries wrongly set as public/private Ensure VERSION / SOVERSION is not set on MODULE libraries Allow for in-source builds (RPM support) Add DL lib dependency Fix object target linking on CMake < 3.12 Ensure we build with PIC and PIE when available [Examples] Allow examples to build without Boost support","title":"Bug fixes"},{"location":"releases/CHANGES_v2.3.0/#known-issues","text":"[NA OFI] [tcp/verbs;ofi_rxm] Using more than 256 peers requires FI_UNIVERSE_SIZE to be set.","title":"Known Issues"},{"location":"releases/download/","text":"Mercury is distributed under a BSD 3-Clause license . Latest Release Filename Date Size Arch Type mercury-2.3.0.tar.bz2 2023-06-06 679 kB Any Source .bz2 Note that releases can also be accessed through GitHub . Warning Always use the tarballs named mercury-x.tar.bz2 and not the tarballs that GitHub generates from the \"Source code\" link as they do not include mchecksum / kwsys submodules. Tip Mercury packages are also distributed through Spack: Current development distribution The mercury repository is hosted on GitHub at: https://github.com/mercury-hpc/mercury To get the source (read-only access), simply run: git clone --recurse-submodules https://github.com/mercury-hpc/mercury.git","title":"Download"},{"location":"releases/download/#latest-release","text":"Filename Date Size Arch Type mercury-2.3.0.tar.bz2 2023-06-06 679 kB Any Source .bz2 Note that releases can also be accessed through GitHub . Warning Always use the tarballs named mercury-x.tar.bz2 and not the tarballs that GitHub generates from the \"Source code\" link as they do not include mchecksum / kwsys submodules. Tip Mercury packages are also distributed through Spack:","title":"Latest Release"},{"location":"releases/download/#current-development-distribution","text":"The mercury repository is hosted on GitHub at: https://github.com/mercury-hpc/mercury To get the source (read-only access), simply run: git clone --recurse-submodules https://github.com/mercury-hpc/mercury.git","title":"Current development distribution"},{"location":"user/cancel/","text":"Mercury provides two separate types of transfers: RPC and bulk data. We present in this page how on-going operations can be canceled and recovered from a canceled state. Pre-requisites Mercury has been defined as a building block for distributed services. In that context, adding support for cancelation of mercury operations is a primary requirement to provide resiliency and allow services to recover after a fault has occurred (e.g., node failure, etc). This implies reclaiming resources that canceled operations have previously allocated. Mercury defines remote lookup operations as well as two types of transfer operations, RPC and bulk data transfers, which may be interrupted if any of the party involved no longer responds or reaches a time of no response (e.g., on process termination), in which case pending operations must be canceled. Canceling an operation that cannot complete, either because a fault has occurred or a timeout has been reached, is necessary in order to reach proper completion. This documentation assumes that the reader already has knowledge of Mercury and its layers (NA / HG / HG Bulk). Progress model Mercury uses a callback-based mechanism that is built on top of the network abstraction (NA) layer\u2019s callback mechanism. A callback mechanism presents two advantages compared to a traditional request based model: there is no explicit wait() control point; cancelation of operations can be easily done without any additional code branching. Mercury\u2019s progress is directly driven by NA\u2019s progress. When an NA operation completes, an internal callback is pushed to the NA\u2019s completion queue. To make progress on Mercury\u2019s operations, the Mercury layer also internally triggers these NA callback operations. Triggering NA operations may in turn result in the completion of Mercury operations. When these operations complete, the user callback that is associated with these operations is in turn pushed to a completion queue. RPC operations are associated with a handle that is explicitly created by the user and linked to an execution target. The forward call is passed the handle along with a structure holding the input arguments, serializes input arguments, and passes the RPC parameters to the target. On completion, the user callback passed to the forward call is pushed to a completion queue. When an RPC forward operation completes, the get output call is passed that same handle to retrieve output arguments, deserializes them. Note that the handle can be safely re-used after completion (or cancelation) to issue another RPC to the same target. When the user no longer needs to operate on a given handle, it can be explicitly destroyed; a reference count provides operation safety. RPC cancelation In that context, Mercury\u2019s RPC cancelation can be defined so that: No explicit tracking of handles is required (user calls HG_Destroy() ). User callbacks are pushed to the completion queue with a canceled state. Canceled handles can be reused to retry to forward a call to a target. When cancelation is done on an HG operation, cancelation is also done internally on the NA operations that were involved in that HG operation. When this cancelation is successful and the NA operations complete with a canceled state, the HG callbacks associated to the NA operations are pushed to the completion queue. When these callbacks are executed with a canceled state, the actual HG operation is successfully canceled and the state of the operation passed to the callback function indicates that the operation was canceled. Warning It is important to note that cancelation is always local , in the sense that there is no communication involved with a remote party (i.e., it does not rely on the remote party being able to communicate). It is also worth noting that the main focus of our implementation of mercury\u2019s RPC cancelation is the recovery from faults, and not the support of RPC transfer scenarios that rely on cancelation (e.g., optimistic queries in a data service, or higher level protocol operations, which could theoretically also be supported). Xancelation can be supported for the following operations: - HG_Forward() , HG_Respond() (RPC operations) - HG_Bulk_transfer() (Bulk operations) We define the following calls: RPC operations: hg_return_t HG_Cancel ( hg_handle_t handle ); Bulk operations: hg_return_t HG_Bulk_cancel ( hg_op_id_t op_id ); Use Cases Example Cancelation of an RPC operation without bulk transfer involved In the case described below, a handle is created and forwarded to a target. After reaching timeout, the current operation referenced by the handle is canceled. The forward_cb user callback is pushed to the context\u2019s completion queue with a canceled return state. static hg_return_t forward_cb ( const struct hg_cb_info * cb_info ) { if ( cb_info -> ret == HG_CANCELED ) { /* Canceled */ } if ( cb_info -> ret == HG_SUCCESS ) { /* Sucessfully executed */ } } int main ( void ) { hg_handle_t handle ; /* Create new HG handle */ HG_Create ( hg_context , target , rpc_id , & hg_handle ); /* Encode RPC */ ... /* Forward call */ HG_Forward ( hg_handle , forward_cb , forward_cb_args , in_struct ); /* No progress after timeout */ ... /* Cancel operation */ HG_Cancel ( hg_handle ); /* Trigger user callback */ HG_Trigger ( hg_context ); /* Destroy handle */ HG_Destroy ( hg_handle ); } Example Cancelation of an RPC operation with bulk transfer involved In that case, the RPC operation additionally involves a bulk transfer that is initiated by a remote target. A bulk handle that describes the memory region is first created and registered to the NIC. This bulk handle is then serialized along with the RPC arguments, thereby exposing/publishing the memory region to the target. The RPC handle is similarly forwarded to the target. After reaching timeout, the handle is canceled. The forward_cb user callback is pushed to the context\u2019s completion queue with a canceled return state. It is worth noting that when the RPC operation is canceled, the target may be in the process of accessing the exposed bulk region. To guarantee prevention of further remote accesses to the region involved in the bulk transfer, the bulk transfer must be separately destroyed and unpublished (note that this guaranty is only valid if the underlying NA plugin supports it). The bulk handle is part of the input data structure and can be referenced within the RPC handle callback function for the purpose of separately canceling the remote bulk operation. static hg_return_t forward_cb ( const struct hg_cb_info * cb_info ) { if ( cb_info -> ret == HG_CANCELED ) { /* Canceled */ } if ( cb_info -> ret == HG_SUCCESS ) { /* Sucessfully executed */ } } int main ( void ) { hg_handle_t handle ; hg_bulk_t bulk_handle ; /* Create new HG bulk handle */ HG_Bulk_create ( hg_class , buffer_ptrs , buffer_sizes , & hg_bulk_handle ); /* Create new HG handle */ HG_Create ( hg_context , target , rpc_id , & hg_handle ); /* Encode RPC and bulk handle */ in_struct . bulk_handle = bulk_handle ; ... /* Forward call */ HG_Forward ( hg_handle , forward_cb , forward_cb_args , & in_struct ); /* No progress after timeout */ ... /* Cancel operation */ HG_Cancel ( hg_handle ); /* Trigger user callback */ HG_Trigger ( hg_context ); /* Destroy HG handle */ HG_Destroy ( hg_handle ); /* Destroy HG bulk handle */ HG_Bulk_destroy ( hg_bulk_handle ); } Example Cancelation of a bulk operation Bulk cancelation follows a similar model. However, bulk operations are initiated by an RPC target, not by the origin. Bulk operations are identified by an operation ID, which gets freed when the bulk callback is executed. static hg_return_t bulk_cb ( const struct hg_cb_info * cb_info ) { if ( cb_info -> ret == HG_CANCELED ) { /* Canceled */ } if ( cb_info -> ret == HG_SUCCESS ) { /* Sucessfully executed */ } } static hg_return_t rpc_cb ( hg_handle_t handle ) { hg_bulk_t origin_handle , local_handle ; /* Setup handles etc */ ... /* Start the transfer */ HG_bulk_transfer ( context , bulk_cb , bulk_cb_args , HG_BULK_PULL , origin_addr , origin_handle , origin_offset , local_handle , local_offset , size , & op_id ); /* No progress after timeout */ ... /* Cancel operation */ HG_Bulk_cancel ( op_id ); /* Trigger user callback */ HG_Trigger ( context ); } Timeouts and Retries Mercury does not currently support timeouts on operations because this would require tracking handles / operation IDs, which could lead to unnecessary overheads within the Mercury layer. For cases where a timeout is desired, the application can wrap around Mercury calls. The example below shows how one can use the HG request emulation library to issue an RPC call with timeout. Example static hg_return_t forward_cb ( const struct hg_cb_info * cb_info ) { hg_request_t * request = ( hg_request_t * ) cb_info -> arg ; if ( cb_info -> ret == HG_CANCELED ) { /* Canceled */ } if ( cb_info -> ret == HG_SUCCESS ) { /* Sucessfully executed */ } hg_request_complete ( request ); } int main () { hg_handle_t handle ; hg_request_t * request ; /* Create new HG handle */ HG_Create ( hg_context , target , rpc_id , & hg_handle ); /* Encode RPC */ ... /* Create new request */ request = hg_request_create ( request_class ); /* Forward call */ HG_Forward ( hg_handle , forward_cb , request , & in_struct ); /* Wait for completion */ hg_request_wait ( request , timeout , & completed ); if ( ! completed ) HG_Cancel ( hg_handle ); /* Wait for completion */ hg_request_wait ( request , timeout , & completed ); /* Destroy request */ hg_request_destroy ( request ); /* Destroy handle */ HG_Destroy ( hg_handle ); } Cancelation in NA Cancelation of HG operations can only be realized by first supporting cancelation at the NA layer. Cancelation is supported via the following call: na_return_t NA_Cancel ( na_class_t * na_class , na_context_t * context , na_op_id_t op_id ); An additional cancel callback is added to the NA layer that allows plugin developers to support cancelation of non-blocking operations. These include: NA_Msg_send_unexpected() , NA_Msg_recv_unexpected() NA_Msg_send_expected() , NA_Msg_recv_expected() NA_Put() , NA_Get() Cancelation of NA operations is internally progressed and actually completes when internal plugin cancelation has been successfully completed (which may or may not be immediate). When an NA operation is successfully canceled, the internal callback associated to the HG operation is placed onto the NA context\u2019s completion queue with a NA_CANCELED return state. Cancelation is supported for all plugins. It is worth noting that BMI and MPI emulate one-sided operations ( NA_Put() , NA_Get() ) on top of two-sided operations and cancelation for these operations is not yet supported. To emulate these operations, send/recv requests are sent to the remote target which may issue a send in the case of a get, or issue a recv in the case of a put. Cancelation of these operations implies cancelation at the target of the potentially issued send/recv operations, which can only be done using timeouts (remote notification not being an option because the caller has no guaranty that the target is still alive). Cancelation capabilities and execution scenarios where cancelation is supported (i.e., not only for fault tolerance) only depend on the underlying NA plugins and their capabilities to support cancelation of on-going transfers. The BMI plugin for example may not recover well from cancelation of transfers when using TCP and a rendez-vous protocol, as the TCP channel must be entirely flushed before one can do further communication. This may be compromising if other operations were also in the pipe at that time as these operations may consequently fail. Conclusion Adding cancelation to mercury is an important step for building resilient services and a required component for the definition of future high-level mercury features such as group membership and pub/sub services, where fault tolerance must be considered in order to prevent collective failure.","title":"Cancelation and Timeouts"},{"location":"user/cancel/#pre-requisites","text":"Mercury has been defined as a building block for distributed services. In that context, adding support for cancelation of mercury operations is a primary requirement to provide resiliency and allow services to recover after a fault has occurred (e.g., node failure, etc). This implies reclaiming resources that canceled operations have previously allocated. Mercury defines remote lookup operations as well as two types of transfer operations, RPC and bulk data transfers, which may be interrupted if any of the party involved no longer responds or reaches a time of no response (e.g., on process termination), in which case pending operations must be canceled. Canceling an operation that cannot complete, either because a fault has occurred or a timeout has been reached, is necessary in order to reach proper completion. This documentation assumes that the reader already has knowledge of Mercury and its layers (NA / HG / HG Bulk).","title":"Pre-requisites"},{"location":"user/cancel/#progress-model","text":"Mercury uses a callback-based mechanism that is built on top of the network abstraction (NA) layer\u2019s callback mechanism. A callback mechanism presents two advantages compared to a traditional request based model: there is no explicit wait() control point; cancelation of operations can be easily done without any additional code branching. Mercury\u2019s progress is directly driven by NA\u2019s progress. When an NA operation completes, an internal callback is pushed to the NA\u2019s completion queue. To make progress on Mercury\u2019s operations, the Mercury layer also internally triggers these NA callback operations. Triggering NA operations may in turn result in the completion of Mercury operations. When these operations complete, the user callback that is associated with these operations is in turn pushed to a completion queue. RPC operations are associated with a handle that is explicitly created by the user and linked to an execution target. The forward call is passed the handle along with a structure holding the input arguments, serializes input arguments, and passes the RPC parameters to the target. On completion, the user callback passed to the forward call is pushed to a completion queue. When an RPC forward operation completes, the get output call is passed that same handle to retrieve output arguments, deserializes them. Note that the handle can be safely re-used after completion (or cancelation) to issue another RPC to the same target. When the user no longer needs to operate on a given handle, it can be explicitly destroyed; a reference count provides operation safety.","title":"Progress model"},{"location":"user/cancel/#rpc-cancelation","text":"In that context, Mercury\u2019s RPC cancelation can be defined so that: No explicit tracking of handles is required (user calls HG_Destroy() ). User callbacks are pushed to the completion queue with a canceled state. Canceled handles can be reused to retry to forward a call to a target. When cancelation is done on an HG operation, cancelation is also done internally on the NA operations that were involved in that HG operation. When this cancelation is successful and the NA operations complete with a canceled state, the HG callbacks associated to the NA operations are pushed to the completion queue. When these callbacks are executed with a canceled state, the actual HG operation is successfully canceled and the state of the operation passed to the callback function indicates that the operation was canceled. Warning It is important to note that cancelation is always local , in the sense that there is no communication involved with a remote party (i.e., it does not rely on the remote party being able to communicate). It is also worth noting that the main focus of our implementation of mercury\u2019s RPC cancelation is the recovery from faults, and not the support of RPC transfer scenarios that rely on cancelation (e.g., optimistic queries in a data service, or higher level protocol operations, which could theoretically also be supported). Xancelation can be supported for the following operations: - HG_Forward() , HG_Respond() (RPC operations) - HG_Bulk_transfer() (Bulk operations) We define the following calls: RPC operations: hg_return_t HG_Cancel ( hg_handle_t handle ); Bulk operations: hg_return_t HG_Bulk_cancel ( hg_op_id_t op_id );","title":"RPC cancelation"},{"location":"user/cancel/#use-cases","text":"Example Cancelation of an RPC operation without bulk transfer involved In the case described below, a handle is created and forwarded to a target. After reaching timeout, the current operation referenced by the handle is canceled. The forward_cb user callback is pushed to the context\u2019s completion queue with a canceled return state. static hg_return_t forward_cb ( const struct hg_cb_info * cb_info ) { if ( cb_info -> ret == HG_CANCELED ) { /* Canceled */ } if ( cb_info -> ret == HG_SUCCESS ) { /* Sucessfully executed */ } } int main ( void ) { hg_handle_t handle ; /* Create new HG handle */ HG_Create ( hg_context , target , rpc_id , & hg_handle ); /* Encode RPC */ ... /* Forward call */ HG_Forward ( hg_handle , forward_cb , forward_cb_args , in_struct ); /* No progress after timeout */ ... /* Cancel operation */ HG_Cancel ( hg_handle ); /* Trigger user callback */ HG_Trigger ( hg_context ); /* Destroy handle */ HG_Destroy ( hg_handle ); } Example Cancelation of an RPC operation with bulk transfer involved In that case, the RPC operation additionally involves a bulk transfer that is initiated by a remote target. A bulk handle that describes the memory region is first created and registered to the NIC. This bulk handle is then serialized along with the RPC arguments, thereby exposing/publishing the memory region to the target. The RPC handle is similarly forwarded to the target. After reaching timeout, the handle is canceled. The forward_cb user callback is pushed to the context\u2019s completion queue with a canceled return state. It is worth noting that when the RPC operation is canceled, the target may be in the process of accessing the exposed bulk region. To guarantee prevention of further remote accesses to the region involved in the bulk transfer, the bulk transfer must be separately destroyed and unpublished (note that this guaranty is only valid if the underlying NA plugin supports it). The bulk handle is part of the input data structure and can be referenced within the RPC handle callback function for the purpose of separately canceling the remote bulk operation. static hg_return_t forward_cb ( const struct hg_cb_info * cb_info ) { if ( cb_info -> ret == HG_CANCELED ) { /* Canceled */ } if ( cb_info -> ret == HG_SUCCESS ) { /* Sucessfully executed */ } } int main ( void ) { hg_handle_t handle ; hg_bulk_t bulk_handle ; /* Create new HG bulk handle */ HG_Bulk_create ( hg_class , buffer_ptrs , buffer_sizes , & hg_bulk_handle ); /* Create new HG handle */ HG_Create ( hg_context , target , rpc_id , & hg_handle ); /* Encode RPC and bulk handle */ in_struct . bulk_handle = bulk_handle ; ... /* Forward call */ HG_Forward ( hg_handle , forward_cb , forward_cb_args , & in_struct ); /* No progress after timeout */ ... /* Cancel operation */ HG_Cancel ( hg_handle ); /* Trigger user callback */ HG_Trigger ( hg_context ); /* Destroy HG handle */ HG_Destroy ( hg_handle ); /* Destroy HG bulk handle */ HG_Bulk_destroy ( hg_bulk_handle ); } Example Cancelation of a bulk operation Bulk cancelation follows a similar model. However, bulk operations are initiated by an RPC target, not by the origin. Bulk operations are identified by an operation ID, which gets freed when the bulk callback is executed. static hg_return_t bulk_cb ( const struct hg_cb_info * cb_info ) { if ( cb_info -> ret == HG_CANCELED ) { /* Canceled */ } if ( cb_info -> ret == HG_SUCCESS ) { /* Sucessfully executed */ } } static hg_return_t rpc_cb ( hg_handle_t handle ) { hg_bulk_t origin_handle , local_handle ; /* Setup handles etc */ ... /* Start the transfer */ HG_bulk_transfer ( context , bulk_cb , bulk_cb_args , HG_BULK_PULL , origin_addr , origin_handle , origin_offset , local_handle , local_offset , size , & op_id ); /* No progress after timeout */ ... /* Cancel operation */ HG_Bulk_cancel ( op_id ); /* Trigger user callback */ HG_Trigger ( context ); }","title":"Use Cases"},{"location":"user/cancel/#timeouts-and-retries","text":"Mercury does not currently support timeouts on operations because this would require tracking handles / operation IDs, which could lead to unnecessary overheads within the Mercury layer. For cases where a timeout is desired, the application can wrap around Mercury calls. The example below shows how one can use the HG request emulation library to issue an RPC call with timeout. Example static hg_return_t forward_cb ( const struct hg_cb_info * cb_info ) { hg_request_t * request = ( hg_request_t * ) cb_info -> arg ; if ( cb_info -> ret == HG_CANCELED ) { /* Canceled */ } if ( cb_info -> ret == HG_SUCCESS ) { /* Sucessfully executed */ } hg_request_complete ( request ); } int main () { hg_handle_t handle ; hg_request_t * request ; /* Create new HG handle */ HG_Create ( hg_context , target , rpc_id , & hg_handle ); /* Encode RPC */ ... /* Create new request */ request = hg_request_create ( request_class ); /* Forward call */ HG_Forward ( hg_handle , forward_cb , request , & in_struct ); /* Wait for completion */ hg_request_wait ( request , timeout , & completed ); if ( ! completed ) HG_Cancel ( hg_handle ); /* Wait for completion */ hg_request_wait ( request , timeout , & completed ); /* Destroy request */ hg_request_destroy ( request ); /* Destroy handle */ HG_Destroy ( hg_handle ); }","title":"Timeouts and Retries"},{"location":"user/cancel/#cancelation-in-na","text":"Cancelation of HG operations can only be realized by first supporting cancelation at the NA layer. Cancelation is supported via the following call: na_return_t NA_Cancel ( na_class_t * na_class , na_context_t * context , na_op_id_t op_id ); An additional cancel callback is added to the NA layer that allows plugin developers to support cancelation of non-blocking operations. These include: NA_Msg_send_unexpected() , NA_Msg_recv_unexpected() NA_Msg_send_expected() , NA_Msg_recv_expected() NA_Put() , NA_Get() Cancelation of NA operations is internally progressed and actually completes when internal plugin cancelation has been successfully completed (which may or may not be immediate). When an NA operation is successfully canceled, the internal callback associated to the HG operation is placed onto the NA context\u2019s completion queue with a NA_CANCELED return state. Cancelation is supported for all plugins. It is worth noting that BMI and MPI emulate one-sided operations ( NA_Put() , NA_Get() ) on top of two-sided operations and cancelation for these operations is not yet supported. To emulate these operations, send/recv requests are sent to the remote target which may issue a send in the case of a get, or issue a recv in the case of a put. Cancelation of these operations implies cancelation at the target of the potentially issued send/recv operations, which can only be done using timeouts (remote notification not being an option because the caller has no guaranty that the target is still alive). Cancelation capabilities and execution scenarios where cancelation is supported (i.e., not only for fault tolerance) only depend on the underlying NA plugins and their capabilities to support cancelation of on-going transfers. The BMI plugin for example may not recover well from cancelation of transfers when using TCP and a rendez-vous protocol, as the TCP channel must be entirely flushed before one can do further communication. This may be compromising if other operations were also in the pipe at that time as these operations may consequently fail.","title":"Cancelation in NA"},{"location":"user/cancel/#conclusion","text":"Adding cancelation to mercury is an important step for building resilient services and a required component for the definition of future high-level mercury features such as group membership and pub/sub services, where fault tolerance must be considered in order to prevent collective failure.","title":"Conclusion"},{"location":"user/checksum/","text":"Note Mercury users should generally not have to directly use the MChecksum library as checksumming may be done within Mercury for small messages. For large payloads, however, if checksums are desired, users should then be responsible for calling MChecksum routines on the buffers. Mchecksum is a library created in the context of Mercury for checksumming RPC headers as well as RPC function arguments. In Mercury, checksums are not computed for bulk data transfers and it is left upon the user to decide whether to verify transfers or not. Because mchecksum is a separate library, it can be independently used by applications to verify data integrity. Mchecksum provides a simple interface and uses a system of plugins to abstract and provide various hash methods. Interface A checksum object is created using the mchecksum_init() function with a valid hash method (see the available plugins section for a list of plugins and the hash_method format). int mchecksum_init ( const char * hash_method , mchecksum_object_t * checksum ); The checksum object is destroyed with a call to mchecksum_destroy() . int mchecksum_destroy ( mchecksum_object_t checksum ); The checksum can be reset with mchecksum_reset() , which prevents an extra allocation when the checksum needs to be re-used. int mchecksum_reset ( mchecksum_object_t checksum ); The size of the checksum can be queried using the mchecksum_get_size() call. size_t mchecksum_get_size ( mchecksum_object_t checksum ); The computed checksum hash can be retrieved with a call to mchecksum_get() . If MCHECKSUM_FINALIZE is passed, the checksum is finalized and no more data can be added to that checksum, the only valid calls to follow are either mchecksum_reset() or mchecksum_destroy() . If MCHECKSUM_NOFINALIZE is passed, more data can be later added to this checksum. int mchecksum_get ( mchecksum_object_t checksum , void * buf , size_t size , int finalize ); The checksum is computed on a given piece of data by using the mchecksum_update() call. Note again that incremental update is allowed unless mchecksum_get() has been called with the MCHECKSUM_FINALIZE parameter. int mchecksum_update ( mchecksum_object_t checksum , const void * data , size_t size ); Available Plugins Below is a list of the currently available plugins as well as corresponding initialization strings that must be passed to the mchecksum_init() call. Note that CRC32 and ADLER32 are available through the ZLIB library and CRC32C is available with and without SSE4.2 optimization. When using the ISA-L library, improved performance can be achieved for CRC16, CRC32C and CRC64 by using the PCLMULQDQ CPU instruction (when supported). Plugin Initialization Format CRC16 crc16 CRC32 crc32 CRC32C crc32c CRC64 crc64 ADLER32 adler32 Performance Comparison Below is a performance comparison of the hash methods defined through mchecksum, using non-SSE/SSE/ISA-L (v2.24.0) versions. Example The example below is given for illustration. #include <mchecksum.h> #include <stdlib.h> #define BUF_SIZE 256 int main ( int argc , char * argv []) { unsigned char buf [ BUF_SIZE ]; unsigned int i ; mchecksum_object_t checksum ; void * hash = NULL ; size_t hash_size ; int ret = EXIT_SUCCESS ; /* Initialize buf */ for ( i = 0 ; i < BUF_SIZE ; i ++ ) buf [ i ] = i ; /* Initialize checksum */ mchecksum_init ( \"crc32c\" , & checksum ); /* Update checksum */ mchecksum_update ( checksum , buf , BUF_SIZE ); /* Get size of checksum and allocate buffer to store checksum */ hash_size = mchecksum_get_size ( checksum ); hash = malloc ( hash_size ); /* Get checksum and finalize it */ mchecksum_get ( checksum , hash , hash_size , MCHECKSUM_FINALIZE ); /* Use checksum */ ... /* Destroy checksums and free hash buffers */ mchecksum_destroy ( checksum ); free ( hash ); return ret ; }","title":"MChecksum Library"},{"location":"user/checksum/#interface","text":"A checksum object is created using the mchecksum_init() function with a valid hash method (see the available plugins section for a list of plugins and the hash_method format). int mchecksum_init ( const char * hash_method , mchecksum_object_t * checksum ); The checksum object is destroyed with a call to mchecksum_destroy() . int mchecksum_destroy ( mchecksum_object_t checksum ); The checksum can be reset with mchecksum_reset() , which prevents an extra allocation when the checksum needs to be re-used. int mchecksum_reset ( mchecksum_object_t checksum ); The size of the checksum can be queried using the mchecksum_get_size() call. size_t mchecksum_get_size ( mchecksum_object_t checksum ); The computed checksum hash can be retrieved with a call to mchecksum_get() . If MCHECKSUM_FINALIZE is passed, the checksum is finalized and no more data can be added to that checksum, the only valid calls to follow are either mchecksum_reset() or mchecksum_destroy() . If MCHECKSUM_NOFINALIZE is passed, more data can be later added to this checksum. int mchecksum_get ( mchecksum_object_t checksum , void * buf , size_t size , int finalize ); The checksum is computed on a given piece of data by using the mchecksum_update() call. Note again that incremental update is allowed unless mchecksum_get() has been called with the MCHECKSUM_FINALIZE parameter. int mchecksum_update ( mchecksum_object_t checksum , const void * data , size_t size );","title":"Interface"},{"location":"user/checksum/#available-plugins","text":"Below is a list of the currently available plugins as well as corresponding initialization strings that must be passed to the mchecksum_init() call. Note that CRC32 and ADLER32 are available through the ZLIB library and CRC32C is available with and without SSE4.2 optimization. When using the ISA-L library, improved performance can be achieved for CRC16, CRC32C and CRC64 by using the PCLMULQDQ CPU instruction (when supported). Plugin Initialization Format CRC16 crc16 CRC32 crc32 CRC32C crc32c CRC64 crc64 ADLER32 adler32","title":"Available Plugins"},{"location":"user/checksum/#performance-comparison","text":"Below is a performance comparison of the hash methods defined through mchecksum, using non-SSE/SSE/ISA-L (v2.24.0) versions.","title":"Performance Comparison"},{"location":"user/checksum/#example","text":"The example below is given for illustration. #include <mchecksum.h> #include <stdlib.h> #define BUF_SIZE 256 int main ( int argc , char * argv []) { unsigned char buf [ BUF_SIZE ]; unsigned int i ; mchecksum_object_t checksum ; void * hash = NULL ; size_t hash_size ; int ret = EXIT_SUCCESS ; /* Initialize buf */ for ( i = 0 ; i < BUF_SIZE ; i ++ ) buf [ i ] = i ; /* Initialize checksum */ mchecksum_init ( \"crc32c\" , & checksum ); /* Update checksum */ mchecksum_update ( checksum , buf , BUF_SIZE ); /* Get size of checksum and allocate buffer to store checksum */ hash_size = mchecksum_get_size ( checksum ); hash = malloc ( hash_size ); /* Get checksum and finalize it */ mchecksum_get ( checksum , hash , hash_size , MCHECKSUM_FINALIZE ); /* Use checksum */ ... /* Destroy checksums and free hash buffers */ mchecksum_destroy ( checksum ); free ( hash ); return ret ; }","title":"Example"},{"location":"user/drc/","text":"The goal of this page is to present minimal usage of Cray Dynamic RDMA Credential (DRC) mechanism when using mercury and libfabric. Design notes on DRC were presented at CUG in this paper . DRC must be used on Cray systems with Aries interconnect in order to establish cross-job communication (normally two separate jobs are protected by protection domains and communication may only occur within that domain). Client-Server Example In this example we show how a server can grant access to a client job. The first step is for the server to acquire a new DRC token by calling: uint32_t credential ; drc_acquire ( & credential , 0 ); On the client, the first step is to usually retrieve the WLM ID by calling: uint32_t wlm_id = drc_get_wlm_id (); The WLM ID should then be communicated to the server (using TCP for example), which can then grant access to the client by doing: drc_grant ( credential , wlm_id , DRC_FLAGS_TARGET_WLM ); From there, the server can simply pass around its credential back to the client. Both the client and server should then use that credential to retrieve a cookie that will then be used to communicate within the domain: drc_info_handle_t credential_info ; uint32_t cookie ; drc_access ( credential , 0 , & credential_info ); cookie = drc_get_first_cookie ( credential_info ); The cookie can then be given to Mercury through the init info struct: char auth_key [ 16 ]; struct hg_init_info init_info = HG_INIT_INFO_INITIALIZER ; sprintf ( auth_key , \"%\" PRIu32 , cookie ); init_info . na_init_info . auth_key = auth_key ; hg_class = HG_Init_opt (... /* init string */ , ... /* listen */ , & init_info ); Note that eventually the DRC resources must also be released by doing: drc_release_local ( & credential_info ); drc_release ( credential , 0 );","title":"Using Cray DRC credentials"},{"location":"user/drc/#client-server-example","text":"In this example we show how a server can grant access to a client job. The first step is for the server to acquire a new DRC token by calling: uint32_t credential ; drc_acquire ( & credential , 0 ); On the client, the first step is to usually retrieve the WLM ID by calling: uint32_t wlm_id = drc_get_wlm_id (); The WLM ID should then be communicated to the server (using TCP for example), which can then grant access to the client by doing: drc_grant ( credential , wlm_id , DRC_FLAGS_TARGET_WLM ); From there, the server can simply pass around its credential back to the client. Both the client and server should then use that credential to retrieve a cookie that will then be used to communicate within the domain: drc_info_handle_t credential_info ; uint32_t cookie ; drc_access ( credential , 0 , & credential_info ); cookie = drc_get_first_cookie ( credential_info ); The cookie can then be given to Mercury through the init info struct: char auth_key [ 16 ]; struct hg_init_info init_info = HG_INIT_INFO_INITIALIZER ; sprintf ( auth_key , \"%\" PRIu32 , cookie ); init_info . na_init_info . auth_key = auth_key ; hg_class = HG_Init_opt (... /* init string */ , ... /* listen */ , & init_info ); Note that eventually the DRC resources must also be released by doing: drc_release_local ( & credential_info ); drc_release ( credential , 0 );","title":"Client-Server Example"},{"location":"user/hg/","text":"The RPC layer is used for sending and receiving RPCs. RPC arguments are generally small. For handling larger arguments, this layer is complemented with a bulk interface that is covered in the next section. HG Interface The HG interface directly builds on top of the NA interface. Sending an RPC generally results in two NA operations being posted: an expected receive for the response and an unexpected send for the RPC request. The entire interface is therefore non-blocking with a goal of asynchronously executing RPCs on a given target. In order to achieve that, the HG interface provides the following primitives: target address lookup , RPC registration , RPC execution , progress and cancelation . Initialization To initialize the HG RPC interface, two options are available, either by using the default HG_Init() function and specifying an init info string as described in the NA plugin section : hg_class_t * HG_Init ( const char * info_string , hg_bool_t listen ); Or by using the HG_Init_opt() function, which allows for passing extra options. Option Description na_init_info See NA initialization options . na_class Enables initialization from an existing NA class. request_post_init Controls the initial number of requests that are posted on context creation. Default value is: 256 request_post_incr Controls the number of requests that are incrementally posted when the initial number of requests is exhausted. Default value is: 256 auto_sm Controls whether shared-memory should be automatically used when origin and target share the same node. sm_info_string Overrides default init string for NA SM plugin. checksum_level Control checksum level on RPC (none by default). no_bulk_eager Prevents small bulk data from being automatically embedded along with the RPC request. no_loopback Disables internal loopback interface that enables forwarding of RPC to self addresses. stats Print RPC stats at exit. no_multi_recv Disable use of multi_recv feature ( ofi plugin only) release_input_early Attempt to release input buffers as early as possible once HG_Get_input() has been called. struct hg_init_info { struct na_init_info na_init_info ; na_class_t * na_class ; hg_uint32_t request_post_init ; hg_uint32_t request_post_incr ; hg_bool_t auto_sm ; const char * sm_info_string ; hg_checksum_level_t checksum_level ; hg_bool_t no_bulk_eager ; hg_bool_t no_loopback ; hg_bool_t stats ; hg_bool_t no_multi_recv ; hg_bool_t release_input_early ; }; hg_class_t * HG_Init_opt2 ( const char * na_info_string , hg_bool_t na_listen , unsigned int version , const struct hg_init_info * hg_init_info ); Similar to the NA layer, the HG_Init() call results in the creation of a new hg_class_t object. The hg_class_t object can later be released after a call to: hg_return_t HG_Finalize ( hg_class_t * hg_class ); Once the interface has been initialized, a context of execution must be created, which (similar to the NA layer) internally associates a specific queue to the operations that will complete: hg_context_t * HG_Context_create ( hg_class_t * hg_class ); It can then be destroyed using: hg_return_t HG_Context_destroy ( hg_context_t * context ); Registration Before an RPC can be sent, the HG class needs a way of identifying it so that a callback corresponding to that RPC can be executed on the target. Additionally, the functions to serialize and deserialize the function arguments associated to that RPC must be provided. This is done through the HG_Register_name() function. Note that this step can be slightly simplified by using the MERCURY_REGISTER macro. Registration must be done on both the origin and the target with the same func_name identifier. Alternatively HG_Register() can be used to pass a user-defined unique identifier and avoid internal hashing of the provided function name. typedef hg_return_t ( * hg_proc_cb_t )( hg_proc_t proc , void * data ); typedef hg_return_t ( * hg_rpc_cb_t )( hg_handle_t handle ); hg_id_t HG_Register_name ( hg_class_t * hg_class , const char * func_name , hg_proc_cb_t in_proc_cb , hg_proc_cb_t out_proc_cb , hg_rpc_cb_t rpc_cb ); It is also possible (but not necessary) to deregister an existing RPC ID, in the case where an RPC should no longer be received by using: hg_return_t HG_Deregister ( hg_class_t * hg_class , hg_id_t id ); In the case where an RPC does not require a response, one can indicate that no response is expected (and therefore avoid waiting for a message to be sent back) by using the following call (on an already registered RPC): hg_return_t HG_Registered_disable_response ( hg_class_t * hg_class , hg_id_t id , hg_bool_t disable ); Target Address Lookup As mentioned in the overview section, there is no real distinction between client and server since it may be desirable for a client to also act as a server for other processes. Therefore, the interface only uses the distinction of origin and target . Similar to NA's API, the first step consists of retrieving the target's address, this can be done by calling on the target: hg_return_t HG_Addr_self ( hg_class_t * hg_class , hg_addr_t * addr ); And then convert it to string using: hg_return_t HG_Addr_to_string ( hg_class_t * hg_class , char * buf , hg_size_t * buf_size , hg_addr_t addr ); The string can then be exchanged back with the origin through out-of-band mechanisms (e.g., using a file, etc), which can then look the target up using the function: hg_return_t HG_Addr_lookup ( hg_class_t * hg_class , const char * name , hg_addr_t * addr ); All addresses must then be freed using: hg_return_t HG_Addr_free ( hg_class_t * hg_class , hg_addr_t addr ); RPC Execution Executing an RPC is generally composed of two parts, one on the origin, which will send the RPC request and receive a response, one on the target, which will receive the request, execute it and send a response back. Origin Using the RPC ID defined after a call to HG_Register() , one can use the HG_Create() call to define a new hg_handle_t object that can be used (and later re-used without reallocating resources) to set/get input/output arguments. hg_return_t HG_Create ( hg_context_t * context , hg_addr_t addr , hg_id_t id , hg_handle_t * handle ); This handle can be destroyed with HG_Destroy() \u2014and a reference count prevents resources from being released while the handle is still in use. hg_return_t HG_Destroy ( hg_handle_t handle ); The second step is to pack the input arguments within a structure, for which a serialization function is provided with the HG_Register() call. The HG_Forward() function can then be used to send that structure (which describes the input arguments). This function is non-blocking. When it completes, the associated callback can be executed by calling HG_Trigger() . typedef hg_return_t ( * hg_cb_t )( const struct hg_cb_info * callback_info ); hg_return_t HG_Forward ( hg_handle_t handle , hg_cb_t callback , void * arg , void * in_struct ); When HG_Forward() completes (i.e., when the user callback can be triggered), the RPC has been remotely executed and a response with the output results has been sent back. This output can then be retrieved (usually within the callback) with the following function: hg_return_t HG_Get_output ( hg_handle_t handle , void * out_struct ); Retrieving the output may result in the creation of memory objects, which must then be released by calling: hg_return_t HG_Free_output ( hg_handle_t handle , void * out_struct ); To be safe and if necessary, one must make a copy of the results before calling HG_Free_output() . Note that in the case of an RPC with no response, completion occurs after the RPC has been successfully sent (i.e., there is no output to retrieve). Target On the target, the RPC callback function passed to the HG_Register() call must be defined. typedef hg_return_t ( * hg_rpc_cb_t )( hg_handle_t handle ); Whenever a new RPC is received, that callback will be invoked. The input arguments can be retrieved with: hg_return_t HG_Get_input ( hg_handle_t handle , void * in_struct ); Retrieving the input may result in the creation of memory objects, which must then be released by calling: hg_return_t HG_Free_input ( hg_handle_t handle , void * in_struct ); When the input has been retrieved, the arguments contained in the input structure can be passed to the actual function call. When the execution is done, an output structure can be filled with the return value and/or the output arguments of the function. It can then be sent back using: typedef hg_return_t ( * hg_cb_t )( const struct hg_cb_info * callback_info ); hg_return_t HG_Respond ( hg_handle_t handle , hg_cb_t callback , void * arg , void * out_struct ); This call is also non-blocking. When it completes, the associated callback is placed onto a completion queue. It can then be triggered after a call to HG_Trigger() . Note that in the case of an RPC with no response, calling HG_Respond() will return an error. Progress and Cancelation Mercury uses a callback model. Callbacks are passed to non-blocking functions and are pushed to the context's completion queue when the operation completes. Explicit progress is made by calling HG_Progress() . HG_Progress() returns when an operation completes, is in the completion queue or timeout is reached. hg_return_t HG_Progress ( hg_context_t * context , unsigned int timeout ); When an operation completes, calling HG_Trigger() allows the callback execution to be separately controlled from the main progress loop. Warning Operations may complete with an HG_SUCCESS return code or with an error return code if failure occured after the operation was submitted. The ret field from the hg_cb_info struct should therefore always be checked for potential errors. hg_return_t HG_Trigger ( hg_context_t * context , unsigned int timeout , unsigned int max_count , unsigned int * actual_count ); In some cases, one may want to call HG_Progress() then HG_Trigger() or have them execute in parallel by using separate threads. When it is desirable to cancel an HG operation, one can call HG_Cancel() on a HG handle to cancel an on-going HG_Forward() or HG_Respond() operation. Please refer to this page for additional details regarding cancellation of operations and handling of timeouts. hg_return_t HG_Cancel ( hg_handle_t handle ); Cancelation is always asynchronous. When/if the operation is successfully canceled, it will be pushed to the completion queue and the callback ret value will set with an HG_CANCELED error return code.","title":"Mercury RPC Layer"},{"location":"user/hg/#hg-interface","text":"The HG interface directly builds on top of the NA interface. Sending an RPC generally results in two NA operations being posted: an expected receive for the response and an unexpected send for the RPC request. The entire interface is therefore non-blocking with a goal of asynchronously executing RPCs on a given target. In order to achieve that, the HG interface provides the following primitives: target address lookup , RPC registration , RPC execution , progress and cancelation .","title":"HG Interface"},{"location":"user/hg/#initialization","text":"To initialize the HG RPC interface, two options are available, either by using the default HG_Init() function and specifying an init info string as described in the NA plugin section : hg_class_t * HG_Init ( const char * info_string , hg_bool_t listen ); Or by using the HG_Init_opt() function, which allows for passing extra options. Option Description na_init_info See NA initialization options . na_class Enables initialization from an existing NA class. request_post_init Controls the initial number of requests that are posted on context creation. Default value is: 256 request_post_incr Controls the number of requests that are incrementally posted when the initial number of requests is exhausted. Default value is: 256 auto_sm Controls whether shared-memory should be automatically used when origin and target share the same node. sm_info_string Overrides default init string for NA SM plugin. checksum_level Control checksum level on RPC (none by default). no_bulk_eager Prevents small bulk data from being automatically embedded along with the RPC request. no_loopback Disables internal loopback interface that enables forwarding of RPC to self addresses. stats Print RPC stats at exit. no_multi_recv Disable use of multi_recv feature ( ofi plugin only) release_input_early Attempt to release input buffers as early as possible once HG_Get_input() has been called. struct hg_init_info { struct na_init_info na_init_info ; na_class_t * na_class ; hg_uint32_t request_post_init ; hg_uint32_t request_post_incr ; hg_bool_t auto_sm ; const char * sm_info_string ; hg_checksum_level_t checksum_level ; hg_bool_t no_bulk_eager ; hg_bool_t no_loopback ; hg_bool_t stats ; hg_bool_t no_multi_recv ; hg_bool_t release_input_early ; }; hg_class_t * HG_Init_opt2 ( const char * na_info_string , hg_bool_t na_listen , unsigned int version , const struct hg_init_info * hg_init_info ); Similar to the NA layer, the HG_Init() call results in the creation of a new hg_class_t object. The hg_class_t object can later be released after a call to: hg_return_t HG_Finalize ( hg_class_t * hg_class ); Once the interface has been initialized, a context of execution must be created, which (similar to the NA layer) internally associates a specific queue to the operations that will complete: hg_context_t * HG_Context_create ( hg_class_t * hg_class ); It can then be destroyed using: hg_return_t HG_Context_destroy ( hg_context_t * context );","title":"Initialization"},{"location":"user/hg/#registration","text":"Before an RPC can be sent, the HG class needs a way of identifying it so that a callback corresponding to that RPC can be executed on the target. Additionally, the functions to serialize and deserialize the function arguments associated to that RPC must be provided. This is done through the HG_Register_name() function. Note that this step can be slightly simplified by using the MERCURY_REGISTER macro. Registration must be done on both the origin and the target with the same func_name identifier. Alternatively HG_Register() can be used to pass a user-defined unique identifier and avoid internal hashing of the provided function name. typedef hg_return_t ( * hg_proc_cb_t )( hg_proc_t proc , void * data ); typedef hg_return_t ( * hg_rpc_cb_t )( hg_handle_t handle ); hg_id_t HG_Register_name ( hg_class_t * hg_class , const char * func_name , hg_proc_cb_t in_proc_cb , hg_proc_cb_t out_proc_cb , hg_rpc_cb_t rpc_cb ); It is also possible (but not necessary) to deregister an existing RPC ID, in the case where an RPC should no longer be received by using: hg_return_t HG_Deregister ( hg_class_t * hg_class , hg_id_t id ); In the case where an RPC does not require a response, one can indicate that no response is expected (and therefore avoid waiting for a message to be sent back) by using the following call (on an already registered RPC): hg_return_t HG_Registered_disable_response ( hg_class_t * hg_class , hg_id_t id , hg_bool_t disable );","title":"Registration"},{"location":"user/hg/#target-address-lookup","text":"As mentioned in the overview section, there is no real distinction between client and server since it may be desirable for a client to also act as a server for other processes. Therefore, the interface only uses the distinction of origin and target . Similar to NA's API, the first step consists of retrieving the target's address, this can be done by calling on the target: hg_return_t HG_Addr_self ( hg_class_t * hg_class , hg_addr_t * addr ); And then convert it to string using: hg_return_t HG_Addr_to_string ( hg_class_t * hg_class , char * buf , hg_size_t * buf_size , hg_addr_t addr ); The string can then be exchanged back with the origin through out-of-band mechanisms (e.g., using a file, etc), which can then look the target up using the function: hg_return_t HG_Addr_lookup ( hg_class_t * hg_class , const char * name , hg_addr_t * addr ); All addresses must then be freed using: hg_return_t HG_Addr_free ( hg_class_t * hg_class , hg_addr_t addr );","title":"Target Address Lookup"},{"location":"user/hg/#rpc-execution","text":"Executing an RPC is generally composed of two parts, one on the origin, which will send the RPC request and receive a response, one on the target, which will receive the request, execute it and send a response back.","title":"RPC Execution"},{"location":"user/hg/#origin","text":"Using the RPC ID defined after a call to HG_Register() , one can use the HG_Create() call to define a new hg_handle_t object that can be used (and later re-used without reallocating resources) to set/get input/output arguments. hg_return_t HG_Create ( hg_context_t * context , hg_addr_t addr , hg_id_t id , hg_handle_t * handle ); This handle can be destroyed with HG_Destroy() \u2014and a reference count prevents resources from being released while the handle is still in use. hg_return_t HG_Destroy ( hg_handle_t handle ); The second step is to pack the input arguments within a structure, for which a serialization function is provided with the HG_Register() call. The HG_Forward() function can then be used to send that structure (which describes the input arguments). This function is non-blocking. When it completes, the associated callback can be executed by calling HG_Trigger() . typedef hg_return_t ( * hg_cb_t )( const struct hg_cb_info * callback_info ); hg_return_t HG_Forward ( hg_handle_t handle , hg_cb_t callback , void * arg , void * in_struct ); When HG_Forward() completes (i.e., when the user callback can be triggered), the RPC has been remotely executed and a response with the output results has been sent back. This output can then be retrieved (usually within the callback) with the following function: hg_return_t HG_Get_output ( hg_handle_t handle , void * out_struct ); Retrieving the output may result in the creation of memory objects, which must then be released by calling: hg_return_t HG_Free_output ( hg_handle_t handle , void * out_struct ); To be safe and if necessary, one must make a copy of the results before calling HG_Free_output() . Note that in the case of an RPC with no response, completion occurs after the RPC has been successfully sent (i.e., there is no output to retrieve).","title":"Origin"},{"location":"user/hg/#target","text":"On the target, the RPC callback function passed to the HG_Register() call must be defined. typedef hg_return_t ( * hg_rpc_cb_t )( hg_handle_t handle ); Whenever a new RPC is received, that callback will be invoked. The input arguments can be retrieved with: hg_return_t HG_Get_input ( hg_handle_t handle , void * in_struct ); Retrieving the input may result in the creation of memory objects, which must then be released by calling: hg_return_t HG_Free_input ( hg_handle_t handle , void * in_struct ); When the input has been retrieved, the arguments contained in the input structure can be passed to the actual function call. When the execution is done, an output structure can be filled with the return value and/or the output arguments of the function. It can then be sent back using: typedef hg_return_t ( * hg_cb_t )( const struct hg_cb_info * callback_info ); hg_return_t HG_Respond ( hg_handle_t handle , hg_cb_t callback , void * arg , void * out_struct ); This call is also non-blocking. When it completes, the associated callback is placed onto a completion queue. It can then be triggered after a call to HG_Trigger() . Note that in the case of an RPC with no response, calling HG_Respond() will return an error.","title":"Target"},{"location":"user/hg/#progress-and-cancelation","text":"Mercury uses a callback model. Callbacks are passed to non-blocking functions and are pushed to the context's completion queue when the operation completes. Explicit progress is made by calling HG_Progress() . HG_Progress() returns when an operation completes, is in the completion queue or timeout is reached. hg_return_t HG_Progress ( hg_context_t * context , unsigned int timeout ); When an operation completes, calling HG_Trigger() allows the callback execution to be separately controlled from the main progress loop. Warning Operations may complete with an HG_SUCCESS return code or with an error return code if failure occured after the operation was submitted. The ret field from the hg_cb_info struct should therefore always be checked for potential errors. hg_return_t HG_Trigger ( hg_context_t * context , unsigned int timeout , unsigned int max_count , unsigned int * actual_count ); In some cases, one may want to call HG_Progress() then HG_Trigger() or have them execute in parallel by using separate threads. When it is desirable to cancel an HG operation, one can call HG_Cancel() on a HG handle to cancel an on-going HG_Forward() or HG_Respond() operation. Please refer to this page for additional details regarding cancellation of operations and handling of timeouts. hg_return_t HG_Cancel ( hg_handle_t handle ); Cancelation is always asynchronous. When/if the operation is successfully canceled, it will be pushed to the completion queue and the callback ret value will set with an HG_CANCELED error return code.","title":"Progress and Cancelation"},{"location":"user/hg_bulk/","text":"In addition to the previous layer, some RPCs may require the transfer of larger amounts of data. For these RPCs, the bulk layer can be used. It is built on top of the RMA protocol defined in the network abstraction layer and prevents intermediate memory copies. HG Bulk Interface The interface allows origin processes to expose a memory region to the target by creating a bulk descriptor (which contains virtual memory address information, size of the memory region that is being exposed, and other parameters that depend on the underlying network implementation). The bulk descriptor can be serialized and sent to the target along with the RPC request arguments (using the RPC layer). When the target gets the input parameters, it can deserialize the bulk descriptor, get the size of the memory buffer that has to be transferred, and initiate the transfer. Only targets should initiate one-sided transfers so that they can, as well as controlling the data flow, protect their memory from concurrent accesses. As no explicit ack message is sent on transfer completion, the origin process can only assume that accesses to its local memory are completed once it receives the RPC response from the target. Therefore, in the case of an RPC with no response, great care should be taken when initiating a bulk transfer to ensure that the origin gets notified when its exposed memory can be safely released and accessed. Descriptors The interface uses the class and execution context that are defined by the HG RPC layer. To initiate a bulk transfer, one needs to create a bulk descriptor on both the origin and the target, which will later be passed to the HG_Bulk_transfer() call. hg_return_t HG_Bulk_create ( hg_class_t * hg_class , hg_uint32_t count , void ** buf_ptrs , const hg_size_t * buf_sizes , hg_uint8_t flags , hg_bulk_t * handle ); The bulk descriptor can be released by using: hg_return_t HG_Bulk_free ( hg_bulk_t handle ); For convenience, memory pointers from an existing bulk descriptor can be accessed with: hg_return_t HG_Bulk_access ( hg_bulk_t handle , hg_size_t offset , hg_size_t size , hg_uint8_t flags , hg_uint32_t max_count , void ** buf_ptrs , hg_size_t * buf_sizes , hg_uint32_t * actual_count ); Additionally, it is also possible to bind the origin's address to the bulk handle through the HG_Bulk_bind() function at the cost of an additional overhead for serializing and deserializing addressing information. This should only be necessary when the source address retrieved from the HG_Get_info() call is different from the one that must be used for the transfer (e.g., multiple sources). hg_return_t HG_Bulk_bind ( hg_bulk_t handle , hg_context_t * context ); In that particular case, the address information can be directly retrieved using: hg_addr_t HG_Bulk_get_addr ( hg_bulk_t handle ); Serialization Serialization and deserialization of bulk handles should never be explicitly done by users and we instead encourage the use of the mercury proc routines that provide an hg_proc_hg_bulk_t routine: hg_return_t hg_proc_hg_bulk_t ( hg_proc_t proc , void * data ); For more details on RPC argument serialization, please refer to this section . Bulk Transfer When the bulk descriptor from the origin has been received, the target can initiate the bulk transfer to/from its own bulk descriptor. Virtual offsets can be used to transfer data pieces from a non-contiguous block transparently. The call is non-blocking. When the operation completes, the user callback is placed onto the context's completion queue. hg_return_t HG_Bulk_transfer ( hg_context_t * context , hg_bulk_cb_t callback , void * arg , hg_bulk_op_t op , hg_addr_t origin_addr , hg_bulk_t origin_handle , hg_size_t origin_offset , hg_bulk_t local_handle , hg_size_t local_offset , hg_size_t size , hg_op_id_t * op_id ); Note that for convenience, as the transfer needs to be realized within the RPC callback on the RPC target, the routine HG_Get_info() enables easy retrieval of classes, contexts and source address: struct hg_info { hg_class_t * hg_class ; /* HG class */ hg_context_t * context ; /* HG context */ hg_addr_t addr ; /* HG address */ hg_id_t id ; /* RPC ID */ }; struct hg_info * HG_Get_info ( hg_handle_t handle );","title":"Mercury Bulk Layer"},{"location":"user/hg_bulk/#hg-bulk-interface","text":"The interface allows origin processes to expose a memory region to the target by creating a bulk descriptor (which contains virtual memory address information, size of the memory region that is being exposed, and other parameters that depend on the underlying network implementation). The bulk descriptor can be serialized and sent to the target along with the RPC request arguments (using the RPC layer). When the target gets the input parameters, it can deserialize the bulk descriptor, get the size of the memory buffer that has to be transferred, and initiate the transfer. Only targets should initiate one-sided transfers so that they can, as well as controlling the data flow, protect their memory from concurrent accesses. As no explicit ack message is sent on transfer completion, the origin process can only assume that accesses to its local memory are completed once it receives the RPC response from the target. Therefore, in the case of an RPC with no response, great care should be taken when initiating a bulk transfer to ensure that the origin gets notified when its exposed memory can be safely released and accessed.","title":"HG Bulk Interface"},{"location":"user/hg_bulk/#descriptors","text":"The interface uses the class and execution context that are defined by the HG RPC layer. To initiate a bulk transfer, one needs to create a bulk descriptor on both the origin and the target, which will later be passed to the HG_Bulk_transfer() call. hg_return_t HG_Bulk_create ( hg_class_t * hg_class , hg_uint32_t count , void ** buf_ptrs , const hg_size_t * buf_sizes , hg_uint8_t flags , hg_bulk_t * handle ); The bulk descriptor can be released by using: hg_return_t HG_Bulk_free ( hg_bulk_t handle ); For convenience, memory pointers from an existing bulk descriptor can be accessed with: hg_return_t HG_Bulk_access ( hg_bulk_t handle , hg_size_t offset , hg_size_t size , hg_uint8_t flags , hg_uint32_t max_count , void ** buf_ptrs , hg_size_t * buf_sizes , hg_uint32_t * actual_count ); Additionally, it is also possible to bind the origin's address to the bulk handle through the HG_Bulk_bind() function at the cost of an additional overhead for serializing and deserializing addressing information. This should only be necessary when the source address retrieved from the HG_Get_info() call is different from the one that must be used for the transfer (e.g., multiple sources). hg_return_t HG_Bulk_bind ( hg_bulk_t handle , hg_context_t * context ); In that particular case, the address information can be directly retrieved using: hg_addr_t HG_Bulk_get_addr ( hg_bulk_t handle );","title":"Descriptors"},{"location":"user/hg_bulk/#serialization","text":"Serialization and deserialization of bulk handles should never be explicitly done by users and we instead encourage the use of the mercury proc routines that provide an hg_proc_hg_bulk_t routine: hg_return_t hg_proc_hg_bulk_t ( hg_proc_t proc , void * data ); For more details on RPC argument serialization, please refer to this section .","title":"Serialization"},{"location":"user/hg_bulk/#bulk-transfer","text":"When the bulk descriptor from the origin has been received, the target can initiate the bulk transfer to/from its own bulk descriptor. Virtual offsets can be used to transfer data pieces from a non-contiguous block transparently. The call is non-blocking. When the operation completes, the user callback is placed onto the context's completion queue. hg_return_t HG_Bulk_transfer ( hg_context_t * context , hg_bulk_cb_t callback , void * arg , hg_bulk_op_t op , hg_addr_t origin_addr , hg_bulk_t origin_handle , hg_size_t origin_offset , hg_bulk_t local_handle , hg_size_t local_offset , hg_size_t size , hg_op_id_t * op_id ); Note that for convenience, as the transfer needs to be realized within the RPC callback on the RPC target, the routine HG_Get_info() enables easy retrieval of classes, contexts and source address: struct hg_info { hg_class_t * hg_class ; /* HG class */ hg_context_t * context ; /* HG context */ hg_addr_t addr ; /* HG address */ hg_id_t id ; /* RPC ID */ }; struct hg_info * HG_Get_info ( hg_handle_t handle );","title":"Bulk Transfer"},{"location":"user/hg_macros/","text":"For convenience, Mercury provides macros that can reduce the amount of code required to send an RPC call. Instead of using tedious RPC stubs and code generators, Mercury makes use of the Boost preprocessor library so that users can generate all the boilerplate code that is necessary to serialize and deserialize function arguments. RPC Registration When registering a new RPC through the RPC layer (see previous section), users are expected to tell Mercury how to serialize and deserialize input and output arguments. To facilitate that and in conjunction with the following macros, the MERCURY_REGISTER() macro makes the registration of RPC calls more convenient by mapping the types to the generated proc functions. MERCURY_REGISTER ( hg_class , func_name , in_struct_type_name , out_struct_type_name , rpc_cb ); Example int rpc_open ( const char * path , rpc_handle_t handle , int * event_id ); One can use the MERCURY_REGISTER macro and pass the types of the input/output structures directly. In cases where no input or no output argument is present, the void type can be passed to the macro. rpc_id = MERCURY_REGISTER ( hg_class , \"rpc_open\" , rpc_open_in_t , rpc_open_out_t , rpc_open_cb ); Predefined Types Mercury already defines some types and uses standard types so that the size of the type is fixed between platforms when serializing and deserializing it. For convenience, HG types can also be used to serialize bulk handles for example, but also strings, etc. Predefined Types Type name Standard types int8_t , uint8_t int16_t , uint16_t int32_t , uint32_t int64_t , uint64_t Strings hg_string_t , hg_const_string_t Bulk descriptor hg_bulk_t Mercury types hg_bool_t , hg_id_t , hg_size_t , hg_ptr_t New Type Description The macro MERCURY_GEN_PROC() can be used to describe new types that are generally composed of primitive types. The macro generates both a new struct and a proc function that can be used to serialize arguments. The structure fields contain either input arguments or output arguments. The generated proc routine uses the proc routines from pre-existing types to serialize and deserialize each of the fields. MERCURY_GEN_PROC ( struct_type_name , fields ) Example The following function has two input arguments, one output argument and one return value. int rpc_open ( const char * path , rpc_handle_t handle , int * event_id ); The following macro can be used to generate boilerplate code for the input argument (again, refer to the predefined types section for a list of the pre-existing types that can be passed to this macro): MERCURY_GEN_PROC ( rpc_open_in_t , (( hg_const_string_t )( path )) (( rpc_handle_t )( handle )) ) /* Will generate an rpc_open_in_t struct */ typedef struct { hg_const_string_t path ; rpc_handle_t handle ; } rpc_open_in_t ; /* and an hg_proc_rpc_open_in_t proc function */ hg_return_t hg_proc_rpc_open_in_t ( hg_proc_t proc , void * data ) { hg_return_t ret ; rpc_open_in_t * struct_data = ( rpc_open_in_t * ) data ; ret = hg_proc_hg_const_string_t ( proc , & struct_data -> path ); if ( ret != HG_SUCCESS ) { /* error */ } ret = hg_proc_rpc_handle_t ( proc , & struct_data -> handle ); if ( ret != HG_SUCCESS ) { /* error */ } return ret ; } Note the parentheses that separate the name of the field and its type. Each field is then separated by another pair of parentheses. This follows the sequence data type of the Boost preprocessor library. Existing struct Description In some cases, however, the argument types are not known by Mercury, which is the case of the previous example with the rpc_handle_t type. For these cases, another macro, called MERCURY_GEN_STRUCT_PROC , can be used. It defines a serialization function for an existing struct or type\u2014this assumes that the type can be mapped to already existing types; if not, users can create their own proc function and use the hg_proc_raw routine that takes a stream of bytes. MERCURY_GEN_STRUCT_PROC ( struct_type_name , fields ) Example The following function has one non-standard type, rpc_handle_t . int rpc_open ( const char * path , rpc_handle_t handle , int * event_id ); /* pre-defined struct */ typedef struct { hg_uint64_t cookie ; } rpc_handle_t ; The following macro can then be used to generate boilerplate code for the type by defining its fields. MERCURY_GEN_STRUCT_PROC ( rpc_handle_t , (( hg_uint64_t )( cookie )) ) /* Will generate an hg_proc_rpc_handle_t function */ static hg_return_t hg_proc_rpc_handle_t ( hg_proc_t proc , void * data ) { hg_return_t ret ; rpc_handle_t * struct_data = ( rpc_handle_t * ) data ; ret = hg_proc_hg_uint64_t ( proc , & struct_data -> cookie ); if ( ret != HG_SUCCESS ) { /* error */ } return ret ; }","title":"Mercury Serialization Macros"},{"location":"user/hg_macros/#rpc-registration","text":"When registering a new RPC through the RPC layer (see previous section), users are expected to tell Mercury how to serialize and deserialize input and output arguments. To facilitate that and in conjunction with the following macros, the MERCURY_REGISTER() macro makes the registration of RPC calls more convenient by mapping the types to the generated proc functions. MERCURY_REGISTER ( hg_class , func_name , in_struct_type_name , out_struct_type_name , rpc_cb ); Example int rpc_open ( const char * path , rpc_handle_t handle , int * event_id ); One can use the MERCURY_REGISTER macro and pass the types of the input/output structures directly. In cases where no input or no output argument is present, the void type can be passed to the macro. rpc_id = MERCURY_REGISTER ( hg_class , \"rpc_open\" , rpc_open_in_t , rpc_open_out_t , rpc_open_cb );","title":"RPC Registration"},{"location":"user/hg_macros/#predefined-types","text":"Mercury already defines some types and uses standard types so that the size of the type is fixed between platforms when serializing and deserializing it. For convenience, HG types can also be used to serialize bulk handles for example, but also strings, etc. Predefined Types Type name Standard types int8_t , uint8_t int16_t , uint16_t int32_t , uint32_t int64_t , uint64_t Strings hg_string_t , hg_const_string_t Bulk descriptor hg_bulk_t Mercury types hg_bool_t , hg_id_t , hg_size_t , hg_ptr_t","title":"Predefined Types"},{"location":"user/hg_macros/#new-type-description","text":"The macro MERCURY_GEN_PROC() can be used to describe new types that are generally composed of primitive types. The macro generates both a new struct and a proc function that can be used to serialize arguments. The structure fields contain either input arguments or output arguments. The generated proc routine uses the proc routines from pre-existing types to serialize and deserialize each of the fields. MERCURY_GEN_PROC ( struct_type_name , fields ) Example The following function has two input arguments, one output argument and one return value. int rpc_open ( const char * path , rpc_handle_t handle , int * event_id ); The following macro can be used to generate boilerplate code for the input argument (again, refer to the predefined types section for a list of the pre-existing types that can be passed to this macro): MERCURY_GEN_PROC ( rpc_open_in_t , (( hg_const_string_t )( path )) (( rpc_handle_t )( handle )) ) /* Will generate an rpc_open_in_t struct */ typedef struct { hg_const_string_t path ; rpc_handle_t handle ; } rpc_open_in_t ; /* and an hg_proc_rpc_open_in_t proc function */ hg_return_t hg_proc_rpc_open_in_t ( hg_proc_t proc , void * data ) { hg_return_t ret ; rpc_open_in_t * struct_data = ( rpc_open_in_t * ) data ; ret = hg_proc_hg_const_string_t ( proc , & struct_data -> path ); if ( ret != HG_SUCCESS ) { /* error */ } ret = hg_proc_rpc_handle_t ( proc , & struct_data -> handle ); if ( ret != HG_SUCCESS ) { /* error */ } return ret ; } Note the parentheses that separate the name of the field and its type. Each field is then separated by another pair of parentheses. This follows the sequence data type of the Boost preprocessor library.","title":"New Type Description"},{"location":"user/hg_macros/#existing-struct-description","text":"In some cases, however, the argument types are not known by Mercury, which is the case of the previous example with the rpc_handle_t type. For these cases, another macro, called MERCURY_GEN_STRUCT_PROC , can be used. It defines a serialization function for an existing struct or type\u2014this assumes that the type can be mapped to already existing types; if not, users can create their own proc function and use the hg_proc_raw routine that takes a stream of bytes. MERCURY_GEN_STRUCT_PROC ( struct_type_name , fields ) Example The following function has one non-standard type, rpc_handle_t . int rpc_open ( const char * path , rpc_handle_t handle , int * event_id ); /* pre-defined struct */ typedef struct { hg_uint64_t cookie ; } rpc_handle_t ; The following macro can then be used to generate boilerplate code for the type by defining its fields. MERCURY_GEN_STRUCT_PROC ( rpc_handle_t , (( hg_uint64_t )( cookie )) ) /* Will generate an hg_proc_rpc_handle_t function */ static hg_return_t hg_proc_rpc_handle_t ( hg_proc_t proc , void * data ) { hg_return_t ret ; rpc_handle_t * struct_data = ( rpc_handle_t * ) data ; ret = hg_proc_hg_uint64_t ( proc , & struct_data -> cookie ); if ( ret != HG_SUCCESS ) { /* error */ } return ret ; }","title":"Existing struct Description"},{"location":"user/na/","text":"The network abstraction (NA) layer is internally used by both the RPC layer and the bulk layer. The NA layer uses a plugin mechanism so that support for various network protocols can be easily added and selected at runtime. Info The NA interface should not be directly used if you intend to use Mercury's RPC layer (HG calls). In that case, please directly jump to the available plugins section for a list of plugins that can be used when initializing Mercury\u2014Mercury's initialization is then further described in the RPC layer section. NA Interface NA provides a minimal set of function calls that abstract the underlying network fabric and that can be used to provide: target address lookup , point-to-point messaging with both unexpected and expected messaging, remote memory access (RMA) , progress and cancelation . The API is non-blocking and uses a callback mechanism so that upper layers can provide asynchronous execution more easily: when progress is made (either internally or after a call to NA_Progress() ) and an operation completes, the user callback is placed onto a completion queue. The callback can then be dequeued and separately executed after a call to NA_Trigger() . Initialization When using NA, the first step of a program should consist of initializing the NA interface and selecting an underlying plugin that will be used. Initializing the NA interface with a specified info_string results in the creation of a new na_class_t object. Please refer to the available plugins section for more information on the info_string format. Additionally, it is possible to specify whether the na_class_t object will be listening or not\u2014this is the only time where a \"server\" specific behavior is defined, all subsequent calls do not make any distinction between a \"client\" and a \"server\" and instead only use the concept of origin and target . It is worth noting, however, that the listen flag may have an effect on the resources that are allocated and that the address passed through info_string will be used to create an endpoint that remote peers can access. na_class_t * NA_Initialize ( const char * info_string , bool listen ); If a more specific behavior is required, the following call can also be used to pass specific init options. Option Description ip_subnet Preferred IP subnet to use. auth_key Authorization key that can be used for communication. All processes should use the same key in order to communicate. max_unexpected_size Max unexpected size hint that can be passed to control the size of unexpected messages. max_expected_size Max expected size hint that can be passed to control the size of unexpected messages. progress_mode Progress mode flag. Setting NA_NO_BLOCK will force busy-spin on progress and remove any wait/notification calls. addr_format Preferred address format. Can be set to NA_ADDR_IPV4 , NA_ADDR_IPV6 or NA_ADDR_NATIVE . max_contexts Maximum number of contexts that are expected to be created. thread_mode Thread mode flags. Setting NA_THREAD_MODE_SINGLE will relax thread-safety requirements. request_mem_device Request support for tranfers to/from memory devices (e.g., GPU, etc). struct na_init_info { const char * ip_subnet ; const char * auth_key ; size_t max_unexpected_size ; size_t max_expected_size ; uint8_t progress_mode ; enum na_addr_format addr_format ; uint8_t max_contexts ; uint8_t thread_mode ; bool request_mem_device ; }; na_class_t * NA_Initialize_opt2 ( const char * info_string , bool listen , unsigned int version , const struct na_init_info * na_init_info ); The na_class_t object created from these initialization calls should later be released with a call to: na_return_t NA_Finalize ( na_class_t * na_class ); Once the interface has been initialized, a context within this plugin must be created, which internally creates and associates a completion queue for the operations: na_context_t * NA_Context_create ( na_class_t * na_class ); It can then be destroyed using: na_return_t NA_Context_destroy ( na_class_t * na_class , na_context_t * context ); Target Address Lookup To communicate with a target, one must first get its address. The most convenient and safe way of doing that is by calling on the target: na_return_t NA_Addr_self ( na_class_t * na_class , na_addr_t ** addr_p ); And then convert that address to a string using: na_return_t NA_Addr_to_string ( na_class_t * na_class , char * buf , size_t * buf_size_p , na_addr_t * addr ); The string can then be exchanged to other processes through out-of-band mechanisms (e.g., using a file, etc), which can then look up the target using the function: na_return_t NA_Addr_lookup ( na_class_t * na_class , const char * name , na_addr_t ** addr_p ); All addresses must then be freed using: na_return_t NA_Addr_free ( na_class_t * na_class , na_addr_t * addr ); Point-to-point Messaging Point-to-point messaging in NA is always non-blocking with completion callbacks being executed after a call to NA_Trigger() (once the operation has completed and been placed onto the completion queue). NA supports two separates modes for sending and receiving messages: either unexpected or expected . Expected messages should always have their receive pre-posted. Though messages may be dropped without notification if that is not the case, they are usually still queued and later processed. Unexpected messages on the other handle never require receives to be pre-posted and messages are also allowed to be dropped (though once again plugins usually do queue them). Both types of messages are tagged messages that take the same arguments for sends: na_return_t NA_Msg_send_unexpected ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , const void * buf , size_t buf_size , void * plugin_data , na_addr_t * dest_addr , uint8_t dest_id , na_tag_t tag , na_op_id_t * op_id ); na_return_t NA_Msg_send_expected ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , const void * buf , size_t buf_size , void * plugin_data , na_addr_t * dest_addr , uint8_t dest_id , na_tag_t tag , na_op_id_t * op_id ); And only mostly differ in their receive operation: na_return_t NA_Msg_recv_unexpected ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , void * buf , size_t buf_size , void * plugin_data , na_op_id_t * op_id ); na_return_t NA_Msg_recv_expected ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , void * buf , size_t buf_size , void * plugin_data , na_addr_t source_addr , uint8_t source_id , na_tag_t tag , na_op_id_t * op_id ); One will only match with a specific source_addr and tag while the other will match with any source and tag, which can then later be retrieved from the callback info. struct na_cb_info_recv_unexpected { size_t actual_buf_size ; na_addr_t * source ; na_tag_t tag ; }; Note that for best performance, NA_Msg_buf_alloc() and NA_Msg_buf_free() may be used to allocate send and receive buffers. Remote Memory Access Remote memory access requires host memory that is desired to be accessed to be first registered with the NA layer. This is done in two steps, by first creating a handle that describes the memory buffer that is to be registered and calling NA_Mem_register() on it. na_return_t NA_Mem_handle_create ( na_class_t * na_class , void * buf , size_t buf_size , unsigned long flags , na_mem_handle_t ** mem_handle_p ); na_return_t NA_Mem_register ( na_class_t * na_class , na_mem_handle_t * mem_handle , enum na_mem_type mem_type , uint64_t device ); Similarly, NA_Mem_deregister() and NA_Mem_handle_free() must be called to release resources. Once memory has been registered, the handle of the target must be serialized and exchanged with the peer that will initiate the RMA operation. This is done by calling: na_return_t NA_Mem_handle_serialize ( na_class_t * na_class , void * buf , size_t buf_size , na_mem_handle_t * mem_handle ); The peer can then deserialize the handle using: na_return_t NA_Mem_handle_deserialize ( na_class_t * na_class , na_mem_handle_t ** mem_handle_p , const void * buf , size_t buf_size ); And initiate an RMA operation using both the handle of the target that describes its remote memory and the local handle that describes its local memory: na_return_t NA_Put ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , na_mem_handle_t * local_mem_handle , na_offset_t local_offset , na_mem_handle_t * remote_mem_handle , na_offset_t remote_offset , size_t data_size , na_addr_t * remote_addr , uint8_t remote_id , na_op_id_t * op_id ); na_return_t NA_Get ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , na_mem_handle_t * local_mem_handle , na_offset_t local_offset , na_mem_handle_t * remote_mem_handle , na_offset_t remote_offset , size_t data_size , na_addr_t * remote_addr , uint8_t remote_id , na_op_id_t * op_id ); Similar to point-to-point operations, RMA operations are non-blocking and use a callback-based model that is triggered after a call to NA_Trigger() when the operation completes. Progress and Cancelation NA progress model is always explicit and users are expected to call NA_Progress() followed by a call to NA_Trigger() : na_return_t NA_Progress ( na_class_t * na_class , na_context_t * context , unsigned int timeout ); na_return_t NA_Trigger ( na_context_t * context , unsigned int max_count , unsigned int * actual_count ); NA_Trigger() always operates on a single context while NA_Progress() may operate both on a class and a context. When progress is called, it returns as soon as an operation either completes or is already in the completion queue so that a call to NA_Trigger() may be done to empty the queue and execute the user callback. When an operation must be canceled, users are expected to call NA_Cancel() on that operation: na_return_t NA_Cancel ( na_class_t * na_class , na_context_t * context , na_op_id_t * op_id ); Cancelation is always asynchronous. When/if the operation is successfully canceled, it will be pushed to the completion queue with an NA_CANCELED error return code. Available Plugins NA supports different backend implementations. However, OFI/libfabric is the recommended plugin in most situations for inter-node communication, while SM (shared-memory) is recommended for intra-node communication. Summary The table below summarizes the current list of plugins along with the transports that we currently support with those plugins. Plugin / Transport tcp verbs shm opx gni cxi ofi ucx sm Warning Additional transports may be supported for each plugin but we do not recommend their use unless explicitly mentioned in the above table as they are either unstable or have not been tested. Transports with are not available for the selected plugin. Transports with are not supported but may be available in the future. Transports with have known issues. Initialization String Format Below is a table summarizing the protocols and expected format for each plugin ( [ ] means optional, in which case the plugin will select default hostnames and ports to use). Plugin Protocol Initialization format 1 ofi tcp verbs shm opx gni cxi ofi+tcp[://<hostname,IP,interface name>:<port>] ofi+verbs[://[MLX device/]<hostname,IP,interface name>:<port>] 2 ofi+shm 3 ofi+opx[://<HFI device>:<port>] ofi+gni[://<hostname,IP,interface name>] 4 ofi+cxi[://<CXI device>:<port ID>] ucx all tcp rc,ud,dc 5 ucx+all[://[net_device/]<hostname,IP,interface name>:<port>] na sm na+sm[://<shm_prefix>] Note Invalid port numbers that are passed may be silently ignored by the underlying implementation in which case a new port will be automatically picked up. 1 When initialized without listening, the port specification can be elided. 2 The libfabric domain name can also be passed directly to select the right adapter to use. See the output generated by the command hg_info for provider name verbs;ofi_rxm (e.g., mlx5_0 ). 3 Any hostname or port being passed will be ignored. 4 No port information needs to be passed, the most common interface name is ipogif0 , which will be used by default if no hostname is passed. 5 Please refer to the UCX documentation for a full list of available transports that can be used. OFI ( as of v1.0.0 ) The NA OFI/libfabric plugin is available for general purpose use. The plugin currently supports tcp, verbs, opx and cxi transports. The psm2 and gni protocols are deprecated. See this page for additional implementation and performance details. Attention As of libfabric 1.18.0, tcp no longer uses the RxM layer. To force use of tcp with RxM, tcp;ofi_rxm must be directly passed. However, it is recommended to use tcp for improved stability and performance. Technical notes: Low CPU consumption (i.e., idles without busy spinning) is supported by all supported libfabric providers. Connection-less and uses reliable datagrams. RMA (for Mercury bulk operations) is implemented natively on transports that support it. ofi/tcp ( tcp provider) may use the RxM layer to emulate connection-less endpoints. It also emulates RMA operations. ofi/verbs ( verbs provider) uses the RxM layer to emulate connection-less endpoints (the first message being sent may be slower). ofi/opx ( opx provider) can be used on legacy Intel \u00ae Omni-Path 2 interconnect and Cornelis Omni-Path Express hardware. ofi/gni ( gni provider) can be used on Cray \u00ae systems with Gemini/Aries interconnects. Note that it requires the use of Cray \u00ae DRC to exchange credentials when communication between separate jobs is required (see section on DRC credentials ). ofi/cxi ( cxi provider) can be used on HPE systems with Slingshot interconnect. For systems with multiple NICs, hwloc can be used to automatically select the closest NIC to the CPU in-use (mercury must be configured with NA_OFI_USE_HWLOC in that case). Influential variables: RDMAV_HUGEPAGES_SAFE : must be set when using hugepages in combination with verbs provider. FI_UNIVERSE_SIZE : must be set when exceeding 256 peers with tcp or verbs providers. Please refer to the libfabric manpages for additional details for each transports. UCX ( as of v2.1.0 ) The UCX plugin is available for general purpose use. By default and as opposed to other plugins, the UCX plugin is able to automatically determine which transport is best to be used. This is achieved by passing the all keyword in lieu of a specific transport. However, note that we are only testing the tcp and rc,ud,dc (verbs) protocols of UCX. Technical notes: Connection-less is currently emulated on top of connected endpoints. Therefore, it is expected that the first message sent to a target will be slower than subsequent messages. A thread safe enabled UCX library is required to be used unless users explicitly tell NA, using the thread_mode init option (see above ), that they will not access classes and contexts with more than one thread. NA_Addr_to_string() cannot be used on non-listening processes to convert a self-address to a string. This is due to the fact that UCX does not expose endpoints prior to their connection. Influential variables: ucx_info -c -f will display the default configuration. Each of these variables can be overridden by the user. Note, however, that the UCX_TLS and UCX_NET_DEVICES are currently overridden by the NA UCX plugin. SM ( as of v0.9.0 ) This is the integrated shared memory NA plugin. Plugin is stable and provides significantly better performance for local node communication. The goal of this plugin is to provide a transparent shortcut for other NA plugins when they connect to local services using the auto_sm initialization option (see the RPC section for more details), but it is also useful as a primary transport for single-node services. Technical notes: Uses fully connection-less communication. Low CPU consumption (i.e., idles without busy spinning or using threads). RMA (for Mercury bulk operations) is implemented natively through cross-memory attach ( CMA ) on Linux, and there are fallback methods for other platforms as well. See this page for additional implementation and performance details. Deprecated Plugins CCI ( deprecated ) This NA plugin is no longer available for general purpose use, and is now deprecated as CCI itself is no longer actively maintained. MPI MPI implementations are widely available for nearly any platform, and the NA MPI plugin provides a convenient option for prototyping and functionality testing. It is not optimized for performance, however, and it has some practical limitations when used for persistent services. Technical notes: Clients can connect to a server dynamically only if the underlying MPI implementation supports MPI_Comm_connect() . RMA (for Mercury bulk operations) is emulated via point-to-point messaging (note: MPI window creation requires collective coordination and is not a good fit for RPC use). Significant CPU consumption (progress function iteratively polls pending operations for completion). BMI The BMI library itself is no longer under active feature development beyond basic maintenance, but the NA BMI plugin provides a very stable and reasonably performant option for IP networks when used with BMI's TCP method. Technical notes: Low CPU consumption (i.e., idles without busy spinning or using threads). Supports dynamic client connection and disconnection. RMA (for Mercury bulk operations) is emulated via point-to-point messaging. Does not support initializing multiple instances simultaneously. Other BMI methods besides TCP are not supported. For general BMI information see this paper .","title":"Network Abstraction Layer"},{"location":"user/na/#na-interface","text":"NA provides a minimal set of function calls that abstract the underlying network fabric and that can be used to provide: target address lookup , point-to-point messaging with both unexpected and expected messaging, remote memory access (RMA) , progress and cancelation . The API is non-blocking and uses a callback mechanism so that upper layers can provide asynchronous execution more easily: when progress is made (either internally or after a call to NA_Progress() ) and an operation completes, the user callback is placed onto a completion queue. The callback can then be dequeued and separately executed after a call to NA_Trigger() .","title":"NA Interface"},{"location":"user/na/#initialization","text":"When using NA, the first step of a program should consist of initializing the NA interface and selecting an underlying plugin that will be used. Initializing the NA interface with a specified info_string results in the creation of a new na_class_t object. Please refer to the available plugins section for more information on the info_string format. Additionally, it is possible to specify whether the na_class_t object will be listening or not\u2014this is the only time where a \"server\" specific behavior is defined, all subsequent calls do not make any distinction between a \"client\" and a \"server\" and instead only use the concept of origin and target . It is worth noting, however, that the listen flag may have an effect on the resources that are allocated and that the address passed through info_string will be used to create an endpoint that remote peers can access. na_class_t * NA_Initialize ( const char * info_string , bool listen ); If a more specific behavior is required, the following call can also be used to pass specific init options. Option Description ip_subnet Preferred IP subnet to use. auth_key Authorization key that can be used for communication. All processes should use the same key in order to communicate. max_unexpected_size Max unexpected size hint that can be passed to control the size of unexpected messages. max_expected_size Max expected size hint that can be passed to control the size of unexpected messages. progress_mode Progress mode flag. Setting NA_NO_BLOCK will force busy-spin on progress and remove any wait/notification calls. addr_format Preferred address format. Can be set to NA_ADDR_IPV4 , NA_ADDR_IPV6 or NA_ADDR_NATIVE . max_contexts Maximum number of contexts that are expected to be created. thread_mode Thread mode flags. Setting NA_THREAD_MODE_SINGLE will relax thread-safety requirements. request_mem_device Request support for tranfers to/from memory devices (e.g., GPU, etc). struct na_init_info { const char * ip_subnet ; const char * auth_key ; size_t max_unexpected_size ; size_t max_expected_size ; uint8_t progress_mode ; enum na_addr_format addr_format ; uint8_t max_contexts ; uint8_t thread_mode ; bool request_mem_device ; }; na_class_t * NA_Initialize_opt2 ( const char * info_string , bool listen , unsigned int version , const struct na_init_info * na_init_info ); The na_class_t object created from these initialization calls should later be released with a call to: na_return_t NA_Finalize ( na_class_t * na_class ); Once the interface has been initialized, a context within this plugin must be created, which internally creates and associates a completion queue for the operations: na_context_t * NA_Context_create ( na_class_t * na_class ); It can then be destroyed using: na_return_t NA_Context_destroy ( na_class_t * na_class , na_context_t * context );","title":"Initialization"},{"location":"user/na/#target-address-lookup","text":"To communicate with a target, one must first get its address. The most convenient and safe way of doing that is by calling on the target: na_return_t NA_Addr_self ( na_class_t * na_class , na_addr_t ** addr_p ); And then convert that address to a string using: na_return_t NA_Addr_to_string ( na_class_t * na_class , char * buf , size_t * buf_size_p , na_addr_t * addr ); The string can then be exchanged to other processes through out-of-band mechanisms (e.g., using a file, etc), which can then look up the target using the function: na_return_t NA_Addr_lookup ( na_class_t * na_class , const char * name , na_addr_t ** addr_p ); All addresses must then be freed using: na_return_t NA_Addr_free ( na_class_t * na_class , na_addr_t * addr );","title":"Target Address Lookup"},{"location":"user/na/#point-to-point-messaging","text":"Point-to-point messaging in NA is always non-blocking with completion callbacks being executed after a call to NA_Trigger() (once the operation has completed and been placed onto the completion queue). NA supports two separates modes for sending and receiving messages: either unexpected or expected . Expected messages should always have their receive pre-posted. Though messages may be dropped without notification if that is not the case, they are usually still queued and later processed. Unexpected messages on the other handle never require receives to be pre-posted and messages are also allowed to be dropped (though once again plugins usually do queue them). Both types of messages are tagged messages that take the same arguments for sends: na_return_t NA_Msg_send_unexpected ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , const void * buf , size_t buf_size , void * plugin_data , na_addr_t * dest_addr , uint8_t dest_id , na_tag_t tag , na_op_id_t * op_id ); na_return_t NA_Msg_send_expected ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , const void * buf , size_t buf_size , void * plugin_data , na_addr_t * dest_addr , uint8_t dest_id , na_tag_t tag , na_op_id_t * op_id ); And only mostly differ in their receive operation: na_return_t NA_Msg_recv_unexpected ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , void * buf , size_t buf_size , void * plugin_data , na_op_id_t * op_id ); na_return_t NA_Msg_recv_expected ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , void * buf , size_t buf_size , void * plugin_data , na_addr_t source_addr , uint8_t source_id , na_tag_t tag , na_op_id_t * op_id ); One will only match with a specific source_addr and tag while the other will match with any source and tag, which can then later be retrieved from the callback info. struct na_cb_info_recv_unexpected { size_t actual_buf_size ; na_addr_t * source ; na_tag_t tag ; }; Note that for best performance, NA_Msg_buf_alloc() and NA_Msg_buf_free() may be used to allocate send and receive buffers.","title":"Point-to-point Messaging"},{"location":"user/na/#remote-memory-access","text":"Remote memory access requires host memory that is desired to be accessed to be first registered with the NA layer. This is done in two steps, by first creating a handle that describes the memory buffer that is to be registered and calling NA_Mem_register() on it. na_return_t NA_Mem_handle_create ( na_class_t * na_class , void * buf , size_t buf_size , unsigned long flags , na_mem_handle_t ** mem_handle_p ); na_return_t NA_Mem_register ( na_class_t * na_class , na_mem_handle_t * mem_handle , enum na_mem_type mem_type , uint64_t device ); Similarly, NA_Mem_deregister() and NA_Mem_handle_free() must be called to release resources. Once memory has been registered, the handle of the target must be serialized and exchanged with the peer that will initiate the RMA operation. This is done by calling: na_return_t NA_Mem_handle_serialize ( na_class_t * na_class , void * buf , size_t buf_size , na_mem_handle_t * mem_handle ); The peer can then deserialize the handle using: na_return_t NA_Mem_handle_deserialize ( na_class_t * na_class , na_mem_handle_t ** mem_handle_p , const void * buf , size_t buf_size ); And initiate an RMA operation using both the handle of the target that describes its remote memory and the local handle that describes its local memory: na_return_t NA_Put ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , na_mem_handle_t * local_mem_handle , na_offset_t local_offset , na_mem_handle_t * remote_mem_handle , na_offset_t remote_offset , size_t data_size , na_addr_t * remote_addr , uint8_t remote_id , na_op_id_t * op_id ); na_return_t NA_Get ( na_class_t * na_class , na_context_t * context , na_cb_t callback , void * arg , na_mem_handle_t * local_mem_handle , na_offset_t local_offset , na_mem_handle_t * remote_mem_handle , na_offset_t remote_offset , size_t data_size , na_addr_t * remote_addr , uint8_t remote_id , na_op_id_t * op_id ); Similar to point-to-point operations, RMA operations are non-blocking and use a callback-based model that is triggered after a call to NA_Trigger() when the operation completes.","title":"Remote Memory Access"},{"location":"user/na/#progress-and-cancelation","text":"NA progress model is always explicit and users are expected to call NA_Progress() followed by a call to NA_Trigger() : na_return_t NA_Progress ( na_class_t * na_class , na_context_t * context , unsigned int timeout ); na_return_t NA_Trigger ( na_context_t * context , unsigned int max_count , unsigned int * actual_count ); NA_Trigger() always operates on a single context while NA_Progress() may operate both on a class and a context. When progress is called, it returns as soon as an operation either completes or is already in the completion queue so that a call to NA_Trigger() may be done to empty the queue and execute the user callback. When an operation must be canceled, users are expected to call NA_Cancel() on that operation: na_return_t NA_Cancel ( na_class_t * na_class , na_context_t * context , na_op_id_t * op_id ); Cancelation is always asynchronous. When/if the operation is successfully canceled, it will be pushed to the completion queue with an NA_CANCELED error return code.","title":"Progress and Cancelation"},{"location":"user/na/#available-plugins","text":"NA supports different backend implementations. However, OFI/libfabric is the recommended plugin in most situations for inter-node communication, while SM (shared-memory) is recommended for intra-node communication.","title":"Available Plugins"},{"location":"user/na/#summary","text":"The table below summarizes the current list of plugins along with the transports that we currently support with those plugins. Plugin / Transport tcp verbs shm opx gni cxi ofi ucx sm Warning Additional transports may be supported for each plugin but we do not recommend their use unless explicitly mentioned in the above table as they are either unstable or have not been tested. Transports with are not available for the selected plugin. Transports with are not supported but may be available in the future. Transports with have known issues.","title":"Summary"},{"location":"user/na/#initialization-string-format","text":"Below is a table summarizing the protocols and expected format for each plugin ( [ ] means optional, in which case the plugin will select default hostnames and ports to use). Plugin Protocol Initialization format 1 ofi tcp verbs shm opx gni cxi ofi+tcp[://<hostname,IP,interface name>:<port>] ofi+verbs[://[MLX device/]<hostname,IP,interface name>:<port>] 2 ofi+shm 3 ofi+opx[://<HFI device>:<port>] ofi+gni[://<hostname,IP,interface name>] 4 ofi+cxi[://<CXI device>:<port ID>] ucx all tcp rc,ud,dc 5 ucx+all[://[net_device/]<hostname,IP,interface name>:<port>] na sm na+sm[://<shm_prefix>] Note Invalid port numbers that are passed may be silently ignored by the underlying implementation in which case a new port will be automatically picked up. 1 When initialized without listening, the port specification can be elided. 2 The libfabric domain name can also be passed directly to select the right adapter to use. See the output generated by the command hg_info for provider name verbs;ofi_rxm (e.g., mlx5_0 ). 3 Any hostname or port being passed will be ignored. 4 No port information needs to be passed, the most common interface name is ipogif0 , which will be used by default if no hostname is passed. 5 Please refer to the UCX documentation for a full list of available transports that can be used.","title":"Initialization String Format"},{"location":"user/na/#ofi","text":"( as of v1.0.0 ) The NA OFI/libfabric plugin is available for general purpose use. The plugin currently supports tcp, verbs, opx and cxi transports. The psm2 and gni protocols are deprecated. See this page for additional implementation and performance details. Attention As of libfabric 1.18.0, tcp no longer uses the RxM layer. To force use of tcp with RxM, tcp;ofi_rxm must be directly passed. However, it is recommended to use tcp for improved stability and performance. Technical notes: Low CPU consumption (i.e., idles without busy spinning) is supported by all supported libfabric providers. Connection-less and uses reliable datagrams. RMA (for Mercury bulk operations) is implemented natively on transports that support it. ofi/tcp ( tcp provider) may use the RxM layer to emulate connection-less endpoints. It also emulates RMA operations. ofi/verbs ( verbs provider) uses the RxM layer to emulate connection-less endpoints (the first message being sent may be slower). ofi/opx ( opx provider) can be used on legacy Intel \u00ae Omni-Path 2 interconnect and Cornelis Omni-Path Express hardware. ofi/gni ( gni provider) can be used on Cray \u00ae systems with Gemini/Aries interconnects. Note that it requires the use of Cray \u00ae DRC to exchange credentials when communication between separate jobs is required (see section on DRC credentials ). ofi/cxi ( cxi provider) can be used on HPE systems with Slingshot interconnect. For systems with multiple NICs, hwloc can be used to automatically select the closest NIC to the CPU in-use (mercury must be configured with NA_OFI_USE_HWLOC in that case). Influential variables: RDMAV_HUGEPAGES_SAFE : must be set when using hugepages in combination with verbs provider. FI_UNIVERSE_SIZE : must be set when exceeding 256 peers with tcp or verbs providers. Please refer to the libfabric manpages for additional details for each transports.","title":"OFI"},{"location":"user/na/#ucx","text":"( as of v2.1.0 ) The UCX plugin is available for general purpose use. By default and as opposed to other plugins, the UCX plugin is able to automatically determine which transport is best to be used. This is achieved by passing the all keyword in lieu of a specific transport. However, note that we are only testing the tcp and rc,ud,dc (verbs) protocols of UCX. Technical notes: Connection-less is currently emulated on top of connected endpoints. Therefore, it is expected that the first message sent to a target will be slower than subsequent messages. A thread safe enabled UCX library is required to be used unless users explicitly tell NA, using the thread_mode init option (see above ), that they will not access classes and contexts with more than one thread. NA_Addr_to_string() cannot be used on non-listening processes to convert a self-address to a string. This is due to the fact that UCX does not expose endpoints prior to their connection. Influential variables: ucx_info -c -f will display the default configuration. Each of these variables can be overridden by the user. Note, however, that the UCX_TLS and UCX_NET_DEVICES are currently overridden by the NA UCX plugin.","title":"UCX"},{"location":"user/na/#sm","text":"( as of v0.9.0 ) This is the integrated shared memory NA plugin. Plugin is stable and provides significantly better performance for local node communication. The goal of this plugin is to provide a transparent shortcut for other NA plugins when they connect to local services using the auto_sm initialization option (see the RPC section for more details), but it is also useful as a primary transport for single-node services. Technical notes: Uses fully connection-less communication. Low CPU consumption (i.e., idles without busy spinning or using threads). RMA (for Mercury bulk operations) is implemented natively through cross-memory attach ( CMA ) on Linux, and there are fallback methods for other platforms as well. See this page for additional implementation and performance details.","title":"SM"},{"location":"user/na/#deprecated-plugins","text":"","title":"Deprecated Plugins"},{"location":"user/na/#cci","text":"( deprecated ) This NA plugin is no longer available for general purpose use, and is now deprecated as CCI itself is no longer actively maintained.","title":"CCI"},{"location":"user/na/#mpi","text":"MPI implementations are widely available for nearly any platform, and the NA MPI plugin provides a convenient option for prototyping and functionality testing. It is not optimized for performance, however, and it has some practical limitations when used for persistent services. Technical notes: Clients can connect to a server dynamically only if the underlying MPI implementation supports MPI_Comm_connect() . RMA (for Mercury bulk operations) is emulated via point-to-point messaging (note: MPI window creation requires collective coordination and is not a good fit for RPC use). Significant CPU consumption (progress function iteratively polls pending operations for completion).","title":"MPI"},{"location":"user/na/#bmi","text":"The BMI library itself is no longer under active feature development beyond basic maintenance, but the NA BMI plugin provides a very stable and reasonably performant option for IP networks when used with BMI's TCP method. Technical notes: Low CPU consumption (i.e., idles without busy spinning or using threads). Supports dynamic client connection and disconnection. RMA (for Mercury bulk operations) is emulated via point-to-point messaging. Does not support initializing multiple instances simultaneously. Other BMI methods besides TCP are not supported. For general BMI information see this paper .","title":"BMI"},{"location":"user/ofi/","text":"Note The implementation notes in this page are provided for reference and may be slightly out of date. If you are only looking for user documentation, please refer to the NA plugin documentation on this page . OFI Capabilities The OFI plugin makes use of the following libfabric capabilities: FI_EP_RDM FI_DIRECTED_RECV FI_READ FI_RECV FI_REMOTE_READ FI_REMOVE_WRITE FI_RMA FI_SEND FI_TAGGED FI_WRITE FI_SOURCE FI_SOURCE_ERR FI_ASYNC_IOV FI_CONTEXT FI_MR_BASIC Scalable endpoints Feature Matrix Supported Limited support or emulated (see footnote) Not supported Feature tcp verbs psm2 gni Source Addressing 1 1 Manual Progress 2 2 2 FI_WAIT_FD Scalable Endpoints 3 1 Emulated: source address is encoded in the message header. 2 Emulated: the provider is using a thread to drive background progress. 3 Emulated: provider resources are shared. Performance Below is a performance comparison of the libfabric plugin with available libfabric providers when using both wait and busy spin mechanisms, mercury v1.0.0 and libfabric v1.7.0a1. InfiniBand verbs;rxm Performance is measured between two nodes on ALCF's cooley cluster using the FDR InfiniBand interface mlx5_0 . The following plot shows the RPC average time compared to ofi+tcp when using one single RPC in-flight: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with pull bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with push bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight: Omni-Path psm2 Performance is measured between two nodes on LCRC's bebop cluster using the Omni-Path interface with PSM2 v11.2.23. The following plot shows the RPC average time compared to ofi+tcp when using one single RPC in-flight: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with pull bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with push bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight: Aries gni Performance is measured between two Haswell nodes (debug queue in exclusive mode) on Nersc's cori system using the interface ipogif0 with uGNI v6.0.14.0. The following plot shows the RPC average time compared to ofi+tcp when using one single RPC in-flight: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with pull bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with push bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight:","title":"Libfabric Plugin"},{"location":"user/ofi/#ofi-capabilities","text":"The OFI plugin makes use of the following libfabric capabilities: FI_EP_RDM FI_DIRECTED_RECV FI_READ FI_RECV FI_REMOTE_READ FI_REMOVE_WRITE FI_RMA FI_SEND FI_TAGGED FI_WRITE FI_SOURCE FI_SOURCE_ERR FI_ASYNC_IOV FI_CONTEXT FI_MR_BASIC Scalable endpoints","title":"OFI Capabilities"},{"location":"user/ofi/#feature-matrix","text":"Supported Limited support or emulated (see footnote) Not supported Feature tcp verbs psm2 gni Source Addressing 1 1 Manual Progress 2 2 2 FI_WAIT_FD Scalable Endpoints 3 1 Emulated: source address is encoded in the message header. 2 Emulated: the provider is using a thread to drive background progress. 3 Emulated: provider resources are shared.","title":"Feature Matrix"},{"location":"user/ofi/#performance","text":"Below is a performance comparison of the libfabric plugin with available libfabric providers when using both wait and busy spin mechanisms, mercury v1.0.0 and libfabric v1.7.0a1.","title":"Performance"},{"location":"user/ofi/#infiniband-verbsrxm","text":"Performance is measured between two nodes on ALCF's cooley cluster using the FDR InfiniBand interface mlx5_0 . The following plot shows the RPC average time compared to ofi+tcp when using one single RPC in-flight: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with pull bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with push bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight:","title":"InfiniBand verbs;rxm"},{"location":"user/ofi/#omni-path-psm2","text":"Performance is measured between two nodes on LCRC's bebop cluster using the Omni-Path interface with PSM2 v11.2.23. The following plot shows the RPC average time compared to ofi+tcp when using one single RPC in-flight: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with pull bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with push bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight:","title":"Omni-Path psm2"},{"location":"user/ofi/#aries-gni","text":"Performance is measured between two Haswell nodes (debug queue in exclusive mode) on Nersc's cori system using the interface ipogif0 with uGNI v6.0.14.0. The following plot shows the RPC average time compared to ofi+tcp when using one single RPC in-flight: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with pull bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with push bulk transfer performance compared to ofi+tcp with various transfer sizes: Same plot but with 16 RPCs in-flight:","title":"Aries gni"},{"location":"user/overview/","text":"Mercury is composed of three main layers: the network abstraction layer , which provides a high-performance communication interface on top of lower level network fabrics. the RPC layer , which provides users with the necessary components for sending and receiving RPC metadata (small messages). This includes serialization and deserialization of function arguments; the bulk layer , which provides the necessary components for handling large arguments---this implies large data transfers through RMA; the ( optional ) high-level RPC layer , which aims at providing a convenience API, builds on top of the lower layers and provides macros for generating RPC stubs as well as serialization and deserialization functions. These three main layers can be summarized in the following diagram: By definition, an RPC call is initiated by one process, referred to as origin , and forwarded to another process, which will execute the call, and referred to as target . Each side, origin and target, uses an RPC processor to serialize and deserialize parameters sent through the interface. Calling functions with relatively small arguments results in using a short messaging mechanism exposed by the network abstraction layer, whereas functions containing large data arguments additionally use a remote memory access (RMA) mechanism. Note that when the bulk data is small enough, Mercury will automatically embed it along with the metadata if it can fit.","title":"Overview"},{"location":"user/sm/","text":"Note The implementation notes in this page are provided for reference and may be slightly out of date. If you are only looking for user documentation, please refer to the NA plugin documentation on this page . Mercury defines a network abstraction layer that allows definition of plugins for high-speed networks. In the case of intra-node communication, the most efficient way of accessing memory between processes is to use shared-memory. Introduction Mercury's network abstraction layer is designed to take advantage of high-speed networks by providing two types of messaging: small messaging (low-latency) and large transfers (high-bandwidth). Small messages fall into two categories: unexpected and expected. Large transfers use a one-sided mechanism for efficient access to remote memory, enabling transfers to be made without intermediate copy. The interface currently provides implementations for BMI, MPI, CCI and OFI libfabric, which are themselves abstractions on top of the common HPC network protocols. When doing communication locally on the same node between separate processes, it is desirable to bypass the loopback network interface and directly access/share memory regions, thereby increasing bandwidth and decreasing latency of the transfers. While the CCI plugin already provides a shared memory transport, it currently has some inherent limitations: handling is explicit and not transparent to the user; it requires explicit use of the CCI external library; it uses a connection thread internally; CCI only provides RMA registration per contiguous segment region which prevents users from transferring non-contiguous regions in one single RMA operation. It is also worth noting that other libraries such as libfabric support shared memory optimization, though having an independent shared-memory plugin that can be used with other transports at the same time, in a transparent manner, (and that can provide optimal performance) is an important feature for mercury. This document assumes that the reader already has knowledge of Mercury and its layers (NA / HG / HG Bulk). Adding shared memory support to mercury is referenced under the GitHub issue #75 . Requirements The design of this plugin follows three main requirements: Reuse existing shared-memory technology and concepts to the degree possible; Make progress on conventional and shared-memory communication simultaneously without busy waiting; Use plugin transparently (i.e., ability to use the same address for both conventional and shared memory communication). SM Plugin Architecture The plugin can be decomposed into multiple parts: lookup , short messages (unexpected and expected); RMA transfers ; progress . Lookup, connection and set up of exchange channels between processes is initialized through UNIX domain sockets. One listening socket is created on the listening processes, which then accept connections in a non blocking manner and exchange address channel information between peers. Short Messages For short messages, we use an mmap'ed POSIX shared memory object combined to a signaling interface that allows either party to be notified when a new message has been written into the shared memory space. One region is created per listening interface that allows processes to post short messages, by first reserving a buffer atomically in the mmap'ed shared memory object and then signaling the destination that it has been copied (in a non blocking manner). This requires a 2-way signaling channel (based on either an eventfd or a named pipe if the former is not available) per process/connection ( eventfd descriptors can be exchanged over UNIX domain sockets through ancillary data). The number of buffers that are mmap'ed is fixed and its global size pre-defined to 64 (the size of a 64-bit atomic value) pages of 4 KB. CCI and MPICH for instance use different methods, CCI exposes 64 lines of 64-byte buffers with a default maximum send size of 256 bytes, MPICH exposes 8 buffers of 32 KB and copies messages in a pipelined fashion. The sender waits until there is an empty buffer, then fills it in and marks the number of bytes copied. CCI on the other hand uses an mmap'ed ring buffer for message headers and fails when the total number of buffer has been exhausted. In our case, we combine both approaches, buffers are reserved and marked with the number of bytes copied. Large Transfers Large transfers do not require explicit signaling between processes and CMA (cross-memory attach) can be used directly without mmap (on Linux platforms that support CMA as of kernel v3.2, see also this page for security requirements). In that case, the only arguments needed are the remote process ID as well as a local and remote iovec that describe the memory segments that are to be transferred. Note that in this case, the SM plugin performs better by registering non-contiguous memory segments and does a single scatter/gather operation between local and remote regions. Note also that passing local and remote handles requires the base address of the memory regions that needs to be accessed to be first communicated to the issuing process, though this is part of the NA infrastructure, which also implies serialization, exchange and deserialization of remote memory handles. Progress is made through epoll() / poll() / kqueue() only on connections and message signaling interfaces that are registered to a polling set, RMA operations using CMA complete immediately after the process_vm_readv() or process_vm_writev() calls complete. Simultaneous Progress The second requirement is the ability to make progress simultaneously over different plugins without busing polling. In order to do that, the easiest and most efficient way is to make use of the kernel's existing file descriptor infrastructure. That method consists of exposing a file descriptor from the NA plugin and add it to a global polling set of NA plugin file descriptors. Making progress on that set of file descriptors is then made through the epoll() / poll() / kqueue() system calls. When one file descriptor wakes up , the NA layer can then determine which plugin that file descriptor belongs to and enter the corresponding progress functions to complete the operation. When the NA plugins supports it (e.g., SM, CCI, OFI), progress can be made without any latency overhead, which would otherwise be introduced by entering multiple NA_Progress() calls in order to do busy polling. Transparent Use Transparent use is essential for a shared-memory plugin as adding an explicit condition to switch between local and remote operations is not always reasonable, both in terms of performance and convenience. This mode of operation can be enabled within Mercury through the CMake option MERCURY_USE_SM_ROUTING . When enabled, Mercury internally creates a separate NA SM class and makes progress on that class as well as on the requested class (e.g., OFI, CCI). Local node detection is enabled by generating a UUID for the node and storing that UUID in the NA_SM_TMP_DIRECTORY-NA_SM_SHM_PREFIX directory. When a lookup call is issued, the string passed is parsed and the UUID compared with the locally stored UUID. Performance Below is a performance comparison of the shared-memory plugin when using both wait and busy spin mechanisms, CCI v2.2, libfabric v1.7.0a1 and mercury v1.0.0. The following plot shows the RPC average time with one RPC in flight: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with pull bulk transfer performance compared to existing plugins with various transfer sizes: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with push bulk transfer performance compared to existing plugins with various transfer sizes: Same plot but with 16 RPCs in-flight:","title":"Shared-Memory Plugin"},{"location":"user/sm/#introduction","text":"Mercury's network abstraction layer is designed to take advantage of high-speed networks by providing two types of messaging: small messaging (low-latency) and large transfers (high-bandwidth). Small messages fall into two categories: unexpected and expected. Large transfers use a one-sided mechanism for efficient access to remote memory, enabling transfers to be made without intermediate copy. The interface currently provides implementations for BMI, MPI, CCI and OFI libfabric, which are themselves abstractions on top of the common HPC network protocols. When doing communication locally on the same node between separate processes, it is desirable to bypass the loopback network interface and directly access/share memory regions, thereby increasing bandwidth and decreasing latency of the transfers. While the CCI plugin already provides a shared memory transport, it currently has some inherent limitations: handling is explicit and not transparent to the user; it requires explicit use of the CCI external library; it uses a connection thread internally; CCI only provides RMA registration per contiguous segment region which prevents users from transferring non-contiguous regions in one single RMA operation. It is also worth noting that other libraries such as libfabric support shared memory optimization, though having an independent shared-memory plugin that can be used with other transports at the same time, in a transparent manner, (and that can provide optimal performance) is an important feature for mercury. This document assumes that the reader already has knowledge of Mercury and its layers (NA / HG / HG Bulk). Adding shared memory support to mercury is referenced under the GitHub issue #75 .","title":"Introduction"},{"location":"user/sm/#requirements","text":"The design of this plugin follows three main requirements: Reuse existing shared-memory technology and concepts to the degree possible; Make progress on conventional and shared-memory communication simultaneously without busy waiting; Use plugin transparently (i.e., ability to use the same address for both conventional and shared memory communication).","title":"Requirements"},{"location":"user/sm/#sm-plugin-architecture","text":"The plugin can be decomposed into multiple parts: lookup , short messages (unexpected and expected); RMA transfers ; progress . Lookup, connection and set up of exchange channels between processes is initialized through UNIX domain sockets. One listening socket is created on the listening processes, which then accept connections in a non blocking manner and exchange address channel information between peers.","title":"SM Plugin Architecture"},{"location":"user/sm/#short-messages","text":"For short messages, we use an mmap'ed POSIX shared memory object combined to a signaling interface that allows either party to be notified when a new message has been written into the shared memory space. One region is created per listening interface that allows processes to post short messages, by first reserving a buffer atomically in the mmap'ed shared memory object and then signaling the destination that it has been copied (in a non blocking manner). This requires a 2-way signaling channel (based on either an eventfd or a named pipe if the former is not available) per process/connection ( eventfd descriptors can be exchanged over UNIX domain sockets through ancillary data). The number of buffers that are mmap'ed is fixed and its global size pre-defined to 64 (the size of a 64-bit atomic value) pages of 4 KB. CCI and MPICH for instance use different methods, CCI exposes 64 lines of 64-byte buffers with a default maximum send size of 256 bytes, MPICH exposes 8 buffers of 32 KB and copies messages in a pipelined fashion. The sender waits until there is an empty buffer, then fills it in and marks the number of bytes copied. CCI on the other hand uses an mmap'ed ring buffer for message headers and fails when the total number of buffer has been exhausted. In our case, we combine both approaches, buffers are reserved and marked with the number of bytes copied.","title":"Short Messages"},{"location":"user/sm/#large-transfers","text":"Large transfers do not require explicit signaling between processes and CMA (cross-memory attach) can be used directly without mmap (on Linux platforms that support CMA as of kernel v3.2, see also this page for security requirements). In that case, the only arguments needed are the remote process ID as well as a local and remote iovec that describe the memory segments that are to be transferred. Note that in this case, the SM plugin performs better by registering non-contiguous memory segments and does a single scatter/gather operation between local and remote regions. Note also that passing local and remote handles requires the base address of the memory regions that needs to be accessed to be first communicated to the issuing process, though this is part of the NA infrastructure, which also implies serialization, exchange and deserialization of remote memory handles. Progress is made through epoll() / poll() / kqueue() only on connections and message signaling interfaces that are registered to a polling set, RMA operations using CMA complete immediately after the process_vm_readv() or process_vm_writev() calls complete.","title":"Large Transfers"},{"location":"user/sm/#simultaneous-progress","text":"The second requirement is the ability to make progress simultaneously over different plugins without busing polling. In order to do that, the easiest and most efficient way is to make use of the kernel's existing file descriptor infrastructure. That method consists of exposing a file descriptor from the NA plugin and add it to a global polling set of NA plugin file descriptors. Making progress on that set of file descriptors is then made through the epoll() / poll() / kqueue() system calls. When one file descriptor wakes up , the NA layer can then determine which plugin that file descriptor belongs to and enter the corresponding progress functions to complete the operation. When the NA plugins supports it (e.g., SM, CCI, OFI), progress can be made without any latency overhead, which would otherwise be introduced by entering multiple NA_Progress() calls in order to do busy polling.","title":"Simultaneous Progress"},{"location":"user/sm/#transparent-use","text":"Transparent use is essential for a shared-memory plugin as adding an explicit condition to switch between local and remote operations is not always reasonable, both in terms of performance and convenience. This mode of operation can be enabled within Mercury through the CMake option MERCURY_USE_SM_ROUTING . When enabled, Mercury internally creates a separate NA SM class and makes progress on that class as well as on the requested class (e.g., OFI, CCI). Local node detection is enabled by generating a UUID for the node and storing that UUID in the NA_SM_TMP_DIRECTORY-NA_SM_SHM_PREFIX directory. When a lookup call is issued, the string passed is parsed and the UUID compared with the locally stored UUID.","title":"Transparent Use"},{"location":"user/sm/#performance","text":"Below is a performance comparison of the shared-memory plugin when using both wait and busy spin mechanisms, CCI v2.2, libfabric v1.7.0a1 and mercury v1.0.0. The following plot shows the RPC average time with one RPC in flight: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with pull bulk transfer performance compared to existing plugins with various transfer sizes: Same plot but with 16 RPCs in-flight: The following plot shows the RPC with push bulk transfer performance compared to existing plugins with various transfer sizes: Same plot but with 16 RPCs in-flight:","title":"Performance"}]}