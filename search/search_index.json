{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"about/","title":"About","text":"<p>Engineers and scientists working in a heterogeneous computing environment often want to distribute the various tasks of an application\u2014such as computation, storage, analysis, or visualization\u2014to different types of resources and libraries. Often, a technique known as Remote Procedure Call (RPC) is used that allows local calls to be transparently executed onto remote resources.</p> <p>Using common RPC frameworks on a High-Performance Computing (HPC) system presents two limitations, however: the inability to take advantage of the native network transport and the inability to transfer large amounts of data.</p> <p>To avoid these limitations, we developed Mercury\u2014an RPC interface specifically designed for HPC. Mercury builds on a small, easily ported network abstraction layer, providing operations closely matched to the capabilities of high-performance network environments. Unlike most other RPC frameworks, Mercury directly supports handling remote calls containing large data arguments. Moreover, Mercury\u2019s network protocol is designed to scale to thousands of clients.</p>"},{"location":"about/#collaborators","title":"Collaborators","text":""},{"location":"help/","title":"Help","text":""},{"location":"help/#mailing-lists","title":"Mailing Lists","text":"<p>There are two mailing lists described below that users may wish to subscribe to:</p> <ul> <li>mercury@lists.mcs.anl.gov | subscribe |</li> </ul> <p>This mailing list is available for users to discuss Mercury issues among each other. Users must subscribe before they can send e-mails to the list.</p> <ul> <li>mercury-devel@lists.mcs.anl.gov | subscribe |</li> </ul> <p>This mailing list is available for Mercury developers to discuss implementation of new and existing features, NA plugins, etc. Developers must subscribe before they can send e-mails to the list.</p>"},{"location":"help/#issue-tracking","title":"Issue Tracking","text":"<p>Current and past issues can be found on GitHub: </p> <p>You may check that the latest build passes by looking at the CI: </p> <p>Or for more details you may also look at what the build tests have reported onto the CDash Dashboard: </p>"},{"location":"help/#contribute","title":"Contribute","text":"<p>We welcome all contributions to Mercury!</p> <ul> <li>Code Patches</li> <li>Requests for new features</li> <li>Feedback on using Mercury and suggestions for improvements</li> </ul> <p>Please feel free to send any of the above to the mercury development mailing list or create an issue/pull request directly on GitHub. We have many things planned for Mercury and limited developer time available; contact us if you want to learn more about RPC on HPC systems or if you are looking for an interesting project to contribute to.</p> <p>Info</p> <p>We require a Contributor License Agreement (CLA) to be filled out and sent to:  You may use either an individual CLA for your own personal contributions or a corporate CLA for contributions from your organization.</p>"},{"location":"publications/","title":"Publications","text":""},{"location":"publications/#conference-proceedings","title":"Conference Proceedings","text":"<ul> <li>J. Soumagne, D. Kimpe, J. Zounmevo, M. Chaarawi, Q. Koziol, A. Afsahi, and R. Ross, Mercury: Enabling Remote Procedure Call for High-Performance Computing, IEEE International Conference on Cluster Computing, Sep 2013. | paper | slides |</li> </ul>"},{"location":"publications/#journals","title":"Journals","text":"<ul> <li>J. Soumagne, P. Carns, R. Ross, Advancing RPC for Data Services at Exascale, IEEE Data Engineering Bulletin, Vol. 43 No. 1, 23\u201334, March 2020. | paper |</li> </ul>"},{"location":"publications/#posters","title":"Posters","text":"<ul> <li>J. Soumagne, P. Carns, D. Kimpe, Q. Koziol, and R. Ross, A Remote Procedure Call Approach for Extreme Scale Services, Computational Science and Engineering Software Sustainability and Productivity Challenges (CSESSP) Workshop, Oct 2015. | paper | poster |</li> </ul>"},{"location":"publications/#past-presentations","title":"Past Presentations","text":"<ul> <li>SC18 BoF, Sep 2018. | slides |</li> <li>Nersc CS Seminar, Jun 2017. | slides |</li> <li>Intel F2F, Jul 2016. | slides |</li> <li>INRIA Joint-lab Workshop, Nov 2013. | slides |</li> </ul>"},{"location":"publications/#additional-publications","title":"Additional Publications","text":"<p>Please refer to these two additional links for work that was realized within the context of Mochi and for work from projects that are using Mercury and Mochi:</p> <ul> <li>Mochi Publications. | link |</li> <li>Mochi Projects. | link |</li> </ul>"},{"location":"releases/CHANGES_v2.0.1/","title":"Release Notes v2.0.1","text":""},{"location":"releases/CHANGES_v2.0.1/#summary","title":"Summary","text":"<p>This version brings a few bug fixes and updates to our v2.0.0 release.</p>"},{"location":"releases/CHANGES_v2.0.1/#new-features","title":"New features","text":"<ul> <li>Improve logging system and add <code>HG_LOG_SUBSYS</code> environment variable that can be used in combination with <code>HG_LOG_LEVEL</code> to select log sub-systems.<ul> <li>Add <code>min_debug</code> log level to keep debug traces. Traces get printed when an error occurs.</li> <li>[HG] Add <code>HG_Set_log_subsys()</code>.</li> </ul> </li> <li>[NA] Add support for message size hints though max_unexpected_size and max_expected_size hints. Supported with OFI, BMI and MPI plugins.</li> <li>[NA BMI/SM/OFI] Support sends to self address.</li> <li>[HG/NA] Add <code>HG_HOSTUNREACH</code>/<code>NA_HOSTUNREACH</code> error codes.</li> </ul>"},{"location":"releases/CHANGES_v2.0.1/#bug-fixes","title":"Bug fixes","text":"<ul> <li>[HG]<ul> <li>Add missing check for NULL addr passed to <code>HG_Forward()</code>.</li> <li>Remove unnecessary <code>spinwait()</code> and track handle in completion queue.</li> <li>Fix handle refcount if <code>HG_Respond()</code> fails.</li> <li>Remove race in <code>HG_Trigger()</code> optimization that was skipping signaling.</li> </ul> </li> <li>[HG bulk]<ul> <li>Prevent virtual handle data to be sent eagerly.</li> <li>Ensure underlying error codes from NA are returned back to user.</li> </ul> </li> <li>[HG util]<ul> <li>Fix timeout passed to <code>pthread_cond_timedwait()</code> when <code>CLOCK_MONOTONIC_COARSE</code> is used.</li> <li>Remove check for <code>STDERR_FILENO</code>.</li> <li>Add best-effort C++ compatibility for atomics.</li> </ul> </li> <li>[NA]<ul> <li>Ensure completion callback is called after OP ID is fully released.</li> </ul> </li> <li>[NA BMI]<ul> <li>Rework and simplify NA BMI code and remove extra allocations.</li> </ul> </li> <li>[NA SM]<ul> <li>Prevent potential race on bulk handle that was freed.</li> <li>Fix release of invalid addresses.</li> <li>Prevent race in address resolution.</li> </ul> </li> <li>[NA OFI]<ul> <li>Allow libfabric to return canceled operations.</li> <li>Yield to other threads when using PSM2.</li> <li>Return and convert OFI error codes back to upper layers.</li> <li>Ensure selected domain matches address format.</li> <li>Prevent tcp protocol to be used on macOS.</li> <li>Fix potential memory leak in <code>na_ofi_provider_check()</code>.</li> <li>Add addr pool to prevent addr allocation on unexpected recv.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.0.1/#known-issues","title":"Known Issues","text":"<ul> <li>[NA OFI]<ul> <li>[tcp/verbs;ofi_rxm] Using more than 256 peers requires <code>FI_UNIVERSE_SIZE</code> to be set.</li> <li>[tcp;ofi_rxm] Remains unstable, use <code>sockets</code> as a fallback in case of issues.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.1.0/","title":"Release Notes v2.1.0","text":""},{"location":"releases/CHANGES_v2.1.0/#summary","title":"Summary","text":"<p>This version brings bug fixes and updates to our v2.0.0 release.</p>"},{"location":"releases/CHANGES_v2.1.0/#new-features","title":"New features","text":"<ul> <li>[NA UCX]<ul> <li>Add initial support for UCX. As opposed to other plugins, the UCX plugin is able through the <code>ucx+all</code> init string to decide on which protocol to use.</li> </ul> </li> <li>[NA SM]<ul> <li>Update default addressing format to follow <code>PID-ID</code> instead of <code>PID/ID</code></li> <li>Allow for passing of arbitrary SM init URIs</li> <li>Enable support for bulk handle address binding</li> <li>Add <code>sm_info_string</code> field to HG init info, which allows for specific init URIs to be used for SM when <code>auto_sm</code> is enabled.</li> </ul> </li> <li>[NA]<ul> <li>Add <code>thread_mode</code> to NA init options and add <code>NA_THREAD_MODE_SINGLE</code> to relax thread-safety requirements.</li> <li>Add <code>na_cb_info_recv_expected</code> to return <code>actual_buf_size</code>.</li> <li>Add <code>na_cb_type_to_string()</code> to convert callback enum type to printable string.</li> </ul> </li> <li>[NA IP]<ul> <li>Add <code>na_ip_check_interface()</code> routine that can be used by plugins to select IP interface to use.</li> </ul> </li> <li>[HG util]<ul> <li>Add <code>hg_mem_header_alloc()</code>/<code>free()</code> calls to allocate buffers with a preceding header.</li> <li>Add thread annotation module for thread safety analysis.</li> <li>Add <code>mercury_mem_pool</code> memory pool to facilitate allocation and memory registration of a pool of buffers.</li> <li>Enable format argument checking on logging functions.</li> <li>Add <code>hg_time_from_ms()</code> and <code>hg_time_to_ms()</code> for time conversion to ms.</li> </ul> </li> <li>[HG bulk]<ul> <li>Return transfer size <code>size</code> through <code>hg_cb_info</code> and <code>hg_cb_info_bulk</code>.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.1.0/#bug-fixes","title":"Bug fixes","text":"<ul> <li>[NA OFI]<ul> <li>Require at least v1.7.0 of libfabric.</li> <li>Fix handling of completion queue events and completion of retried operations that fail.</li> <li>Fix progress loop to reduce time calls.</li> <li>Force per-region registration for all providers and remove deprecated FI_MR_SCALABLE type of registrations and global MR keys.</li> </ul> </li> <li>[NA SM]<ul> <li>Refactor and clean up sends/cancelation/retries/rma/address keys.</li> <li>Remove use of usernames from SM paths.</li> </ul> </li> <li>[HG util]<ul> <li>Prevent use of <code>CLOCK_MONOTONIC_COARSE</code> on PPC platforms and default to <code>CLOCK_MONOTONIC</code>.</li> <li>Fix debug logs that were not freed at exit.</li> <li>Remove return value of mutex lock/unlock routines.</li> <li>Fix log subsys to prevent setting duplicates.</li> <li>Simplify handling of compiler attributes and add <code>mercury_compiler_attributes.h</code> module.</li> <li>Remove <code>hg_util_</code> integer types and use <code>stdint.h</code>.</li> <li>Remove OpenPA dependency for atomics and use built-in atomics instead (requires gcc &gt;= 4.7).</li> </ul> </li> <li>[HG/HG util/NA]<ul> <li>Fix thread safety warnings and potential thread locking issues.</li> <li>Fix log level set routines that were not enabling the underlying log sub-system.</li> <li>Avoid reading system timers and optimize handling of timeouts. </li> </ul> </li> <li>[HG bulk]<ul> <li>Fix erroneous call to <code>NA_Mem_deregister()</code> when handle is deserialized.</li> <li>Correctly mark op as canceled if canceled from NA.</li> <li>Clean up and simplify handling of NA error return codes in callback.</li> <li>Minimal tracking of bulk handles that are not freed.</li> </ul> </li> <li>[HG Core]<ul> <li>Fix error handling when NA send fails during an <code>HG_Forward()</code> operation.</li> <li>Correctly map NA error return code back to HG error return code in user callback.</li> <li>Correctly print HG handle debug information.</li> <li>In short responses like ACKs, leave room at the front of a buffer for the NA header, and expect the header to be present.</li> <li>Fix potential issue on context destroy where handles could have been reposted while finalizing if RPCs were still in the queue.</li> </ul> </li> <li>[General]<ul> <li>Warning and static analysis issues were fixed.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.1.0/#known-issues","title":"Known Issues","text":"<ul> <li>[NA OFI]<ul> <li>[tcp/verbs;ofi_rxm] Using more than 256 peers requires <code>FI_UNIVERSE_SIZE</code> to be set.</li> <li>[tcp;ofi_rxm] Remains unstable, use <code>sockets</code> as a fallback in case of issues.<ul> <li>Please note that libfabric v1.13.0 and v1.13.1 have address management issues with that transport. Please either downgrade to v1.12.1 (or earlier) or upgrade to v1.13.2 (or later).</li> </ul> </li> </ul> </li> <li>[NA UCX]<ul> <li><code>NA_Addr_to_string()</code> cannot be used on non-listening processes to convert a self-address to a string.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.2.0/","title":"Release Notes v2.2.0","text":""},{"location":"releases/CHANGES_v2.2.0/#summary","title":"Summary","text":"<p>This version brings bug fixes and updates to our v2.0.0 release.</p>"},{"location":"releases/CHANGES_v2.2.0/#new-features","title":"New features","text":"<ul> <li>[NA OFI]<ul> <li>Choose addr format dynamically based on user preferences</li> <li>Add support for IPv6</li> <li>Add support for <code>FI_SOCKADDR_IB</code></li> <li>Add support for <code>FI_ADDR_STR</code> and shm provider</li> <li>Add support for <code>FI_ADDR_OPX</code> and opx provider</li> <li>Add support for HPE <code>cxi</code> provider,   init info format for <code>cxi</code> is:<ul> <li><code>NIC:PID</code> (both or only one may be passed), NIC is <code>cxi[0-9]</code>, PID is <code>[0-510]</code></li> </ul> </li> <li>Use <code>hwloc</code> to select interface to use if NIC information is available   (only supported by <code>cxi</code> at the moment)</li> <li>Support device memory types and <code>FI_HMEM</code> for <code>verbs</code> and <code>cxi</code> providers</li> <li>Add support for <code>FI_THREAD_DOMAIN</code><ul> <li>Passing <code>NA_THREAD_MODE_SINGLE</code> will relax default <code>FI_THREAD_SAFE</code> thread mode and use <code>FI_THREAD_DOMAIN</code> instead.</li> </ul> </li> <li>Update min required version to libfabric 1.9</li> <li>Improve debug output to print verbose FI info of selected provider</li> </ul> </li> <li>[NA UCX]<ul> <li>Use active messaging <code>UCP_FEATURE_AM</code> for unexpected messages (only), this   allows for removal of address resolution and retry on first message to   exchange connection IDs</li> <li>Turn on mempool by default</li> <li>Support device memory types</li> <li>Bump min required version to 1.10</li> </ul> </li> <li>[NA PSM]<ul> <li>Add mercury NA plugin for the qlogic/intel PSM interface<ul> <li>Also support PSM2 (Intel OmniPath) through the PSM NA plugin</li> </ul> </li> </ul> </li> <li>[NA SM]<ul> <li>Add support for 0-size messages</li> </ul> </li> <li>[NA]<ul> <li>Add <code>na_addr_format</code> init info</li> <li>Add <code>request_mem_device</code> init info when GPU support is requested</li> <li>Update <code>NA_Mem_register()</code> API call to support memory types (e.g., CUDA, ROCm, ZE) and devices IDs</li> <li>Add <code>na_loc</code> module for <code>hwloc</code> detection</li> <li>Remove <code>na_uint</code>, <code>na_int</code>, <code>na_bool_t</code> and <code>na_size_t</code> types</li> <li>Use separate versioning for library and update to v3.0.0</li> </ul> </li> <li>[NA IP]<ul> <li>Refactor <code>na_ip_check_interface()</code> to only use <code>getaddrinfo()</code> and <code>getifaddrs()</code></li> <li>Add family argument to force detection of IPv4/IPv6 addresses</li> <li>Add ip debug log</li> </ul> </li> <li>[NA Test]<ul> <li>Introduce new perf tests to measure msg latency, put / get bandwidth. These benchmarks produce results that are comparable with OSU benchmarks.</li> </ul> </li> <li>[HG util]<ul> <li>Add <code>mercury_byteswap.h</code> for <code>bswap</code> macros</li> <li>Add <code>mercury_inet.h</code> for <code>htonll</code> and <code>ntohll</code> routine</li> <li>Add <code>mercury_param.h</code> to use <code>sys/param.h</code> or <code>MIN/MAX</code> macros etc</li> <li>Add alternative log names: <code>err</code>, <code>warn</code>, <code>trace</code>, <code>dbg</code></li> <li>Use separate versioning for library and update to v3.0.0</li> </ul> </li> <li>[HG bulk]<ul> <li>Add support for memory attributes through a new <code>HG_Bulk_create_attr()</code> routine (support CUDA, ROCm, ZE)</li> </ul> </li> <li>[HG]<ul> <li>Remove <code>MERCURY_ENABLE_STATS</code> CMake option and use <code>'diag'</code> log subsys instead<ul> <li>Modify behavior of <code>stats</code> field to turn on diagnostics</li> <li>Refactor existing counters (used only if debug is on)</li> </ul> </li> <li>Add checksum levels that can be manually controlled at runtime (disabled by default, <code>HG_CHECKSUM_NONE</code> level)</li> <li>Update to mchecksum v2.0</li> <li>Add <code>HG_Set_log_func()</code> and <code>HG_Set_log_stream()</code> to control log output</li> </ul> </li> <li>[HG hl]<ul> <li>The deprecated mercury high-level library and high-level macros have now been removed.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.2.0/#bug-fixes","title":"Bug fixes","text":"<ul> <li>[NA OFI]<ul> <li>Switch <code>tcp</code> provider to <code>FI_PROGRESS_MANUAL</code></li> <li>Prevent empty authorization keys from being passed</li> <li>Check max MR key used when <code>FI_MR_PROV_KEY</code> is not set</li> <li>New implementation of address management<ul> <li>Fix duplicate addresses on multithreaded lookups</li> <li>Redefine address keys and raw addresses to prevent allocations</li> <li>Use FI addr map to lookup by FI addr</li> <li>Improve serialization and deserialization of addresses</li> </ul> </li> <li>Fix provider table and use EP proto</li> <li>Refactor and clean up plugin initialization <ul> <li>Clean up ip and domain checking</li> <li>Ensure interface name is not used as domain name for verbs etc</li> <li>Use NA IP module and add missing <code>NA_OFI_VERIFY_PROV_DOM</code> for <code>tcp</code> provider</li> <li>Rework handling of <code>fi_info</code> to open fabric/domain/endpoint</li> <li>Separate fabric from domain and keep single domain per NA class</li> <li>Refactor handling of scalable vs standard endpoints</li> </ul> </li> <li>Improve handling of retries after <code>FI_EAGAIN</code> return code<ul> <li>Abort retried ops after default 90s timeout</li> <li>Abort ops to a target being retried after first <code>NA_HOSTUNREACH</code> error in CQ</li> </ul> </li> </ul> </li> <li>[NA UCX]<ul> <li>Fix potential error not returned correctly on <code>conn_insert()</code></li> <li>Fix potential double free of worker_addr</li> <li>Remove use of unified mode</li> <li>Ensure address key is correctly reset</li> <li>Fix hostname / net device parsing to allow for multiple net devices</li> </ul> </li> <li>[HG util]<ul> <li>Make sure we round up ms time conversion, this ensures that small timeouts do not result in busy spin.</li> <li>Use sched_yield() instead of deprecated pthread_yield()</li> <li>Fix <code>'none'</code> log level not recognized</li> <li>Fix external logging facility</li> <li>Let mercury log print counters on exit when debug outlet is on</li> </ul> </li> <li>[HG proc]<ul> <li>Prevent call to <code>save_ptr()/restore_ptr()</code> during <code>HG_FREE</code></li> </ul> </li> <li>[HG Bulk]<ul> <li>Remove some <code>NA_CANCELED</code> event warnings.</li> </ul> </li> <li>[HG]<ul> <li>Properly handle error when overflow bulk transfer is interrupted. Previously the RPC callback was triggered regarldless, potentially causing issues.</li> </ul> </li> <li>[CMake]<ul> <li>Correctly set INSTALL_RPATH for target libraries</li> <li>Split <code>mercury.pc</code> pkg config file into multiple <code>.pc</code> files for <code>mercury_util</code> and <code>na</code> to prevent from overlinking against those libraries when using pkg config.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.2.0/#known-issues","title":"Known Issues","text":"<ul> <li>[NA OFI]<ul> <li>[tcp/verbs;ofi_rxm] Using more than 256 peers requires <code>FI_UNIVERSE_SIZE</code> to be set.</li> </ul> </li> <li>[NA UCX]<ul> <li><code>NA_Addr_to_string()</code> cannot be used on non-listening processes to convert a self-address to a string.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.3.0/","title":"Release Notes v2.3.0","text":""},{"location":"releases/CHANGES_v2.3.0/#summary","title":"Summary","text":"<p>This version brings bug fixes and updates to our v2.0.0 release.</p>"},{"location":"releases/CHANGES_v2.3.0/#new-features","title":"New features","text":"<ul> <li>[HG/NA]<ul> <li>Add <code>HG_Init_opt2()</code> / <code>HG_Core_init_opt2()</code> / <code>NA_Initialize_opt2()</code> to safely pass updated init info while maintaining ABI compatibility between versions</li> <li>Add <code>HG_Get_na_protocol_info()</code> / <code>HG_Free_na_protocol_info()</code> and add <code>hg_info</code> utility for basic listing of protocols</li> </ul> </li> <li>[HG]<ul> <li>Add support for multi-recv operations (OFI plugin only)<ul> <li>Currently disable multi-recv when auto SM is on</li> <li>Posted recv operations are in that case decoupled from pool of RPC handles</li> <li>Add <code>release_input_early</code> init info flag to attempt to release input buffers early once input is decoded</li> <li>Add <code>HG_Release_input_buf()</code> to manually release input buffer.</li> <li>Add also <code>no_multi_recv</code> init info option to force disabling multi-recv</li> </ul> </li> <li>Make use of subsys logs (<code>cls</code>, <code>ctx</code>, <code>addr</code>, <code>rpc</code>, <code>poll</code>) to control log output</li> <li>Add init info struct versioning</li> <li>Add <code>HG_Context_unpost()</code> / <code>HG_Core_context_unpost()</code> for optional 2-step context shutdown</li> </ul> </li> <li>[HG bulk]<ul> <li>Update to new logging system through <code>bulk</code> subsys log.</li> </ul> </li> <li>[HG proc]<ul> <li>Update to new logging system through <code>proc</code> subsys log.</li> </ul> </li> <li>[HG Test]<ul> <li>Refactor tests to separate perf tests from unit tests</li> <li>Add NA/HG test common library</li> <li>Add <code>hg_rate</code> / <code>hg_bw_write</code> and <code>hg_bw_read</code> perf tests<ul> <li>Perf test now supports multi-client / multi-server workloads</li> </ul> </li> <li>Add <code>BUILD_TESTING_UNIT</code> and <code>BUILD_TESTING_PERF</code> CMake options</li> </ul> </li> <li>[NA]<ul> <li>Add support for multi-recv operations<ul> <li>Add <code>NA_Msg_multi_recv_unexpected()</code> and <code>na_cb_info_multi_recv_unexpected</code> cb info</li> <li>Add <code>flags</code> parameter to <code>NA_Op_create()</code> and <code>NA_Msg_buf_alloc()</code></li> <li>Add <code>NA_Has_opt_feature()</code> to query multi recv capability</li> </ul> </li> <li>Remove <code>int</code> return type from NA callbacks and return <code>void</code></li> <li>Remove unused <code>timeout</code> parameter from <code>NA_Trigger()</code></li> <li><code>NA_Addr_free()</code> / <code>NA_Mem_handle_free()</code> and <code>NA_Op_destroy()</code> now return <code>void</code></li> <li><code>na_mem_handle_t</code> and <code>na_addr_t</code> types no longer include pointer type</li> <li>Add support for dynamically loaded plugins<ul> <li>Add <code>NA_PLUGIN_PATH</code> env variable to optionally control plugin loading path (default is <code>NA_INSTALL_PLUGIN_DIR</code>)</li> <li>Add <code>NA_INSTALL_PLUGIN_DIR</code> variable to control plugin install path (default is lib install path)</li> <li>Add <code>NA_USE_DYNAMIC_PLUGINS</code> CMake option (OFF by default)</li> </ul> </li> <li>Add ability to query protocol info from plugins<ul> <li>Add <code>NA_Get_protocol_info()</code>/<code>NA_Free_protocol_info()</code> API routines</li> <li>Add <code>na_protocol_info</code> struct to na_types</li> </ul> </li> <li>Bump NA library version to 4.0.0</li> </ul> </li> <li>[NA OFI]<ul> <li>Add support for multi-recv operations and use <code>FI_MSG</code></li> <li>Allocate multi-recv buffers using hugepages when available</li> <li>Switch to using <code>fi_senddata()</code> with immediate data for unexpected msgs<ul> <li><code>NA_OFI_UNEXPECTED_TAG_MSG</code> can be set to switch back to former behavior that uses tagged messages instead</li> </ul> </li> <li>Remove support for deprecated <code>psm</code> provider</li> <li>Control CQ interrupt signaling with <code>FI_AFFINITY</code> (only used if thread is bound to a single CPU ID)</li> <li>Enable <code>cxi</code> provider to use <code>FI_WAIT_FD</code></li> <li>Add <code>NA_OFI_OP_RETRY_TIMEOUT</code> and <code>NA_OFI_OP_RETRY_PERIOD</code><ul> <li>Once <code>NA_OFI_OP_RETRY_TIMEOUT</code> milliseconds elapse, retry is stopped and operation is aborted (default is 120000ms)</li> <li>When <code>NA_OFI_OP_RETRY_PERIOD</code> is set, operations are retried only every <code>NA_OFI_OP_RETRY_PERIOD</code> milliseconds (default is 0)</li> </ul> </li> <li>Add support for <code>tcp</code> with and without <code>ofi_rxm</code><ul> <li><code>tcp</code> defaults to <code>tcp;ofi_rxm</code> for libfabric &lt; 1.18</li> </ul> </li> <li>Enable plugin to be built as a dynamic plugin</li> <li>Add support for <code>get_protocol_info</code> to query list of protocols</li> <li>Add support for libfabric log redirection<ul> <li>Requires libfabric &gt;= 1.16.0, disabled if FI_LOG_LEVEL is set</li> <li>Add <code>libfabric</code> log subsys (off by default)</li> <li>Bump FI_VERSION to 1.13 when log redirection is supported</li> </ul> </li> </ul> </li> <li>[NA UCX]<ul> <li>Attempt to disable UCX backtrace if <code>UCX_HANDLE_ERRORS</code> is not set</li> <li>Add support for <code>UCP_EP_PARAM_FIELD_LOCAL_SOCK_ADDR</code><ul> <li>With UCX &gt;= 1.13 local src address information can now be specified on client to use specific interface and port</li> </ul> </li> <li>Set <code>CM_REUSEADDR</code> by default to enable reuse of existing listener addr after a listener exits abnormally</li> <li>Attempt to reconnect EP if disconnected<ul> <li>This concerns cases where a peer would have reappeared after a previous disconnection</li> </ul> </li> <li>Add support for <code>get_protocol_info</code>  to query list of protocols</li> <li>Enable plugin to be built as a dynamic plugin</li> </ul> </li> <li>[NA Test]<ul> <li>Update NA test perf to use multi-recv feature</li> <li>Update perf test to use hugepages</li> <li>Add support for multi-targets and add lookup test</li> <li>Install perf tests if <code>BUILD_TESTING_PERF</code> is <code>ON</code></li> </ul> </li> <li>[HG util]<ul> <li>Change return type of <code>hg_time_less()</code> to <code>bool</code></li> <li>Add <code>HG_LOG_WRITE_FUNC()</code> macro to pass func/line info<ul> <li>Add also <code>module</code> / <code>no_return</code> parameters to hg_log_write()</li> </ul> </li> <li>Add support for hugepage allocations</li> <li>Use <code>isb</code> for <code>cpu_spinwait</code> on <code>aarch64</code></li> <li>Add <code>mercury_dl</code> to support dynamically loaded modules</li> <li>Bump HG util version to 4.0.0</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.3.0/#bug-fixes","title":"Bug fixes","text":"<ul> <li>[HG]<ul> <li>Ensure init info version is compatible with previous versions of the struct</li> <li>Clean up and refactoring fixes</li> <li>Fix race condition in <code>hg_core_forward</code> with debug enabled</li> <li>Simplify RPC map and fix hashing for RPC IDs larger than 32-bit integer</li> <li>Refactor context pools and cleanup</li> <li>Fix potential leak on ack buffer</li> <li>Ensure list of created RPC handles is empty before closing context</li> <li>Bump default number of pre-allocated requests from 256 to 512 to make use of 2M hugepages by default</li> <li>Add extra error checking to prevent class mismatch</li> <li>Fix potential race when sending one-way RPCs to ourself</li> </ul> </li> <li>[HG Bulk]<ul> <li>Add extra error checking to prevent class mismatch</li> </ul> </li> <li>[HG Test]<ul> <li>Refactor <code>test_rpc</code> to correctly handle timeout return values</li> <li>Fix overflow of number of target / classes<ul> <li>Number of targets was limited to <code>UINT8_MAX</code></li> </ul> </li> </ul> </li> <li>[NA OFI]<ul> <li>Fix handling of extra caps to not always follow advertised caps<ul> <li>Ensure also that extra caps passed are honored by provider</li> </ul> </li> <li>Force <code>sockets</code> provider to use shared domains<ul> <li>This prevents a performance regression when multiple classes are being used (<code>FI_THREAD_DOMAIN</code> is therefore disabled for this provider)</li> </ul> </li> <li>Refactor unexpected and expected sends, retry of OFI operations, handling of RMA operations</li> <li>Always include <code>FI_DIRECTED_RECV</code> in primary caps</li> <li>Disable use of <code>FI_SOURCE</code> for most providers to reduce lookup overhead <ul> <li>Separate code paths for providers that do not support <code>FI_SOURCE</code></li> <li>Remove insert of FI addr into secondary table if <code>FI_SOURCE</code> is not used</li> </ul> </li> <li>Remove <code>NA_OFI_SOURCE_MSG</code> flag that was matching <code>FI_SOURCE_ERR</code></li> <li>Fix potential refcount race when sharing domains</li> <li>Check domain's optimal MR count if non-zero</li> <li>Fix potential double free of src_addr info</li> <li>Refactor auth key parsing code to build without extension headers</li> <li>Merge latest changes required for <code>opx</code> provider enablement<ul> <li>Pass <code>FI_COMPLETION</code> to RMA ops as flag is currently not ignored (<code>prov/opx</code> tmp fix)</li> </ul> </li> <li>Add runtime version check<ul> <li>Ensure that runtime version is greater than min version</li> </ul> </li> </ul> </li> <li>[NA SM]<ul> <li>Fix handling of 0-size messages when no receive has been posted</li> <li>Fix issue where an expected msg that is no longer posted arrives<ul> <li>In that particular case just drop the incoming msg</li> </ul> </li> <li>Add perf warning message for unexpected messages without recv posted</li> </ul> </li> <li>[NA UCX]<ul> <li>Fix handling of UCS return types to match NA types</li> <li>Enforce src_addr port used for connections to be 0<ul> <li>This fixes a port conflict between listener and connection ports</li> </ul> </li> <li>Fix handling of unexpected messages without pre-posted recv</li> </ul> </li> <li>[NA BMI]<ul> <li>Clean up and fix some coverity warnings</li> </ul> </li> <li>[NA MPI]<ul> <li>Clean up and fix some coverity warnings</li> </ul> </li> <li>[NA Test]<ul> <li>Fix NA latency test to ensure recvs are always pre-posted</li> <li>Do not use MPI_Init_thread() if not needed<ul> <li>Fix missing return check of na_test_mpi_init()</li> </ul> </li> </ul> </li> <li>[HG util]<ul> <li>Clean up logging and set log root to <code>hg_all</code><ul> <li><code>hg_all</code> subsys can now be set to turn on logging in all subsystems</li> </ul> </li> <li>Set log subsys to <code>hg_all</code> if log level env is set</li> <li>Fixes to support WIN32 builds</li> </ul> </li> <li>[CMake]<ul> <li>Fix internal/external dependencies that were not correctly set</li> <li>Fix pkg-config entries wrongly set as public/private</li> <li>Ensure <code>VERSION</code>/<code>SOVERSION</code> is not set on <code>MODULE</code> libraries</li> <li>Allow for in-source builds (RPM support)</li> <li>Add <code>DL</code> lib dependency</li> <li>Fix object target linking on CMake &lt; 3.12</li> <li>Ensure we build with PIC and PIE when available</li> </ul> </li> <li>[Examples]<ul> <li>Allow examples to build without Boost support</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.3.0/#known-issues","title":"Known Issues","text":"<ul> <li>[NA OFI]<ul> <li>[tcp/verbs;ofi_rxm] Using more than 256 peers requires <code>FI_UNIVERSE_SIZE</code> to be set.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.3.1/","title":"Release Notes v2.3.1","text":""},{"location":"releases/CHANGES_v2.3.1/#summary","title":"Summary","text":"<p>This version brings bug fixes and updates to our v2.3.0 release.</p>"},{"location":"releases/CHANGES_v2.3.1/#new-features","title":"New features","text":"<ul> <li>[HG info]<ul> <li>Add support for CSV and JSON output formats</li> </ul> </li> <li>[HG/NA Perf Test]<ul> <li>Enable sizes to be passed using k/m/g qualifiers</li> </ul> </li> <li>[NA OFI]<ul> <li>Add <code>tcp_rxm</code> alias for <code>tcp;ofi_rxm</code></li> <li>Find CXI <code>svc_id</code> or <code>vni</code> if <code>auth_key</code> components have zeros (e.g., <code>auth_key=0:0</code>)<ul> <li>Add VNI index for <code>SLINGSHOT_VNIS</code> discovery as extra auth_key parameter</li> </ul> </li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.3.1/#bug-fixes","title":"Bug fixes","text":"<ul> <li>[HG/NA]<ul> <li>Fix potential race when checking secondary completion queue</li> </ul> </li> <li>[HG]<ul> <li>Prevent multiple threads from entering <code>HG_Core_progress()</code><ul> <li>Add <code>HG_ALLOW_MULTI_PROGRESS</code> CMake option to control behavior (<code>ON</code> by default)</li> <li>Disable <code>NA_HAS_MULTI_PROGRESS</code> if <code>HG_ALLOW_MULTI_PROGRESS</code> is <code>ON</code></li> </ul> </li> <li>Fix expected operation count for handle to be atomic<ul> <li>Expected operation count can change if extra RPC payload must be transferred</li> </ul> </li> <li>Let poll events remain private to HG poll wait<ul> <li>Prevent a race when multiple threads call progress and <code>HG_ALLOW_MULTI_PROGRESS</code> is <code>OFF</code></li> </ul> </li> <li>Separate internal list from user created list of handles<ul> <li>Address an issue where <code>HG_Context_unpost()</code> would unnecessarily wait</li> </ul> </li> </ul> </li> <li>[HG Core]<ul> <li>Cache disabled response info in proc info</li> <li>Add <code>HG_Core_registered_disable(d)_response()</code> routines</li> <li>Refactor and optimize self RPC code path</li> <li>Add additional logging of refcount/expected op count</li> <li>Fixes for self RPCs with no response</li> </ul> </li> <li>[HG Util]<ul> <li>Prevent locking in <code>hg_request_wait()</code><ul> <li>Concurrent progress in multi-threaded scenarios on the same context could complete another thread's request and let a thread blocked in progress</li> </ul> </li> </ul> </li> <li>[HG Perf]<ul> <li>Fix tests to be run in parallel with any communicator size</li> </ul> </li> <li>[HG Test]<ul> <li>Ensure affinity of class thread is set</li> <li>Add concurrent multi RPC test</li> <li>Add multi-progress test</li> <li>Add multi-progress test with handle creation</li> <li>Refactoring of unit test cleanup</li> </ul> </li> <li>[NA]<ul> <li>Fix memory leak on <code>NA_Get_protocol_info()</code></li> </ul> </li> <li>[NA OFI]<ul> <li>Fix <code>na_ofi_get_protocol_info()</code> not returning <code>opx</code> protocol<ul> <li>Refactor <code>na_ofi_getinfo()</code> to account for <code>NA_OFI_PROV_NULL</code> type</li> <li>Ensure there are no duplicated entries</li> </ul> </li> <li>Refactor parsing of init info strings and fix OPX parsing</li> <li>Simplify parsing of some address strings</li> <li>Bump default CQ size to have a maximum depth of 128k entries</li> <li>Remove sockets as the only provider on macOS</li> <li>Remove send after send tagged msg ordering</li> <li>Ensure that <code>rx_ctx_bits</code> are not set if SEP is not used</li> <li>Set CXI domain ops w/ slingshot 2.2 to prevent from potential memory corruptions</li> </ul> </li> <li>[NA Perf]<ul> <li>Prevent tests from being run as parallel tests</li> </ul> </li> <li>[CMake]<ul> <li>Pass <code>INSTALL_NAME_DIR</code> through target properties<ul> <li>This fixes an issue seen on macOS where libraries would not be found using <code>@rpath</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.3.1/#known-issues","title":"Known Issues","text":"<ul> <li>[NA OFI]<ul> <li>[tcp/verbs;ofi_rxm] Using more than 256 peers requires <code>FI_UNIVERSE_SIZE</code> to be set.</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.4.0/","title":"Release Notes v2.4.0","text":""},{"location":"releases/CHANGES_v2.4.0/#summary","title":"Summary","text":"<p>This new version brings both bug fixes and feature updates to mercury. Notable are the addition of a new progress mechanism, new initialization parameters for the handling of multi-recv buffers and the support of cxi with HPE SHS 11.0.</p>"},{"location":"releases/CHANGES_v2.4.0/#new-features","title":"New features","text":"<ul> <li>[HG]<ul> <li>Add <code>HG_Get_input_payload_size()</code>/<code>HG_Get_output_payload_size()</code><ul> <li>Add the ability to query input / output payload sizes</li> </ul> </li> <li>Add <code>HG_Diag_dump_counters()</code> to dump diagnostic counters<ul> <li>Add <code>rpc_req_recv_active_count</code> and <code>rpc_multi_recv_copy_count</code> counters</li> </ul> </li> <li>Add <code>HG_Class_get_counters()</code> to retrieve internal counters</li> <li>Add <code>multi_recv_copy_threshold</code> init parameter<ul> <li>Use this new parameter to fallback to memcpy to prevent starvation of multi-recv buffers</li> </ul> </li> <li>Add <code>multi_recv_op_max</code> init parameter<ul> <li>This allows users to control number of multi-recv buffers posted (libfabric plugin only)</li> </ul> </li> <li>Add <code>no_overflow</code> init option to prevent use of overflow buffers</li> <li>Improve multi-recv buffer warning messages</li> <li>Associate handle to HG proc<ul> <li><code>hg_proc_get_handle()</code> can be used to retrieve handle within proc functions</li> </ul> </li> <li>Add <code>HG_Event_get_wait_fd()</code> to retrieve internal wait object</li> <li>Add <code>HG_Event_ready()</code> / <code>HG_Event_progress()</code> / <code>HG_Event_trigger()</code> to support wait fd progress model<ul> <li>Simplify progress mechanism and remove use of internal timers</li> <li>Always make NA progress when <code>HG_Event_progress()</code> is called</li> <li>Update HG progress to use new NA progress routines</li> </ul> </li> <li>Add missing <code>HG_WARN_UNUSED_RESULT</code> to HG calls</li> <li>Switch to using standard types and align with NA<ul> <li>Keep some <code>uint8_t</code> instances instead of <code>hg_bool_t</code> for ABI compatibility</li> </ul> </li> <li>Add <code>HG_IO_ERROR</code> return code</li> </ul> </li> <li>[NA]<ul> <li>Bump NA version to v5.0.0</li> <li>Add <code>NA_Poll()</code> and <code>NA_Poll_wait()</code> routines</li> <li>Deprecate <code>NA_Progress()</code> in favor of poll routines</li> <li>Add <code>NA_Context_get_completion_count()</code> to retrieve size of completion queue</li> <li>Update plugins to use new <code>poll</code> and <code>poll_wait</code> callbacks<ul> <li><code>poll_wait</code> plugin callback remains for compatibility</li> </ul> </li> <li>Fix documentation of <code>NA_Poll_get_fd()</code></li> <li>Add missing <code>NA_WARN_UNUSED_RESULT</code> qualifiers</li> <li>Remove deprecated CCI plugin</li> <li>Return last known error when plugin loading fails</li> <li>Add init info version compatibility wrappers</li> <li>Add support for <code>traffic_class</code> init info (only supported by ofi plugin)</li> <li>Add <code>NA_IO_ERROR</code> return code for generic I/O errors<ul> <li>Update OFI and UCX plugins to use new code</li> </ul> </li> </ul> </li> <li>[NA OFI]<ul> <li>Support use of cxi provider with SHS 11.0</li> <li>Add support for <code>FI_AV_AUTH_KEY</code> (requires libfabric &gt;= 1.20)<ul> <li>Add runtime check for cxi provider version</li> <li>Setting multiple auth keys disables <code>FI_DIRECTED_RECV</code></li> <li>Separate opening of AV and auth key insertion</li> <li>Parse auth key range when <code>FI_AV_AUTH_KEY</code> is available</li> <li>Encode/decode auth key when serializing addrs</li> </ul> </li> <li>Add support for <code>FI_AV_USER_ID</code></li> <li>Always use <code>FI_SOURCE</code> and <code>FI_SOURCE_ERR</code> when both are supported<ul> <li>Clean up handling of <code>FI_SOURCE_ERR</code></li> <li>Remove support of <code>FI_SOURCE</code> w/o <code>FI_SOURCE_ERR</code></li> </ul> </li> <li>Add support for new CXI address format</li> <li>Attempt to distribute multi-NIC domains based on selected CPU ID</li> <li>Support selection of traffic classes (single class per NA class)</li> <li>Add support for <code>FI_PROTO_CXI_RNR</code></li> <li>Add <code>NA_OFI_SKIP_DOMAIN_OPS</code> env variable to skip cxi domain ops</li> <li>Remove unused <code>NA_OFI_DOM_SHARED</code> flag</li> </ul> </li> <li>[NA UCX]<ul> <li>Add <code>ucx</code> log outlet and redirect UCX log<ul> <li>Use default HG log level if <code>UCX_LOG_LEVEL</code> is not set</li> </ul> </li> </ul> </li> <li>[HG/NA perf]<ul> <li>Add <code>hg_first</code> perf test to measure cost of initial RPC</li> <li>Add <code>-u</code> option to control number of multi-recv ops (server only)</li> <li>Add <code>-i</code> option to control number of handles posted (server only)</li> <li>Add <code>-f</code>/<code>--hostfile</code> option to select hostfile to write to / read from</li> <li>Add <code>-T</code>/<code>--tclass</code> option to select trafic class</li> <li>Autodetect MPI implementation in perf utilities<ul> <li>MPI can now be autodetected and dynamically loaded in utilities, even if <code>MERCURY_TESTING_ENABLE_PARALLEL</code> was turned off. If <code>MERCURY_TESTING_ENABLE_PARALLEL</code> is turned on, tests remain manually linked against MPI as they used to be.</li> </ul> </li> <li>Print registration and deregistration times when <code>-R</code> option is used</li> <li>Update to use new HG/NA progress routines and remove use of <code>hg_request</code></li> <li>Support forced registration in <code>hg_bw_read</code>/<code>hg_bw_write</code></li> </ul> </li> <li>[HG Util]<ul> <li>Add <code>hg_log_vwrite()</code> to write log from <code>va_list</code></li> <li>Add <code>hg_log_level_to_string()</code></li> <li>Clean up <code>mercury_event</code> code and add <code>const</code> qualifier to <code>hg_poll_get_fd()</code></li> <li>Add <code>const</code> on atomic gets</li> <li>Switch to using <code>sys/queue.h</code> directly</li> <li>Remove <code>HG_QUEUE</code> and <code>HG_LIST</code> definitions</li> <li>Add <code>hg_dl_error()</code> to return last error</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.4.0/#bug-fixes","title":"Bug fixes","text":"<ul> <li>[HG]<ul> <li>Fix shared-memory path that was previously disabled in conjunction with libfabric transports that use the multi-recv capability</li> <li>Fix behavior of <code>request_post_incr</code> init parameter<ul> <li><code>request_post_incr</code> cannot be disabled (set to -1) with multi-recv</li> </ul> </li> </ul> </li> <li>[HG/NA]<ul> <li>HG NA init info is fixed to v4.0 for now and duplicates tclass info</li> </ul> </li> <li>[NA]<ul> <li>Fix missing free of dynamic plugin entries</li> </ul> </li> <li>[NA BMI/MPI]<ul> <li>Return actual msg size through cb info</li> </ul> </li> <li>[NA OFI]<ul> <li>Fix cxi domain ops settings and disable <code>PROV_KEY_CACHE</code></li> <li>Fix shm provider flags</li> <li>Remove excessive MR count warning message</li> </ul> </li> <li>[NA UCX]<ul> <li>Fix <code>hg_info</code> not filtering protocol   <ul> <li>Allow <code>na_ucx_get_protocol_info()</code> to resolve ucx tl name aliases</li> </ul> </li> <li>Fix context thread mode to default to <code>UCS_THREAD_MODE_MULTI</code></li> </ul> </li> <li>[HG/NA Perf]<ul> <li>Ensure NA perf tests wait on send completion</li> <li>Fix bulk permission flag in <code>hg_bw_read</code></li> <li>Add some missing error checks in mercury_perf</li> </ul> </li> <li>[HG util]<ul> <li>Multiple logging fixes:<ul> <li>Fix <code>dlog_free</code> not called when parent/child have separate dlogs</li> <li>Fix mercury log to correctly generate outlet names</li> <li>Fix log outlets to use prefixed subsys name</li> <li>Fix use of macros in debug log</li> <li>Use destructor to free log outlets</li> </ul> </li> <li>Add missing prototype to <code>hg_atomic_fence()</code> definition</li> </ul> </li> <li>[CMake]<ul> <li>Fix cmake_minimum_required() warning</li> <li>Update kwsys and mchecksum dependencies</li> </ul> </li> </ul>"},{"location":"releases/CHANGES_v2.4.0/#known-issues","title":"Known Issues","text":"<ul> <li>[NA OFI]<ul> <li>[tcp/verbs;ofi_rxm] Using more than 256 peers requires <code>FI_UNIVERSE_SIZE</code> to be set.</li> </ul> </li> </ul>"},{"location":"releases/download/","title":"Download","text":"<p>Mercury is distributed under a BSD 3-Clause license.</p>"},{"location":"releases/download/#latest-release","title":"Latest Release","text":"Filename Date Size Arch Type mercury-2.4.0.tar.bz2 2024-10-28 694 kB Any Source .bz2 <p>Note that releases can also be accessed through GitHub.</p> <p>Warning</p> <p>Always use the tarballs named <code>mercury-x.tar.bz2</code> and not the tarballs that GitHub generates from the \"Source code\" link as they do not include <code>mchecksum</code>/<code>kwsys</code> submodules.</p> <p>Tip</p> <p>Mercury packages are also distributed through Spack: </p>"},{"location":"releases/download/#current-development-distribution","title":"Current development distribution","text":"<p>The mercury repository is hosted on GitHub at: https://github.com/mercury-hpc/mercury</p> <p>To get the source (read-only access), simply run: <pre><code>git clone --recurse-submodules https://github.com/mercury-hpc/mercury.git \n</code></pre></p>"},{"location":"user/cancel/","title":"Cancellation and Timeouts","text":"<p>Mercury provides two separate types of transfers: RPC and bulk data. We present in this page how on-going operations can be canceled and recovered from a canceled state.</p>"},{"location":"user/cancel/#pre-requisites","title":"Pre-requisites","text":"<p>Mercury has been defined as a building block for distributed services. In that context, adding support for cancellation of mercury operations is a primary requirement to provide resiliency and allow services to recover after a fault has occurred (e.g., node failure, etc). This implies reclaiming resources that canceled operations have previously allocated. Mercury defines remote lookup operations as well as two types of transfer operations, RPC and bulk data transfers, which may be interrupted if any of the party involved no longer responds or reaches a time of no response (e.g., on process termination), in which case pending operations must be canceled. Canceling an operation that cannot complete, either because a fault has occurred or a timeout has been reached, is necessary in order to reach proper completion.</p> <p>This documentation assumes that the reader already has knowledge of Mercury and its layers (NA / HG / HG Bulk).</p>"},{"location":"user/cancel/#progress-model","title":"Progress model","text":"<p>Mercury uses a callback-based mechanism that is built on top of the network abstraction (NA) layer\u2019s callback mechanism. A callback mechanism presents two advantages compared to a traditional request based model: there is no explicit <code>wait()</code> control point; cancellation of operations can be easily done without any additional code branching.</p> <p>Mercury\u2019s progress is directly driven by NA\u2019s progress. When an NA operation completes, an internal callback is pushed to the NA\u2019s completion queue. To make progress on Mercury\u2019s operations, the Mercury layer also internally triggers these NA callback operations. Triggering NA operations may in turn result in the completion of Mercury operations. When these operations complete, the user callback that is associated with these operations is in turn pushed to a completion queue.</p> <p>RPC operations are associated with a handle that is explicitly created by the user and linked to an execution target. The forward call is passed the handle along with a structure holding the input arguments, serializes input arguments, and passes the RPC parameters to the target. On completion, the user callback passed to the forward call is pushed to a completion queue. When an RPC forward operation completes, the get output call is passed that same handle to retrieve output arguments, deserializes them. Note that the handle can be safely re-used after completion (or cancellation) to issue another RPC to the same target. When the user no longer needs to operate on a given handle, it can be explicitly destroyed; a reference count provides operation safety.</p>"},{"location":"user/cancel/#rpc-cancellation","title":"RPC cancellation","text":"<p>In that context, Mercury\u2019s RPC cancellation can be defined so that:</p> <ul> <li>No explicit tracking of handles is required (user calls     <code>HG_Destroy()</code>).</li> <li>User callbacks are pushed to the completion queue with a canceled     state.</li> <li>Canceled handles can be reused to retry to forward a call to a     target.</li> </ul> <p>When cancellation is done on an HG operation, cancellation is also done internally on the NA operations that were involved in that HG operation. When this cancellation is successful and the NA operations complete with a canceled state, the HG callbacks associated to the NA operations are pushed to the completion queue. When these callbacks are executed with a canceled state, the actual HG operation is successfully canceled and the state of the operation passed to the callback function indicates that the operation was canceled.</p> <p>Warning</p> <pre><code>It is important to note that cancellation is always *local*, in the\nsense that there is no communication involved with a remote party (i.e.,\nit does not rely on the remote party being able to communicate).\n</code></pre> <p>It is also worth noting that the main focus of our implementation of mercury\u2019s RPC cancellation is the recovery from faults, and not the support of RPC transfer scenarios that rely on cancellation (e.g., optimistic queries in a data service, or higher level protocol operations, which could theoretically also be supported).</p> <p>Cancellation can be supported for the following operations: -   <code>HG_Forward()</code>, <code>HG_Respond()</code> (RPC operations) -   <code>HG_Bulk_transfer()</code> (Bulk operations)</p> <p>We define the following calls:</p> <ul> <li> <p>RPC operations:     <pre><code>    hg_return_t HG_Cancel(hg_handle_t handle);\n</code></pre></p> </li> <li> <p>Bulk operations:     <pre><code>    hg_return_t HG_Bulk_cancel(hg_op_id_t op_id);\n</code></pre></p> </li> </ul>"},{"location":"user/cancel/#use-cases","title":"Use Cases","text":"<p>Example</p> <p>Cancellation of an RPC operation without bulk transfer involved</p> <p>In the case described below, a handle is created and forwarded to a target. After reaching timeout, the current operation referenced by the handle is canceled. The <code>forward_cb</code> user callback is pushed to the context\u2019s completion queue with a canceled return state.</p> <pre><code>static hg_return_t\nforward_cb(const struct hg_cb_info *cb_info)\n{\n    if (cb_info-&gt;ret == HG_CANCELED) {\n        /* Canceled */\n    }\n    if (cb_info-&gt;ret == HG_SUCCESS) {\n        /* Successfully executed */\n    }\n}\n\nint\nmain(void)\n{\n    hg_handle_t handle;\n\n    /* Create new HG handle */\n    HG_Create(hg_context, target, rpc_id, &amp;hg_handle);\n    /* Encode RPC */\n    ...\n    /* Forward call */\n    HG_Forward(hg_handle, forward_cb, forward_cb_args, in_struct);\n    /* No progress after timeout */\n    ...\n    /* Cancel operation */\n    HG_Cancel(hg_handle);\n    /* Trigger user callback */\n    HG_Trigger(hg_context);\n    /* Destroy handle */\n    HG_Destroy(hg_handle);\n}\n</code></pre> <p>Example</p> <p>Cancellation of an RPC operation with bulk transfer involved</p> <p>In that case, the RPC operation additionally involves a bulk transfer that is initiated by a remote target. A bulk handle that describes the memory region is first created and registered to the NIC. This bulk handle is then serialized along with the RPC arguments, thereby exposing/publishing the memory region to the target. The RPC handle is similarly forwarded to the target. After reaching timeout, the handle is canceled. The <code>forward_cb</code> user callback is pushed to the context\u2019s completion queue with a canceled return state.</p> <p>It is worth noting that when the RPC operation is canceled, the target may be in the process of accessing the exposed bulk region. To guarantee prevention of further remote accesses to the region involved in the bulk transfer, the bulk transfer must be separately destroyed and unpublished (note that this guaranty is only valid if the underlying NA plugin supports it). The bulk handle is part of the input data structure and can be referenced within the RPC handle callback function for the purpose of separately canceling the remote bulk operation.</p> <pre><code>static hg_return_t\nforward_cb(const struct hg_cb_info *cb_info)\n{\n    if (cb_info-&gt;ret == HG_CANCELED) {\n        /* Canceled */\n    }\n    if (cb_info-&gt;ret == HG_SUCCESS) {\n        /* Successfully executed */\n    }\n}\n\nint\nmain(void)\n{\n    hg_handle_t handle;\n    hg_bulk_t bulk_handle;\n\n    /* Create new HG bulk handle */\n    HG_Bulk_create(hg_class, buffer_ptrs, buffer_sizes,\n                &amp;hg_bulk_handle);\n    /* Create new HG handle */\n    HG_Create(hg_context, target, rpc_id, &amp;hg_handle);\n    /* Encode RPC and bulk handle */\n    in_struct.bulk_handle = bulk_handle;\n    ...\n    /* Forward call */\n    HG_Forward(hg_handle, forward_cb, forward_cb_args, &amp;in_struct);\n    /* No progress after timeout */\n    ...\n    /* Cancel operation */\n    HG_Cancel(hg_handle);\n    /* Trigger user callback */\n    HG_Trigger(hg_context);\n    /* Destroy HG handle */\n    HG_Destroy(hg_handle);\n    /* Destroy HG bulk handle */\n    HG_Bulk_destroy(hg_bulk_handle);\n}\n</code></pre> <p>Example</p> <p>Cancellation of a bulk operation</p> <p>Bulk cancellation follows a similar model. However, bulk operations are initiated by an RPC target, not by the origin. Bulk operations are identified by an operation ID, which gets freed when the bulk callback is executed.</p> <pre><code>static hg_return_t\nbulk_cb(const struct hg_cb_info *cb_info)\n{\n    if (cb_info-&gt;ret == HG_CANCELED) {\n        /* Canceled */\n    }\n    if (cb_info-&gt;ret == HG_SUCCESS) {\n        /* Successfully executed */\n    }\n}\n\nstatic hg_return_t\nrpc_cb(hg_handle_t handle)\n{\n    hg_bulk_t origin_handle, local_handle;\n\n    /* Setup handles etc */\n    ...\n    /* Start the transfer */\n    HG_bulk_transfer(context, bulk_cb, bulk_cb_args, HG_BULK_PULL,\n                    origin_addr, origin_handle, origin_offset,\n                    local_handle, local_offset, size, &amp;op_id);\n    /* No progress after timeout */\n    ...\n    /* Cancel operation */\n    HG_Bulk_cancel(op_id);\n    /* Trigger user callback */\n    HG_Trigger(context);\n}\n</code></pre>"},{"location":"user/cancel/#timeouts-and-retries","title":"Timeouts and Retries","text":"<p>Mercury does not currently support timeouts on operations because this would require tracking handles / operation IDs, which could lead to unnecessary overheads within the Mercury layer. For cases where a timeout is desired, the application can wrap around Mercury calls. The example below shows how one can use the HG request emulation library to issue an RPC call with timeout.</p> <p>Example</p> <pre><code>static hg_return_t\nforward_cb(const struct hg_cb_info *cb_info)\n{\n    hg_request_t *request = (hg_request_t *) cb_info-&gt;arg;\n    if (cb_info-&gt;ret == HG_CANCELED) {\n        /* Canceled */\n    }\n    if (cb_info-&gt;ret == HG_SUCCESS) {\n        /* Successfully executed */\n    }\n    hg_request_complete(request);\n}\n\nint\nmain()\n{\n    hg_handle_t handle;\n    hg_request_t *request;\n\n    /* Create new HG handle */\n    HG_Create(hg_context, target, rpc_id, &amp;hg_handle);\n    /* Encode RPC */\n    ...\n    /* Create new request */\n    request = hg_request_create(request_class);\n    /* Forward call */\n    HG_Forward(hg_handle, forward_cb, request, &amp;in_struct);\n    /* Wait for completion */\n    hg_request_wait(request, timeout, &amp;completed);\n    if (!completed)\n        HG_Cancel(hg_handle);\n    /* Wait for completion */\n    hg_request_wait(request, timeout, &amp;completed);\n    /* Destroy request */\n    hg_request_destroy(request);\n    /* Destroy handle */\n    HG_Destroy(hg_handle);\n}\n</code></pre>"},{"location":"user/cancel/#cancellation-in-na","title":"Cancellation in NA","text":"<p>Cancellation of HG operations can only be realized by first supporting cancellation at the NA layer. Cancellation is supported via the following call:</p> <pre><code>na_return_t\nNA_Cancel(na_class_t *na_class, na_context_t *context, na_op_id_t op_id);\n</code></pre> <p>An additional <code>cancel</code> callback is added to the NA layer that allows plugin developers to support cancellation of non-blocking operations. These include:</p> <ul> <li><code>NA_Msg_send_unexpected()</code>, <code>NA_Msg_recv_unexpected()</code></li> <li><code>NA_Msg_send_expected()</code>, <code>NA_Msg_recv_expected()</code></li> <li><code>NA_Put()</code>, <code>NA_Get()</code></li> </ul> <p>Cancellation of NA operations is internally progressed and actually completes when internal plugin cancellation has been successfully completed (which may or may not be immediate). When an NA operation is successfully canceled, the internal callback associated to the HG operation is placed onto the NA context\u2019s completion queue with a <code>NA_CANCELED</code> return state.</p> <p>Cancellation is supported for all plugins. It is worth noting that BMI and MPI emulate one-sided operations (<code>NA_Put()</code>, <code>NA_Get()</code>) on top of two-sided operations and cancellation for these operations is not yet supported. To emulate these operations, send/recv requests are sent to the remote target which may issue a send in the case of a get, or issue a recv in the case of a put. Cancellation of these operations implies cancellation at the target of the potentially issued send/recv operations, which can only be done using timeouts (remote notification not being an option because the caller has no guaranty that the target is still alive).</p> <p>Cancellation capabilities and execution scenarios where cancellation is supported (i.e., not only for fault tolerance) only depend on the underlying NA plugins and their capabilities to support cancellation of on-going transfers. The BMI plugin for example may not recover well from cancellation of transfers when using TCP and a rendez-vous protocol, as the TCP channel must be entirely flushed before one can do further communication. This may be compromising if other operations were also in the pipe at that time as these operations may consequently fail.</p>"},{"location":"user/cancel/#conclusion","title":"Conclusion","text":"<p>Adding cancellation to mercury is an important step for building resilient services and a required component for the definition of future high-level mercury features such as group membership and pub/sub services, where fault tolerance must be considered in order to prevent collective failure.</p>"},{"location":"user/checksum/","title":"MChecksum Library","text":"<p>Note</p> <p>Mercury users should generally not have to directly use the MChecksum library as checksumming may be done within Mercury for small messages. For large payloads, however, if checksums are desired, users should then be responsible for calling MChecksum routines on the buffers.</p> <p>Mchecksum is a library created in the context of Mercury for checksumming RPC headers as well as RPC function arguments. In Mercury, checksums are not computed for bulk data transfers and it is left upon the user to decide whether to verify transfers or not. Because mchecksum is a separate library, it can be independently used by applications to verify data integrity. Mchecksum provides a simple interface and uses a system of plugins to abstract and provide various hash methods.</p>"},{"location":"user/checksum/#interface","title":"Interface","text":"<p>A checksum object is created using the <code>mchecksum_init()</code> function with a valid hash method (see the available plugins section for a list of plugins and the <code>hash_method</code> format).</p> <pre><code>int mchecksum_init(const char *hash_method, mchecksum_object_t *checksum);\n</code></pre> <p>The checksum object is destroyed with a call to <code>mchecksum_destroy()</code>.</p> <pre><code>int mchecksum_destroy(mchecksum_object_t checksum);\n</code></pre> <p>The checksum can be reset with <code>mchecksum_reset()</code>, which prevents an extra allocation when the checksum needs to be re-used.</p> <pre><code>int mchecksum_reset(mchecksum_object_t checksum);\n</code></pre> <p>The size of the checksum can be queried using the <code>mchecksum_get_size()</code> call.</p> <pre><code>size_t mchecksum_get_size(mchecksum_object_t checksum);\n</code></pre> <p>The computed checksum hash can be retrieved with a call to <code>mchecksum_get()</code>. If <code>MCHECKSUM_FINALIZE</code> is passed, the checksum is finalized and no more data can be added to that checksum, the only valid calls to follow are either <code>mchecksum_reset()</code> or <code>mchecksum_destroy()</code>. If <code>MCHECKSUM_NOFINALIZE</code> is passed, more data can be later added to this checksum.</p> <pre><code>int mchecksum_get(mchecksum_object_t checksum, void *buf, size_t size, int finalize);\n</code></pre> <p>The checksum is computed on a given piece of data by using the <code>mchecksum_update()</code> call. Note again that incremental update is allowed unless <code>mchecksum_get()</code> has been called with the <code>MCHECKSUM_FINALIZE</code> parameter.</p> <pre><code>int mchecksum_update(mchecksum_object_t checksum, const void *data, size_t size);\n</code></pre>"},{"location":"user/checksum/#available-plugins","title":"Available Plugins","text":"<p>Below is a list of the currently available plugins as well as corresponding initialization strings that must be passed to the <code>mchecksum_init()</code> call. Note that CRC32 and ADLER32 are available through the ZLIB library and CRC32C is available with and without SSE4.2 optimization. When using the ISA-L library, improved performance can be achieved for CRC16, CRC32C and CRC64 by using the <code>PCLMULQDQ</code> CPU instruction (when supported).</p> Plugin Initialization Format CRC16 <code>crc16</code> CRC32 <code>crc32</code> CRC32C <code>crc32c</code> CRC64 <code>crc64</code> ADLER32 <code>adler32</code>"},{"location":"user/checksum/#performance-comparison","title":"Performance Comparison","text":"<p>Below is a performance comparison of the hash methods defined through mchecksum, using non-SSE/SSE/ISA-L (v2.24.0) versions. </p>"},{"location":"user/checksum/#example","title":"Example","text":"<p>The example below is given for illustration.</p> <pre><code>#include &lt;mchecksum.h&gt;\n#include &lt;stdlib.h&gt;\n\n#define BUF_SIZE 256\n\nint\nmain(int argc, char *argv[])\n{\n    unsigned char buf[BUF_SIZE];\n    unsigned int i;\n    mchecksum_object_t checksum;\n    void *hash = NULL;\n    size_t hash_size;\n    int ret = EXIT_SUCCESS;\n\n    /* Initialize buf */\n    for (i = 0; i &lt; BUF_SIZE; i++)\n        buf[i] = i;\n\n    /* Initialize checksum */\n    mchecksum_init(\"crc32c\", &amp;checksum);\n\n    /* Update checksum */\n    mchecksum_update(checksum, buf, BUF_SIZE);\n\n    /* Get size of checksum and allocate buffer to store checksum */\n    hash_size = mchecksum_get_size(checksum);\n    hash = malloc(hash_size);\n\n    /* Get checksum and finalize it */\n    mchecksum_get(checksum, hash, hash_size, MCHECKSUM_FINALIZE);\n\n    /* Use checksum */\n    ...\n\n    /* Destroy checksums and free hash buffers */\n    mchecksum_destroy(checksum);\n    free(hash);\n\n    return ret;\n}\n</code></pre>"},{"location":"user/drc/","title":"Using Cray DRC credentials","text":"<p>The goal of this page is to present minimal usage of Cray Dynamic RDMA Credential (DRC) mechanism when using mercury and libfabric. Design notes on DRC were presented at CUG in this paper. DRC must be used on Cray systems with Aries interconnect in order to establish cross-job communication (normally two separate jobs are protected by protection domains and communication may only occur within that domain).</p>"},{"location":"user/drc/#client-server-example","title":"Client-Server Example","text":"<p>In this example we show how a server can grant access to a client job. The first step is for the server to acquire a new DRC token by calling:</p> <pre><code>uint32_t credential;\n\ndrc_acquire(&amp;credential, 0);\n</code></pre> <p>On the client, the first step is to usually retrieve the WLM ID by calling:</p> <pre><code>uint32_t wlm_id = drc_get_wlm_id();\n</code></pre> <p>The WLM ID should then be communicated to the server (using TCP for example), which can then grant access to the client by doing:</p> <pre><code>drc_grant(credential, wlm_id, DRC_FLAGS_TARGET_WLM);\n</code></pre> <p>From there, the server can simply pass around its <code>credential</code> back to the client.</p> <p>Both the client and server should then use that credential to retrieve a cookie that will then be used to communicate within the domain:</p> <pre><code>drc_info_handle_t credential_info;\nuint32_t cookie;\n\ndrc_access(credential, 0, &amp;credential_info);\ncookie = drc_get_first_cookie(credential_info);\n</code></pre> <p>The cookie can then be given to Mercury through the init info struct:</p> <pre><code>char auth_key[16];\nstruct hg_init_info init_info = HG_INIT_INFO_INITIALIZER;\n\nsprintf(auth_key, \"%\" PRIu32, cookie);\ninit_info.na_init_info.auth_key = auth_key;\n\nhg_class = HG_Init_opt(... /* init string */, ... /* listen */, &amp;init_info);\n</code></pre> <p>Note that eventually the DRC resources must also be released by doing:</p> <pre><code>drc_release_local(&amp;credential_info);\ndrc_release(credential, 0);\n</code></pre>"},{"location":"user/hg/","title":"Mercury RPC Layer","text":"<p>The RPC layer is used for sending and receiving RPCs. RPC arguments are generally small. For handling larger arguments, this layer is complemented with a bulk interface that is covered in the next section.</p>"},{"location":"user/hg/#hg-interface","title":"HG Interface","text":"<p>The HG interface directly builds on top of the NA interface. Sending an RPC generally results in two NA operations being posted: an expected receive for the response and an unexpected send for the RPC request. The entire interface is therefore non-blocking with a goal of asynchronously executing RPCs on a given target. In order to achieve that, the HG interface provides the following  primitives: target address lookup, RPC registration, RPC execution, progress and cancelation.</p>"},{"location":"user/hg/#initialization","title":"Initialization","text":"<p>To initialize the HG RPC interface, two options are available, either by using the default <code>HG_Init()</code> function and specifying an init info string as described in the NA plugin section:</p> <pre><code>hg_class_t *\nHG_Init(const char *info_string, hg_bool_t listen);\n</code></pre> <p>Or by using the <code>HG_Init_opt()</code> function, which allows for passing extra options.</p> Option Description <code>na_init_info</code> See NA initialization options. <code>na_class</code> Enables initialization from an existing NA class. <code>request_post_init</code> Controls the initial number of requests that are posted on context creation.  Default value is: 256 <code>request_post_incr</code> Controls the number of requests that are incrementally posted when the initial number of requests is exhausted.  Default value is: 256 <code>auto_sm</code> Controls whether shared-memory should be automatically used when origin and target share the same node. <code>sm_info_string</code> Overrides default init string for NA SM plugin. <code>checksum_level</code> Control checksum level on RPC (none by default). <code>no_bulk_eager</code> Prevents small bulk data from being automatically embedded along with the RPC request. <code>no_loopback</code> Disables internal loopback interface that enables forwarding of RPC to self addresses. <code>stats</code> Print RPC stats at exit. <code>no_multi_recv</code> Disable use of multi_recv feature (<code>ofi</code> plugin only) <code>release_input_early</code> Attempt to release input buffers as early as possible once <code>HG_Get_input()</code> has been called. <pre><code>struct hg_init_info {\n    struct na_init_info na_init_info;\n    na_class_t *na_class;\n    hg_uint32_t request_post_init;\n    hg_uint32_t request_post_incr;\n    hg_bool_t auto_sm;\n    const char *sm_info_string;\n    hg_checksum_level_t checksum_level;\n    hg_bool_t no_bulk_eager;\n    hg_bool_t no_loopback;\n    hg_bool_t stats;\n    hg_bool_t no_multi_recv;\n    hg_bool_t release_input_early;\n};\n\nhg_class_t *\nHG_Init_opt2(const char *na_info_string, hg_bool_t na_listen,\n             unsigned int version, const struct hg_init_info *hg_init_info);\n</code></pre> <p>Similar to the NA layer, the <code>HG_Init()</code> call results in the creation of a new <code>hg_class_t</code> object. The <code>hg_class_t</code> object can later be released after a call to:</p> <pre><code>hg_return_t\nHG_Finalize(hg_class_t *hg_class);\n</code></pre> <p>Once the interface has been initialized, a context of execution must be created, which (similar to the NA layer) internally associates a specific queue to the operations that will complete:</p> <pre><code>hg_context_t *\nHG_Context_create(hg_class_t *hg_class);\n</code></pre> <p>It can then be destroyed using:</p> <pre><code>hg_return_t\nHG_Context_destroy(hg_context_t *context);\n</code></pre>"},{"location":"user/hg/#registration","title":"Registration","text":"<p>Before an RPC can be sent, the HG class needs a way of identifying it so that a callback corresponding to that RPC can be executed on the target. Additionally, the functions to serialize and deserialize the function arguments associated to that RPC must be provided. This is done through the <code>HG_Register_name()</code> function. Note that this step can be slightly simplified by using the <code>MERCURY_REGISTER</code> macro. Registration must be done on both the origin and the target with the same <code>func_name</code> identifier. Alternatively <code>HG_Register()</code> can be used to pass a user-defined unique identifier and avoid internal hashing of the provided function name.</p> <pre><code>typedef hg_return_t (*hg_proc_cb_t)(hg_proc_t proc, void *data);\ntypedef hg_return_t (*hg_rpc_cb_t)(hg_handle_t handle);\n\nhg_id_t\nHG_Register_name(hg_class_t *hg_class, const char *func_name,\n                 hg_proc_cb_t in_proc_cb, hg_proc_cb_t out_proc_cb,\n                 hg_rpc_cb_t rpc_cb);\n</code></pre> <p>It is also possible (but not necessary) to deregister an existing RPC ID, in the case where an RPC should no longer be received by using:</p> <pre><code>hg_return_t\nHG_Deregister(hg_class_t *hg_class, hg_id_t id);\n</code></pre> <p>In the case where an RPC does not require a response, one can indicate that no response is expected (and therefore avoid waiting for a message to be sent back) by using the following call (on an already registered RPC):</p> <pre><code>hg_return_t\nHG_Registered_disable_response(hg_class_t *hg_class, hg_id_t id, hg_bool_t disable);\n</code></pre>"},{"location":"user/hg/#target-address-lookup","title":"Target Address Lookup","text":"<p>As mentioned in the overview section, there is no real distinction between client and server since it may be desirable for a client to also act as a server for other processes. Therefore, the interface only uses the distinction of origin and target.</p> <p>Similar to NA's API, the first step consists of retrieving the target's address, this can be done by calling on the target:</p> <pre><code>hg_return_t\nHG_Addr_self(hg_class_t *hg_class, hg_addr_t *addr);\n</code></pre> <p>And then convert it to string using:</p> <pre><code>hg_return_t\nHG_Addr_to_string(hg_class_t *hg_class, char *buf, hg_size_t *buf_size, hg_addr_t addr);\n</code></pre> <p>The string can then be exchanged back with the origin through out-of-band mechanisms (e.g., using a file, etc), which can then look the target up using the function:</p> <pre><code>hg_return_t\nHG_Addr_lookup(hg_class_t *hg_class, const char *name, hg_addr_t *addr);\n</code></pre> <p>All addresses must then be freed using:</p> <pre><code>hg_return_t\nHG_Addr_free(hg_class_t *hg_class, hg_addr_t addr);\n</code></pre>"},{"location":"user/hg/#rpc-execution","title":"RPC Execution","text":"<p>Executing an RPC is generally composed of two parts, one on the origin, which will send the RPC request and receive a response, one on the target, which will receive the request, execute it and send a response back.</p>"},{"location":"user/hg/#origin","title":"Origin","text":"<p>Using the RPC ID defined after a call to <code>HG_Register()</code>, one can use the <code>HG_Create()</code> call to define a new <code>hg_handle_t</code> object that can be used (and later re-used without reallocating resources) to set/get input/output arguments.</p> <pre><code>hg_return_t\nHG_Create(hg_context_t *context, hg_addr_t addr, hg_id_t id, hg_handle_t *handle);\n</code></pre> <p>This handle can be destroyed with <code>HG_Destroy()</code>\u2014and a reference count prevents resources from being released while the handle is still in use.</p> <pre><code>hg_return_t\nHG_Destroy(hg_handle_t handle);\n</code></pre> <p>The second step is to pack the input arguments within a structure, for which a serialization function is provided with the <code>HG_Register()</code> call. The <code>HG_Forward()</code> function can then be used to send that structure (which describes the input arguments). This function is non-blocking. When it completes, the associated callback can be executed by calling <code>HG_Trigger()</code>.</p> <pre><code>typedef hg_return_t (*hg_cb_t)(const struct hg_cb_info *callback_info);\n\nhg_return_t\nHG_Forward(hg_handle_t handle, hg_cb_t callback, void *arg, void *in_struct);\n</code></pre> <p>When <code>HG_Forward()</code> completes (i.e., when the user callback can be triggered), the RPC has been remotely executed and a response with the output results has been sent back. This output can then be retrieved (usually within the callback) with the following function:</p> <pre><code>hg_return_t\nHG_Get_output(hg_handle_t handle, void *out_struct);\n</code></pre> <p>Retrieving the output may result in the creation of memory objects, which must then be released by calling:</p> <pre><code>hg_return_t\nHG_Free_output(hg_handle_t handle, void *out_struct);\n</code></pre> <p>To be safe and if necessary, one must make a copy of the results before calling <code>HG_Free_output()</code>. Note that in the case of an RPC with no response, completion occurs after the RPC has been successfully sent (i.e., there is no output to retrieve).</p>"},{"location":"user/hg/#target","title":"Target","text":"<p>On the target, the RPC callback function passed to the <code>HG_Register()</code> call must be defined.</p> <pre><code>typedef hg_return_t (*hg_rpc_cb_t)(hg_handle_t handle);\n</code></pre> <p>Whenever a new RPC is received, that callback will be invoked. The input arguments can be retrieved with:</p> <pre><code>hg_return_t\nHG_Get_input(hg_handle_t handle, void *in_struct);\n</code></pre> <p>Retrieving the input may result in the creation of memory objects, which must then be released by calling:</p> <pre><code>hg_return_t\nHG_Free_input(hg_handle_t handle, void *in_struct);\n</code></pre> <p>When the input has been retrieved, the arguments contained in the input structure can be passed to the actual function call. When the execution is done, an output structure can be filled with the return value and/or the output arguments of the function. It can then be sent back using:</p> <pre><code>typedef hg_return_t (*hg_cb_t)(const struct hg_cb_info *callback_info);\n\nhg_return_t\nHG_Respond(hg_handle_t handle, hg_cb_t callback, void *arg, void *out_struct);\n</code></pre> <p>This call is also non-blocking. When it completes, the associated callback is placed onto a completion queue. It can then be triggered after a call to <code>HG_Trigger()</code>. Note that in the case of an RPC with no response, calling <code>HG_Respond()</code> will return an error.</p>"},{"location":"user/hg/#progress-and-cancelation","title":"Progress and Cancelation","text":"<p>Mercury uses a callback model. Callbacks are passed to non-blocking functions and are pushed to the context's completion queue when the operation completes. Explicit progress is made by calling <code>HG_Progress()</code>. <code>HG_Progress()</code> returns when an operation completes, is in the completion queue or <code>timeout</code> is reached.</p> <pre><code>hg_return_t\nHG_Progress(hg_context_t *context, unsigned int timeout);\n</code></pre> <p>When an operation completes, calling <code>HG_Trigger()</code> allows the callback execution to be separately controlled from the main progress loop.</p> <p>Warning</p> <p>Operations may complete with an <code>HG_SUCCESS</code> return code or with an error return code if failure occured after the operation was submitted. The <code>ret</code> field from the <code>hg_cb_info</code> struct should therefore always be checked for potential errors.</p> <pre><code>hg_return_t\nHG_Trigger(hg_context_t *context, unsigned int timeout,\n           unsigned int max_count, unsigned int *actual_count);\n</code></pre> <p>In some cases, one may want to call <code>HG_Progress()</code> then <code>HG_Trigger()</code> or have them execute in parallel by using separate threads.</p> <p>When it is desirable to cancel an HG operation, one can call <code>HG_Cancel()</code> on a HG handle to cancel an on-going <code>HG_Forward()</code> or <code>HG_Respond()</code> operation. Please refer to this page for additional details regarding cancellation of operations and handling of timeouts.</p> <pre><code>hg_return_t\nHG_Cancel(hg_handle_t handle);\n</code></pre> <p>Cancelation is always asynchronous. When/if the operation is successfully canceled, it will be pushed to the completion queue and the callback <code>ret</code> value will set with an <code>HG_CANCELED</code> error return code.</p>"},{"location":"user/hg_bulk/","title":"Mercury Bulk Layer","text":"<p>In addition to the previous layer, some RPCs may require the transfer of larger amounts of data. For these RPCs, the bulk layer can be used. It is built on top of the RMA protocol defined in the network abstraction layer and prevents intermediate memory copies.</p>"},{"location":"user/hg_bulk/#hg-bulk-interface","title":"HG Bulk Interface","text":"<p>The interface allows origin processes to expose a memory region to the target by creating a bulk descriptor (which contains virtual memory address information, size of the memory region that is being exposed, and other parameters that depend on the underlying network implementation). The bulk descriptor can be serialized and sent to the target along with the RPC request arguments (using the RPC layer). When the target gets the input parameters, it can deserialize the bulk descriptor, get the size of the memory buffer that has to be transferred, and initiate the transfer. Only targets should initiate one-sided transfers so that they can, as well as controlling the data flow, protect their memory from concurrent accesses.</p> <p>As no explicit ack message is sent on transfer completion, the origin process can only assume that accesses to its local memory are completed once it receives the RPC response from the target. Therefore, in the case of an RPC with no response, great care should be taken when initiating a bulk transfer to ensure that the origin gets notified when its exposed memory can be safely released and accessed.</p>"},{"location":"user/hg_bulk/#descriptors","title":"Descriptors","text":"<p>The interface uses the class and execution context that are defined by the HG RPC layer. To initiate a bulk transfer, one needs to create a bulk descriptor on both the origin and the target, which will later be passed to the <code>HG_Bulk_transfer()</code> call.</p> <pre><code>hg_return_t\nHG_Bulk_create(hg_class_t *hg_class, hg_uint32_t count,\n               void **buf_ptrs, const hg_size_t *buf_sizes,\n               hg_uint8_t flags, hg_bulk_t *handle);\n</code></pre> <p>The bulk descriptor can be released by using:</p> <pre><code>hg_return_t HG_Bulk_free(hg_bulk_t handle);\n</code></pre> <p>For convenience, memory pointers from an existing bulk descriptor can be accessed with:</p> <pre><code>hg_return_t\nHG_Bulk_access(hg_bulk_t handle, hg_size_t offset, hg_size_t size,\n               hg_uint8_t flags, hg_uint32_t max_count, void **buf_ptrs,\n               hg_size_t *buf_sizes, hg_uint32_t *actual_count);\n</code></pre> <p>Additionally, it is also possible to bind the origin's address to the bulk handle through the <code>HG_Bulk_bind()</code> function at the cost of an additional overhead for serializing and deserializing addressing information. This should only be necessary when the source address retrieved from the <code>HG_Get_info()</code> call is different from the one that must be used for the transfer (e.g., multiple sources).</p> <pre><code>hg_return_t\nHG_Bulk_bind(hg_bulk_t handle, hg_context_t *context);\n</code></pre> <p>In that particular case, the address information can be directly retrieved using:</p> <pre><code>hg_addr_t\nHG_Bulk_get_addr(hg_bulk_t handle);\n</code></pre>"},{"location":"user/hg_bulk/#serialization","title":"Serialization","text":"<p>Serialization and deserialization of bulk handles should never be explicitly done by users and we instead encourage the use of the mercury proc routines that provide an <code>hg_proc_hg_bulk_t</code> routine:</p> <pre><code>hg_return_t\nhg_proc_hg_bulk_t(hg_proc_t proc, void *data);\n</code></pre> <p>For more details on RPC argument serialization, please refer to this section.</p>"},{"location":"user/hg_bulk/#bulk-transfer","title":"Bulk Transfer","text":"<p>When the bulk descriptor from the origin has been received, the target can initiate the bulk transfer to/from its own bulk descriptor. Virtual offsets can be used to transfer data pieces from a non-contiguous block transparently. The call is non-blocking. When the operation completes, the user callback is placed onto the context's completion queue.</p> <pre><code>hg_return_t\nHG_Bulk_transfer(hg_context_t *context, hg_bulk_cb_t callback, void *arg,\n                 hg_bulk_op_t op, hg_addr_t origin_addr,\n                 hg_bulk_t origin_handle, hg_size_t origin_offset,\n                 hg_bulk_t local_handle, hg_size_t local_offset,\n                 hg_size_t size, hg_op_id_t *op_id);\n</code></pre> <p>Note that for convenience, as the transfer needs to be realized within the RPC callback on the RPC target, the routine <code>HG_Get_info()</code> enables easy retrieval of classes, contexts and source address:</p> <pre><code>struct hg_info {\n    hg_class_t *hg_class;               /* HG class */\n    hg_context_t *context;              /* HG context */\n    hg_addr_t addr;                     /* HG address */\n    hg_id_t id;                         /* RPC ID */\n};\n\nstruct hg_info *\nHG_Get_info(hg_handle_t handle);\n</code></pre>"},{"location":"user/hg_macros/","title":"Mercury Serialization Macros","text":"<p>For convenience, Mercury provides macros that can reduce the amount of code required to send an RPC call. Instead of using tedious RPC stubs and code generators, Mercury makes use of the Boost preprocessor library so that users can generate all the boilerplate code that is necessary to serialize and deserialize function arguments.</p>"},{"location":"user/hg_macros/#rpc-registration","title":"RPC Registration","text":"<p>When registering a new RPC through the RPC layer (see previous section), users are expected to tell Mercury how to serialize and deserialize input and output arguments. To facilitate that and in conjunction with the following macros, the <code>MERCURY_REGISTER()</code> macro makes the registration of RPC calls more convenient by mapping the types to the generated proc functions.</p> <pre><code>MERCURY_REGISTER(hg_class, func_name, in_struct_type_name, out_struct_type_name, rpc_cb);\n</code></pre> <p>Example</p> <pre><code>int rpc_open(const char *path, rpc_handle_t handle, int *event_id);\n</code></pre> <p>One can use the <code>MERCURY_REGISTER</code> macro and pass the types of the input/output structures directly. In cases where no input or no output argument is present, the <code>void</code> type can be passed to the macro.</p> <pre><code>rpc_id = MERCURY_REGISTER(hg_class, \"rpc_open\", rpc_open_in_t, rpc_open_out_t, rpc_open_cb);\n</code></pre>"},{"location":"user/hg_macros/#predefined-types","title":"Predefined Types","text":"<p>Mercury already defines some types and uses standard types so that the size of the type is fixed between platforms when serializing and deserializing it. For convenience, HG types can also be used to serialize bulk handles for example, but also strings, etc.</p> Predefined Types Type name Standard types <code>int8_t</code>, <code>uint8_t</code> <code>int16_t</code>, <code>uint16_t</code> <code>int32_t</code>, <code>uint32_t</code> <code>int64_t</code>, <code>uint64_t</code> Strings <code>hg_string_t</code>, <code>hg_const_string_t</code> Bulk descriptor <code>hg_bulk_t</code> Mercury types <code>hg_bool_t</code>, <code>hg_id_t</code>, <code>hg_size_t</code>, <code>hg_ptr_t</code>"},{"location":"user/hg_macros/#new-type-description","title":"New Type Description","text":"<p>The macro <code>MERCURY_GEN_PROC()</code> can be used to describe new types that are generally composed of primitive types. The macro generates both a new struct and a proc function that can be used to serialize arguments. The structure fields contain either input arguments or output arguments. The generated proc routine uses the proc routines from pre-existing types to serialize and deserialize each of the fields.</p> <pre><code>MERCURY_GEN_PROC(struct_type_name, fields)\n</code></pre> <p>Example</p> <p>The following function has two input arguments, one output argument and one return value.</p> <pre><code>int rpc_open(const char *path, rpc_handle_t handle, int *event_id);\n</code></pre> <p>The following macro can be used to generate boilerplate code for the input argument (again, refer to the predefined types section for a list of the pre-existing types that can be passed to this macro):</p> <pre><code>MERCURY_GEN_PROC( rpc_open_in_t, ((hg_const_string_t)(path))\n                                ((rpc_handle_t)(handle)) )\n\n/* Will generate an rpc_open_in_t struct */\ntypedef struct {\n    hg_const_string_t path;\n    rpc_handle_t handle;\n} rpc_open_in_t;\n\n/* and an hg_proc_rpc_open_in_t proc function */\nhg_return_t\nhg_proc_rpc_open_in_t(hg_proc_t proc, void *data)\n{\n    hg_return_t ret;\n    rpc_open_in_t *struct_data = (rpc_open_in_t *) data;\n\n    ret = hg_proc_hg_const_string_t(proc, &amp;struct_data-&gt;path);\n    if (ret != HG_SUCCESS) {\n      /* error */\n    }\n    ret = hg_proc_rpc_handle_t(proc, &amp;struct_data-&gt;handle);\n    if (ret != HG_SUCCESS) {\n      /* error */\n    }\n    return ret;\n}\n</code></pre> <p>Note the parentheses that separate the name of the field and its type. Each field is then separated by another pair of parentheses. This follows the sequence data type of the Boost preprocessor library.</p>"},{"location":"user/hg_macros/#existing-struct-description","title":"Existing <code>struct</code> Description","text":"<p>In some cases, however, the argument types are not known by Mercury, which is the case of the previous example with the <code>rpc_handle_t</code> type. For these cases, another macro, called <code>MERCURY_GEN_STRUCT_PROC</code>, can be used. It defines a serialization function for an existing struct or type\u2014this assumes that the type can be mapped to already existing types; if not, users can create their own proc function and use the <code>hg_proc_raw</code> routine that takes a stream of bytes.</p> <pre><code>MERCURY_GEN_STRUCT_PROC(struct_type_name, fields)\n</code></pre> <p>Example</p> <p>The following function has one non-standard type, <code>rpc_handle_t</code>.</p> <pre><code>int rpc_open(const char *path, rpc_handle_t handle, int *event_id);\n\n/* pre-defined struct */\ntypedef struct {\n    hg_uint64_t cookie;\n} rpc_handle_t;\n</code></pre> <p>The following macro can then be used to generate boilerplate code for the type by defining its fields.</p> <pre><code>MERCURY_GEN_STRUCT_PROC( rpc_handle_t, ((hg_uint64_t)(cookie)) )\n\n/* Will generate an hg_proc_rpc_handle_t function */\nstatic hg_return_t\nhg_proc_rpc_handle_t(hg_proc_t proc, void *data)\n{\n    hg_return_t ret;\n    rpc_handle_t *struct_data = (rpc_handle_t *) data;\n\n    ret = hg_proc_hg_uint64_t(proc, &amp;struct_data-&gt;cookie);\n    if (ret != HG_SUCCESS) {\n      /* error */\n    }\n    return ret;\n}\n</code></pre>"},{"location":"user/na/","title":"Network Abstraction Layer","text":"<p>The network abstraction (NA) layer is internally used by both the RPC layer and the bulk layer. The NA layer uses a plugin mechanism so that support for various network protocols can be easily added and selected at runtime.</p> <p>Info</p> <p>The NA interface should not be directly used if you intend to use Mercury's RPC layer (HG calls). In that case, please directly jump to the available plugins section for a list of plugins that can be used when initializing Mercury\u2014Mercury's initialization is then further described in the RPC layer section.</p>"},{"location":"user/na/#na-interface","title":"NA Interface","text":"<p>NA provides a minimal set of function calls that abstract the underlying network fabric and that can be used to provide: target address lookup, point-to-point messaging with both unexpected and expected messaging, remote memory access (RMA), progress and cancelation. The API is non-blocking and uses a callback mechanism so that upper layers can provide asynchronous execution more easily: when progress is made (either internally or after a call to <code>NA_Progress()</code>) and an operation completes, the user callback is placed onto a completion queue. The callback can then be dequeued and separately executed after a call to <code>NA_Trigger()</code>.</p>"},{"location":"user/na/#initialization","title":"Initialization","text":"<p>When using NA, the first step of a program should consist of initializing the NA interface and selecting an underlying plugin that will be used. Initializing the NA interface with a specified <code>info_string</code> results in the creation of a new <code>na_class_t</code> object. Please refer to the available plugins section for more information on the <code>info_string</code> format. Additionally, it is possible to specify whether the <code>na_class_t</code> object will be listening or not\u2014this is the only time where a \"server\" specific behavior is defined, all subsequent calls do not make any distinction between a \"client\" and a \"server\" and instead only use the concept of origin and target. It is worth noting, however, that the <code>listen</code> flag may have an effect on the resources that are allocated and that the address passed through <code>info_string</code> will be used to create an endpoint that remote peers can access.</p> <pre><code>na_class_t *\nNA_Initialize(const char *info_string, bool listen);\n</code></pre> <p>If a more specific behavior is required, the following call can also be used to pass specific init options.</p> Option Description <code>ip_subnet</code> Preferred IP subnet to use. <code>auth_key</code> Authorization key that can be used for communication. All processes should use the same key in order to communicate. <code>max_unexpected_size</code> Max unexpected size hint that can be passed to control the size of unexpected messages. <code>max_expected_size</code> Max expected size hint that can be passed to control the size of unexpected messages. <code>progress_mode</code> Progress mode flag. Setting <code>NA_NO_BLOCK</code> will force busy-spin on progress and remove any wait/notification calls. <code>addr_format</code> Preferred address format. Can be set to <code>NA_ADDR_IPV4</code>, <code>NA_ADDR_IPV6</code> or <code>NA_ADDR_NATIVE</code>. <code>max_contexts</code> Maximum number of contexts that are expected to be created. <code>thread_mode</code> Thread mode flags. Setting <code>NA_THREAD_MODE_SINGLE</code> will relax thread-safety requirements. <code>request_mem_device</code> Request support for tranfers to/from memory devices (e.g., GPU, etc). <pre><code>struct na_init_info {\n    const char *ip_subnet;\n    const char *auth_key;\n    size_t max_unexpected_size;\n    size_t max_expected_size;\n    uint8_t progress_mode;\n    enum na_addr_format addr_format;\n    uint8_t max_contexts;\n    uint8_t thread_mode;\n    bool request_mem_device;\n};\n\nna_class_t *\nNA_Initialize_opt2(const char *info_string, bool listen, unsigned int version,\n    const struct na_init_info *na_init_info);\n</code></pre> <p>The <code>na_class_t</code> object created from these initialization calls should later be released with a call to:</p> <pre><code>na_return_t\nNA_Finalize(na_class_t *na_class);\n</code></pre> <p>Once the interface has been initialized, a context within this plugin must be created, which internally creates and associates a completion queue for the operations:</p> <pre><code>na_context_t *\nNA_Context_create(na_class_t *na_class);\n</code></pre> <p>It can then be destroyed using:</p> <pre><code>na_return_t\nNA_Context_destroy(na_class_t *na_class, na_context_t *context);\n</code></pre>"},{"location":"user/na/#target-address-lookup","title":"Target Address Lookup","text":"<p>To communicate with a target, one must first get its address. The most convenient and safe way of doing that is by calling on the target:</p> <pre><code>na_return_t\nNA_Addr_self(na_class_t *na_class, na_addr_t **addr_p);\n</code></pre> <p>And then convert that address to a string using:</p> <pre><code>na_return_t\nNA_Addr_to_string(na_class_t *na_class, char *buf, size_t *buf_size_p, na_addr_t *addr);\n</code></pre> <p>The string can then be exchanged to other processes through out-of-band mechanisms (e.g., using a file, etc), which can then look up the target using the function:</p> <pre><code>na_return_t\nNA_Addr_lookup(na_class_t *na_class, const char *name, na_addr_t **addr_p);\n</code></pre> <p>All addresses must then be freed using:</p> <pre><code>na_return_t\nNA_Addr_free(na_class_t *na_class, na_addr_t *addr);\n</code></pre>"},{"location":"user/na/#point-to-point-messaging","title":"Point-to-point Messaging","text":"<p>Point-to-point messaging in NA is always non-blocking with completion callbacks being executed after a call to <code>NA_Trigger()</code> (once the operation has completed and been placed onto the completion queue). NA supports two separates modes for sending and receiving messages: either unexpected or expected. Expected messages should always have their receive pre-posted. Though messages may be dropped without notification if that is not the case, they are usually still queued and later processed. Unexpected messages on the other handle never require receives to be pre-posted and messages are also allowed to be dropped (though once again plugins usually do queue them). Both types of messages are tagged messages that take the same arguments for sends: <pre><code>na_return_t\nNA_Msg_send_unexpected(na_class_t *na_class, na_context_t *context,\n    na_cb_t callback, void *arg, const void *buf, size_t buf_size,\n    void *plugin_data, na_addr_t *dest_addr, uint8_t dest_id, na_tag_t tag,\n    na_op_id_t *op_id);\n\nna_return_t\nNA_Msg_send_expected(na_class_t *na_class, na_context_t *context,\n    na_cb_t callback, void *arg, const void *buf, size_t buf_size,\n    void *plugin_data, na_addr_t *dest_addr, uint8_t dest_id, na_tag_t tag,\n    na_op_id_t *op_id);\n</code></pre></p> <p>And only mostly differ in their receive operation:</p> <pre><code>na_return_t\nNA_Msg_recv_unexpected(na_class_t *na_class, na_context_t *context,\n    na_cb_t callback, void *arg, void *buf, size_t buf_size,\n    void *plugin_data, na_op_id_t *op_id);\n\nna_return_t\nNA_Msg_recv_expected(na_class_t *na_class, na_context_t *context,\n    na_cb_t callback, void *arg, void *buf, size_t buf_size,\n    void *plugin_data, na_addr_t source_addr, uint8_t source_id,\n    na_tag_t tag, na_op_id_t *op_id);\n</code></pre> <p>One will only match with a specific <code>source_addr</code> and <code>tag</code> while the other will match with any source and tag, which can then later be retrieved from the callback info.</p> <pre><code>struct na_cb_info_recv_unexpected {\n    size_t actual_buf_size;\n    na_addr_t *source;\n    na_tag_t tag;\n};\n</code></pre> <p>Note that for best performance, <code>NA_Msg_buf_alloc()</code> and <code>NA_Msg_buf_free()</code> may be used to allocate send and receive buffers.</p>"},{"location":"user/na/#remote-memory-access","title":"Remote Memory Access","text":"<p>Remote memory access requires host memory that is desired to be accessed to be first registered with the NA layer. This is done in two steps, by first creating a handle that describes the memory buffer that is to be registered and calling <code>NA_Mem_register()</code> on it.</p> <pre><code>na_return_t\nNA_Mem_handle_create(na_class_t *na_class, void *buf, size_t buf_size,\n    unsigned long flags, na_mem_handle_t **mem_handle_p);\n\nna_return_t\nNA_Mem_register(na_class_t *na_class, na_mem_handle_t *mem_handle,\n    enum na_mem_type mem_type, uint64_t device);\n</code></pre> <p>Similarly, <code>NA_Mem_deregister()</code> and <code>NA_Mem_handle_free()</code> must be called to release resources.</p> <p>Once memory has been registered, the handle of the target must be serialized and exchanged with the peer that will initiate the RMA operation. This is done by calling:</p> <pre><code>na_return_t\nNA_Mem_handle_serialize(na_class_t *na_class, void *buf, size_t buf_size,\n    na_mem_handle_t *mem_handle);\n</code></pre> <p>The peer can then deserialize the handle using:</p> <pre><code>na_return_t\nNA_Mem_handle_deserialize(na_class_t *na_class, na_mem_handle_t **mem_handle_p,\n    const void *buf, size_t buf_size);\n</code></pre> <p>And initiate an RMA operation using both the handle of the target that describes its remote memory and the local handle that describes its local memory:</p> <pre><code>na_return_t\nNA_Put(na_class_t *na_class, na_context_t *context, na_cb_t callback, void *arg,\n    na_mem_handle_t *local_mem_handle, na_offset_t local_offset,\n    na_mem_handle_t *remote_mem_handle, na_offset_t remote_offset,\n    size_t data_size, na_addr_t *remote_addr, uint8_t remote_id, na_op_id_t *op_id);\n\nna_return_t\nNA_Get(na_class_t *na_class, na_context_t *context, na_cb_t callback, void *arg,\n    na_mem_handle_t *local_mem_handle, na_offset_t local_offset,\n    na_mem_handle_t *remote_mem_handle, na_offset_t remote_offset,\n    size_t data_size, na_addr_t *remote_addr, uint8_t remote_id, na_op_id_t *op_id);\n</code></pre> <p>Similar to point-to-point operations, RMA operations are non-blocking and use a callback-based model that is triggered after a call to <code>NA_Trigger()</code> when the operation completes.</p>"},{"location":"user/na/#progress-and-cancelation","title":"Progress and Cancelation","text":"<p>NA progress model is always explicit and users are expected to call <code>NA_Progress()</code> followed by a call to <code>NA_Trigger()</code>:</p> <pre><code>na_return_t\nNA_Progress(na_class_t *na_class, na_context_t *context, unsigned int timeout);\n\nna_return_t\nNA_Trigger(na_context_t *context, unsigned int max_count, unsigned int *actual_count);\n</code></pre> <p><code>NA_Trigger()</code> always operates on a single context while <code>NA_Progress()</code> may operate both on a class and a context. When progress is called, it returns as soon as an operation either completes or is already in the completion queue so that a call to <code>NA_Trigger()</code> may be done to empty the queue and execute the user callback.</p> <p>When an operation must be canceled, users are expected to call <code>NA_Cancel()</code> on that operation:</p> <pre><code>na_return_t\nNA_Cancel(na_class_t *na_class, na_context_t *context, na_op_id_t *op_id);\n</code></pre> <p>Cancelation is always asynchronous. When/if the operation is successfully canceled, it will be pushed to the completion queue with an <code>NA_CANCELED</code> error return code.</p>"},{"location":"user/na/#available-plugins","title":"Available Plugins","text":"<p>NA supports different backend implementations. However, OFI/libfabric is the recommended plugin in most situations for inter-node communication, while SM (shared-memory) is recommended for intra-node communication.</p>"},{"location":"user/na/#summary","title":"Summary","text":"<p>The table below summarizes the current list of plugins along with the transports that we currently support with those plugins.</p> Plugin / Transport <code>tcp</code> <code>verbs</code> <code>shm</code> <code>opx</code> <code>gni</code> <code>cxi</code> <code>ofi</code> <code>ucx</code> <code>sm</code> <p>Warning</p> <p>Additional transports may be supported for each plugin but we do not recommend their use unless explicitly mentioned in the above table as they are either unstable or have not been tested. Transports with  are not available for the selected plugin. Transports with  are not supported but may be available in the future. Transports with  have known issues.</p>"},{"location":"user/na/#initialization-string-format","title":"Initialization String Format","text":"<p>Below is a table summarizing the protocols and expected format for each plugin (<code>[ ]</code> means optional, in which case the plugin will select default hostnames and ports to use).</p> Plugin Protocol Initialization format<sup>1</sup> ofi tcp  verbs  shm  opx  gni  cxi <code>ofi+tcp[://&lt;hostname,IP,interface name&gt;:&lt;port&gt;]</code> <code>ofi+verbs[://[MLX device/]&lt;hostname,IP,interface name&gt;:&lt;port&gt;]</code><sup>2</sup> <code>ofi+shm</code><sup>3</sup> <code>ofi+opx[://&lt;HFI device&gt;:&lt;port&gt;]</code> <code>ofi+gni[://&lt;hostname,IP,interface name&gt;]</code> <sup>4</sup> <code>ofi+cxi[://&lt;CXI device&gt;:&lt;port ID&gt;]</code> ucx all  tcp  rc,ud,dc <sup>5</sup> <code>ucx+all[://[net_device/]&lt;hostname,IP,interface name&gt;:&lt;port&gt;]</code> na sm <code>na+sm[://&lt;shm_prefix&gt;]</code> <p>Note</p> <p>Invalid port numbers that are passed may be silently ignored by the underlying implementation in which case a new port will be automatically picked up.</p> <p><sup>1</sup> When initialized without listening, the port specification can be elided.</p> <p><sup>2</sup> The libfabric domain name can also be passed directly to select the right adapter to use. See the output generated by the command <code>hg_info</code> for provider name <code>verbs;ofi_rxm</code> (e.g., <code>mlx5_0</code>).</p> <p><sup>3</sup> Any hostname or port being passed will be ignored.</p> <p><sup>4</sup> No port information needs to be passed, the most common interface name is <code>ipogif0</code>, which will be used by default if no hostname is passed.</p> <p><sup>5</sup> Please refer to the UCX documentation for a full list of available transports that can be used.</p>"},{"location":"user/na/#ofi","title":"OFI","text":"<p>(as of v1.0.0) The NA OFI/libfabric plugin is available for general purpose use. The plugin currently supports tcp, verbs, opx and cxi transports. The psm2 and gni protocols are deprecated. See this page for additional implementation and performance details.</p> <p>Attention</p> <p>As of libfabric 1.18.0, tcp no longer uses the RxM layer. To force use of tcp with RxM, <code>tcp;ofi_rxm</code> must be directly passed. However, it is recommended to use <code>tcp</code> for improved stability and performance.</p> <p>Technical notes:</p> <ul> <li>Low CPU consumption (i.e., idles without busy spinning) is supported by all   supported libfabric providers.</li> <li>Connection-less and uses reliable datagrams.</li> <li>RMA (for Mercury bulk operations) is implemented natively on transports   that support it.</li> <li>ofi/tcp (<code>tcp</code> provider) may use the RxM layer to emulate connection-less endpoints. It also emulates RMA operations.</li> <li>ofi/verbs (<code>verbs</code> provider) uses the RxM layer to emulate connection-less endpoints (the first message being sent may be slower).</li> <li>ofi/opx (<code>opx</code> provider) can be used on legacy Intel<sup>\u00ae</sup> Omni-Path 2 interconnect and Cornelis Omni-Path Express hardware.</li> <li>ofi/gni (<code>gni</code> provider) can be used on Cray<sup>\u00ae</sup> systems with Gemini/Aries interconnects. Note that   it requires the use of Cray<sup>\u00ae</sup> DRC to exchange credentials when   communication between separate jobs is required (see section on DRC credentials).</li> <li>ofi/cxi (<code>cxi</code> provider) can be used on HPE systems with Slingshot interconnect. For systems with multiple NICs, <code>hwloc</code>   can be used to automatically select the closest NIC to the CPU in-use (mercury must be configured with <code>NA_OFI_USE_HWLOC</code>   in that case).</li> </ul> <p>Influential variables:</p> <ul> <li><code>RDMAV_HUGEPAGES_SAFE</code>: must be set when using hugepages in combination with <code>verbs</code> provider.</li> <li><code>FI_UNIVERSE_SIZE</code>: must be set when exceeding 256 peers with <code>tcp</code> or <code>verbs</code> providers.</li> </ul> <p>Please refer to the libfabric manpages for additional details for each transports.</p>"},{"location":"user/na/#ucx","title":"UCX","text":"<p>(as of v2.1.0) The UCX plugin is available for general purpose use. By default and as opposed to other plugins, the UCX plugin is able to automatically determine which transport is best to be used. This is achieved by passing the <code>all</code> keyword in lieu of a specific transport. However, note that we are only testing the <code>tcp</code> and <code>rc,ud,dc</code> (verbs) protocols of UCX.</p> <p>Technical notes:</p> <ul> <li>Connection-less is currently emulated on top of connected endpoints. Therefore,   it is expected that the first message sent to a target will be slower than   subsequent messages.</li> <li>A thread safe enabled UCX library is required to be used unless users explicitly   tell NA, using the <code>thread_mode</code> init option (see above),   that they will not access classes and contexts with more than one thread.</li> <li><code>NA_Addr_to_string()</code> cannot be used on non-listening processes to convert a    self-address to a string. This is due to the fact that UCX does not expose    endpoints prior to their connection.</li> </ul> <p>Influential variables:</p> <ul> <li><code>ucx_info -c -f</code> will display the default configuration. Each of these   variables can be overridden by the user. Note, however, that the <code>UCX_TLS</code>   and <code>UCX_NET_DEVICES</code> are currently overridden by the NA UCX plugin.</li> </ul>"},{"location":"user/na/#sm","title":"SM","text":"<p>(as of v0.9.0) This is the integrated shared memory NA plugin. Plugin is stable and provides significantly better performance for local node communication. The goal of this plugin is to provide a transparent shortcut for other NA plugins when they connect to local services using the <code>auto_sm</code> initialization option (see the RPC section for more details), but it is also useful as a primary transport for single-node services.</p> <p>Technical notes:</p> <ul> <li>Uses fully connection-less communication.</li> <li>Low CPU consumption (i.e., idles without busy spinning or using threads).</li> <li>RMA (for Mercury bulk operations) is implemented natively through     cross-memory attach (CMA) on Linux, and there are fallback methods     for other platforms as well. See this page     for additional implementation and performance details.</li> </ul>"},{"location":"user/na/#deprecated-plugins","title":"Deprecated Plugins","text":""},{"location":"user/na/#cci","title":"CCI","text":"<p>(deprecated) This NA plugin is no longer available for general purpose use,   and is now deprecated as CCI itself is no longer actively maintained.</p>"},{"location":"user/na/#mpi","title":"MPI","text":"<p>MPI implementations are widely available for nearly any platform, and the NA MPI plugin provides a convenient option for prototyping and functionality testing. It is not optimized for performance, however, and it has some practical limitations when used for persistent services.</p> <p>Technical notes:</p> <ul> <li>Clients can connect to a server dynamically only if the underlying MPI      implementation supports <code>MPI_Comm_connect()</code>.</li> <li>RMA (for Mercury bulk operations) is emulated via point-to-point messaging     (note: MPI window creation requires collective coordination and is not a     good fit for RPC use).</li> <li>Significant CPU consumption (progress function iteratively polls pending     operations for completion).</li> </ul>"},{"location":"user/na/#bmi","title":"BMI","text":"<p>The BMI library itself is no longer under active feature development beyond basic maintenance, but the NA BMI plugin provides a very stable and reasonably performant option for IP networks when used with BMI's TCP method.</p> <p>Technical notes:</p> <ul> <li>Low CPU consumption (i.e., idles without busy spinning or using threads).</li> <li>Supports dynamic client connection and disconnection.</li> <li>RMA (for Mercury bulk operations) is emulated via point-to-point messaging.</li> <li>Does not support initializing multiple instances simultaneously.</li> <li>Other BMI methods besides TCP are not supported.</li> <li>For general BMI information see this paper.</li> </ul>"},{"location":"user/ofi/","title":"Libfabric Plugin","text":"<p>Note</p> <p>The implementation notes in this page are provided for reference and may be slightly out of date. If you are only looking for user documentation, please refer to the NA plugin documentation on this page.</p>"},{"location":"user/ofi/#ofi-capabilities","title":"OFI Capabilities","text":"<p>The OFI plugin makes use of the following libfabric capabilities:</p> <ul> <li><code>FI_EP_RDM</code></li> <li><code>FI_DIRECTED_RECV</code></li> <li><code>FI_READ</code></li> <li><code>FI_RECV</code></li> <li><code>FI_REMOTE_READ</code></li> <li><code>FI_REMOVE_WRITE</code></li> <li><code>FI_RMA</code></li> <li><code>FI_SEND</code></li> <li><code>FI_TAGGED</code></li> <li><code>FI_WRITE</code></li> <li><code>FI_SOURCE</code></li> <li><code>FI_SOURCE_ERR</code></li> <li><code>FI_ASYNC_IOV</code></li> <li><code>FI_CONTEXT</code></li> <li><code>FI_MR_BASIC</code></li> <li>Scalable endpoints</li> </ul>"},{"location":"user/ofi/#feature-matrix","title":"Feature Matrix","text":"<ul> <li>Supported </li> <li>Limited support or emulated  (see footnote)</li> <li>Not supported </li> </ul> Feature tcp verbs psm2 gni Source Addressing <sup>1</sup> <sup>1</sup> Manual Progress <sup>2</sup> <sup>2</sup> <sup>2</sup> <code>FI_WAIT_FD</code> Scalable Endpoints <sup>3</sup> <p><sup>1</sup> Emulated: source address is encoded in the message header.</p> <p><sup>2</sup> Emulated: the provider is using a thread to drive background progress.</p> <p><sup>3</sup> Emulated: provider resources are shared.</p>"},{"location":"user/ofi/#performance","title":"Performance","text":"<p>Below is a performance comparison of the libfabric plugin  with available libfabric providers when using both wait and busy spin mechanisms, mercury v1.0.0 and libfabric v1.7.0a1.</p>"},{"location":"user/ofi/#infiniband-verbsrxm","title":"InfiniBand <code>verbs;rxm</code>","text":"<p>Performance is measured between two nodes on ALCF's cooley cluster using the FDR InfiniBand interface <code>mlx5_0</code>. The following plot shows the RPC average time compared to <code>ofi+tcp</code> when using one single RPC in-flight:</p> <p>Same plot but with 16 RPCs in-flight:</p> <p>The following plot shows the RPC with pull bulk transfer performance compared to <code>ofi+tcp</code> with various transfer sizes:</p> <p>Same plot but with 16 RPCs in-flight:</p> <p>The following plot shows the RPC with push bulk transfer performance compared to <code>ofi+tcp</code> with various transfer sizes:</p> <p>Same plot but with 16 RPCs in-flight:</p>"},{"location":"user/ofi/#omni-path-psm2","title":"Omni-Path <code>psm2</code>","text":"<p>Performance is measured between two nodes on LCRC's bebop cluster using the Omni-Path interface with PSM2 v11.2.23. The following plot shows the RPC average time compared to <code>ofi+tcp</code> when using one single RPC in-flight:</p> <p>Same plot but with 16 RPCs in-flight:</p> <p>The following plot shows the RPC with pull bulk transfer performance compared to <code>ofi+tcp</code> with various transfer sizes:</p> <p>Same plot but with 16 RPCs in-flight:</p> <p>The following plot shows the RPC with push bulk transfer performance compared to <code>ofi+tcp</code> with various transfer sizes:</p> <p>Same plot but with 16 RPCs in-flight:</p>"},{"location":"user/ofi/#aries-gni","title":"Aries <code>gni</code>","text":"<p>Performance is measured between two Haswell nodes (debug queue in exclusive mode) on Nersc's cori system using the interface <code>ipogif0</code> with uGNI v6.0.14.0. The following plot shows the RPC average time compared to <code>ofi+tcp</code> when using one single RPC in-flight:</p> <p>Same plot but with 16 RPCs in-flight:</p> <p>The following plot shows the RPC with pull bulk transfer performance compared to <code>ofi+tcp</code> with various transfer sizes:</p> <p>Same plot but with 16 RPCs in-flight:</p> <p>The following plot shows the RPC with push bulk transfer performance compared to <code>ofi+tcp</code> with various transfer sizes:</p> <p>Same plot but with 16 RPCs in-flight:</p>"},{"location":"user/overview/","title":"Overview","text":"<p>Mercury is composed of three main layers:</p> <ol> <li>the network abstraction layer, which provides   a high-performance communication interface on top of lower level network   fabrics.</li> <li>the RPC layer, which provides users with the necessary   components for sending and receiving RPC metadata (small messages). This includes   serialization and deserialization of function arguments;</li> <li>the bulk layer, which provides the necessary components for   handling large arguments---this implies large data transfers through RMA;</li> <li>the (optional) high-level RPC layer, which aims at   providing a convenience API, builds on top of the lower layers and provides   macros for generating RPC stubs as well as serialization and deserialization   functions.</li> </ol> <p>These three main layers can be summarized in the following diagram:</p> <p> </p> <p>By definition, an RPC call is initiated by one process, referred to as origin, and forwarded to another process, which will execute the call, and referred to as target. Each side, origin and target, uses an RPC processor to serialize and deserialize parameters sent through the interface. Calling functions with relatively small arguments results in using a short messaging mechanism exposed by the network abstraction layer, whereas functions containing large data arguments additionally use a remote memory access (RMA) mechanism. Note that when the bulk data is small enough, Mercury will automatically embed it along with the metadata if it can fit.</p>"},{"location":"user/perf/","title":"Diagnosing Performance","text":"<p>Measuring performance both at the Network Abstraction (NA) level and Mercury (RPC) level is always a good idea to ensure proper configuration of the network and that the expected performance can be achieved. To do that, Mercury comes with a set of performance measurement utilities.</p> <p>Note</p> <p>To ensure that the perf utilities are compiled, <code>BUILD_TESTING</code> and <code>BUILD_TESTING_PERF</code> must be turned <code>ON</code> in CMake options. Additionally, to enable MPI support with HG perf tests, <code>MERCURY_TESTING_ENABLE_PARALLEL</code> must also be set to <code>ON</code>. Performance utilities are placed into the <code>bin</code> directory relative to the install prefix.</p>"},{"location":"user/perf/#na-perf","title":"NA Perf","text":"<p>NA perf tests are composed of: <code>na_lat</code>, <code>na_bw_get</code>, <code>na_bw_put</code> (clients) and <code>na_perf_server</code> (server). For all of the tests, <code>na_perf_server</code> must first be launched:</p> <pre><code>na_perf_server -c ofi -p tcp -b\n</code></pre> <p>This will generate a <code>port.cfg</code> within the current working directory. This file will be used by the client to contact the server and must reside within the same working directory when launching the client.</p> <p>To measure latency of the network, run:</p> <pre><code>na_lat -c ofi -p tcp -b -l 1000\n</code></pre> <p>To measure bandwidth, run:</p> <pre><code>na_bw_get -c ofi -p tcp -b -l 1000\n</code></pre>"},{"location":"user/perf/#hg-perf","title":"HG Perf","text":"<p>HG perf tests are composed of: <code>hg_rate</code>, <code>hg_bw_read</code>, <code>hg_bw_write</code> (clients) and <code>hg_perf_server</code> (server). For all of the tests, <code>hg_perf_server</code> must first be launched:</p> <pre><code>hg_perf_server -c ofi -p tcp -b\n</code></pre> <p>This will generate a <code>port.cfg</code> within the current working directory. This file will be used by the client to contact the server and must reside within the same working directory when launching the client.</p> <p>To measure RPC rate, run:</p> <pre><code>hg_rate -c ofi -p tcp -b -l 1000\n</code></pre> <p>To measure bulk RPC bandwidth, run:</p> <pre><code>hg_bw_write -c ofi -p tcp -b -l 1000\n</code></pre>"},{"location":"user/perf/#example-daos-use-case","title":"Example: DAOS Use Case","text":"<p>Most often it is desirable to replicate a specific workflow or communication pattern. In the case of a storage system like DAOS that follows a client-server model, there are two levels of parallelism with servers being both multithreaded and distributed over multiple nodes. Clients on the other hand may also use threads but they are in most cases distributed over multiple nodes. The Mercury performance benchmarks (compiled with parallel mode enabled) can be used to replicate this use case. To simulate multithreaded servers running on multiple nodes, <code>hg_perf_server</code> can be launched with the following parameters:</p> <pre><code>mpirun -np 2 --bind-to numa --map-by numa hg_perf_server -c ofi -p tcp -b -C 16\n</code></pre> <p><code>-C</code> controls the number of Mercury classes/contexts per process (equivalent to the number of DAOS storage targets) while <code>-np</code> controls the number of processes (equivalent to the number of DAOS engines). Since classes/contexts operate independently there is no restriction on either of these values but as a general rule, it is best to restrict <code>-C</code> to the number of available cores per NUMA node (which is also the reason why tasks are mapped by and bound to NUMA nodes in that case).</p> <p>Similarly, to launch multiple clients, one would launch:</p> <pre><code>mpirun -hostfile hosts.txt --bind-to hwthread --map-by numa hg_bw_write -c ofi -p tcp -b -l 100\n</code></pre> <p>The resulting bandwidth in that case is the aggregate bandwidth (or RPC rate when using <code>hg_rate</code>). Without thread, it is best to bind the client to HW threads or cores to ensure that tasks are not migrated and the performance remains consistent.</p> <p>Tip</p> <ul> <li><code>-x</code> can be used to control the number of RPCs in flight</li> <li><code>-b</code> forces busy spin and prevents any wait/sleep</li> <li><code>-w</code> changes the RMA window size and the number of RMAs in flight, increasing it will saturate bandwidth but be wary of memory usage</li> <li><code>-y</code> / <code>-z</code> controls the min/max buffer size, setting it to the same value allows for testing a specific buffer size</li> </ul> <p>See <code>--help</code> for additional options</p>"},{"location":"user/sm/","title":"Shared-Memory Plugin","text":"<p>Note</p> <p>The implementation notes in this page are provided for reference and may be slightly out of date. If you are only looking for user documentation, please refer to the NA plugin documentation on this page.</p> <p>Mercury defines a network abstraction layer that allows definition of plugins for high-speed networks. In the case of intra-node communication, the most efficient way of accessing memory between processes is to use shared-memory.</p>"},{"location":"user/sm/#introduction","title":"Introduction","text":"<p>Mercury's network abstraction layer is designed to take advantage of high-speed networks by providing two types of messaging: small messaging (low-latency) and large transfers (high-bandwidth). Small messages fall into two categories: unexpected and expected. Large transfers use a one-sided mechanism for efficient access to remote memory, enabling transfers to be made without intermediate copy. The interface currently provides implementations for BMI, MPI, CCI and OFI libfabric, which are themselves abstractions on top of the common HPC network protocols. When doing communication locally on the same node between separate processes, it is desirable to bypass the loopback network interface and directly access/share memory regions, thereby increasing bandwidth and decreasing latency of the transfers. While the CCI plugin already provides a shared memory transport, it currently has some inherent limitations: handling is explicit and not transparent to the user; it requires explicit use of the CCI external library; it uses a connection thread internally; CCI only provides RMA registration per contiguous segment region which prevents users from transferring non-contiguous regions in one single RMA operation.</p> <p>It is also worth noting that other libraries such as libfabric support shared memory optimization, though having an independent shared-memory plugin that can be used with other transports at the same time, in a transparent manner, (and that can provide optimal performance) is an important feature for mercury.</p> <p>This document assumes that the reader already has knowledge of Mercury and its layers (NA / HG / HG Bulk). Adding shared memory support to mercury is referenced under the GitHub issue #75.</p>"},{"location":"user/sm/#requirements","title":"Requirements","text":"<p>The design of this plugin follows three main requirements:</p> <ul> <li>Reuse existing shared-memory technology and concepts to the degree possible;</li> <li>Make progress on conventional and shared-memory communication simultaneously   without busy waiting;</li> <li>Use plugin transparently (i.e., ability to use the same address for both   conventional and shared memory communication).</li> </ul>"},{"location":"user/sm/#sm-plugin-architecture","title":"SM Plugin Architecture","text":"<p>The plugin can be decomposed into multiple parts: lookup, short messages (unexpected and expected); RMA transfers; progress. Lookup, connection and set up of exchange channels between processes is initialized through UNIX domain sockets. One listening socket is created on the listening processes, which then accept connections in a non blocking manner and exchange address channel information between peers.</p>"},{"location":"user/sm/#short-messages","title":"Short Messages","text":"<p>For short messages, we use an mmap'ed POSIX shared memory object combined to a signaling interface that allows either party to be notified when a new message has been written into the shared memory space. One region is created per listening interface that allows processes to post short messages, by first reserving a buffer atomically in the mmap'ed shared memory object and then signaling the destination that it has been copied (in a non blocking manner). This requires a 2-way signaling channel (based on either an <code>eventfd</code> or a named pipe if the former is not available) per process/connection (<code>eventfd</code> descriptors can be exchanged over UNIX domain sockets through ancillary data). The number of buffers that are mmap'ed is fixed and its global size pre-defined to 64 (the size of a 64-bit atomic value) pages of 4 KB.</p> <p>CCI and MPICH for instance use different methods, CCI exposes 64 lines of 64-byte buffers with a default maximum send size of 256 bytes, MPICH exposes 8 buffers of 32 KB and copies messages in a pipelined fashion. The sender waits until there is an empty buffer, then fills it in and marks the number of bytes copied. CCI on the other hand uses an mmap'ed ring buffer for message headers and fails when the total number of buffer has been exhausted. In our case, we combine both approaches, buffers are reserved and marked with the number of bytes copied.</p>"},{"location":"user/sm/#large-transfers","title":"Large Transfers","text":"<p>Large transfers do not require explicit signaling between processes and CMA (cross-memory attach) can be used directly without mmap (on Linux platforms that support CMA as of kernel v3.2, see also this page for security requirements). In that case, the only arguments needed are the remote process ID as well as a local and remote <code>iovec</code> that describe the memory segments that are to be transferred. Note that in this case, the SM plugin performs better by registering non-contiguous memory segments and does a single scatter/gather operation between local and remote regions. Note also that passing local and remote handles requires the base address of the memory regions that needs to be accessed to be first communicated to the issuing process, though this is part of the NA infrastructure, which also implies serialization, exchange and deserialization of remote memory handles.</p> <p>Progress is made through <code>epoll()</code>/<code>poll()</code>/<code>kqueue()</code> only on connections and message signaling interfaces that are registered to a polling set, RMA operations using CMA complete immediately after the <code>process_vm_readv()</code> or <code>process_vm_writev()</code> calls complete.</p>"},{"location":"user/sm/#simultaneous-progress","title":"Simultaneous Progress","text":"<p>The second requirement is the ability to make progress simultaneously over different plugins without busing polling. In order to do that, the easiest and most efficient way is to make use of the kernel's existing file descriptor infrastructure. That method consists of exposing a file descriptor from the NA plugin and add it to a global polling set of NA plugin file descriptors. Making progress on that set of file descriptors is then made through the <code>epoll()</code>/<code>poll()</code>/<code>kqueue()</code> system calls. When one file descriptor wakes up, the NA layer can then determine which plugin that file descriptor belongs to and enter the corresponding progress functions to complete the operation. When the NA plugins supports it (e.g., SM, CCI, OFI), progress can be made without any latency overhead, which would otherwise be introduced by entering multiple <code>NA_Progress()</code> calls in order to do busy polling.</p>"},{"location":"user/sm/#transparent-use","title":"Transparent Use","text":"<p>Transparent use is essential for a shared-memory plugin as adding an explicit condition to switch between local and remote operations is not always reasonable, both in terms of performance and convenience. This mode of operation can be enabled within Mercury through the CMake option <code>MERCURY_USE_SM_ROUTING</code>.</p> <p>When enabled, Mercury internally creates a separate NA SM class and makes progress on that class as well as on the requested class (e.g., OFI, CCI). Local node detection is enabled by generating a UUID for the node and storing that UUID in the <code>NA_SM_TMP_DIRECTORY-NA_SM_SHM_PREFIX</code> directory. When a lookup call is issued, the string passed is parsed and the UUID compared with the locally stored UUID.</p>"},{"location":"user/sm/#performance","title":"Performance","text":"<p>Below is a performance comparison of the shared-memory plugin when using both wait and busy spin mechanisms, CCI v2.2, libfabric v1.7.0a1 and mercury v1.0.0. The following plot shows the RPC average time with one RPC in flight:</p> <p>Same plot but with 16 RPCs in-flight:</p> <p>The following plot shows the RPC with pull bulk transfer performance compared to existing plugins with various transfer sizes:</p> <p>Same plot but with 16 RPCs in-flight:</p> <p>The following plot shows the RPC with push bulk transfer performance compared to existing plugins with various transfer sizes:</p> <p>Same plot but with 16 RPCs in-flight:</p>"}]}